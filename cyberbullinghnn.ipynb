{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text classification with Quanvolutional layer + Attention + HQLSTM"
      ],
      "metadata": {
        "id": "IOw7Xm_A-Msu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "yXYmXj3x_Z3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports for computations"
      ],
      "metadata": {
        "id": "fklFBxOt_n0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install custatevec_cu12\n",
        "!pip install pennylane pennylane-lightning-gpu\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "9KMjztfO_iLH",
        "outputId": "0f0d18fc-e962-4f49-bfe9-fa96501248ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: custatevec_cu12 in /usr/local/lib/python3.10/dist-packages (1.6.0.post1)\n",
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.10/dist-packages (0.39.0)\n",
            "Requirement already satisfied: pennylane-lightning-gpu in /usr/local/lib/python3.10/dist-packages (0.39.0)\n",
            "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.4.2)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.15.1)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.7.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.5.0)\n",
            "Requirement already satisfied: pennylane-lightning>=0.39 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.39.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane) (24.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For plotting data"
      ],
      "metadata": {
        "id": "pNda1wZNADCt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0HzKYqfvkO5s",
        "outputId": "1e566407-08a3-4f63-de60-e9cc73cadbd9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.despine()\n",
        "# plt.style.use(\"seaborn-whitegrid\")\n",
        "plt.rc(\"figure\", autolayout=True)\n",
        "plt.rc(\"axes\", labelweight=\"bold\", labelsize=\"large\", titleweight=\"bold\", titlepad=10)\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For data preprocessing and text cleaning"
      ],
      "metadata": {
        "id": "qEByIz_FAyoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect\n",
        "!pip install contractions\n",
        "!pip install emoji==1.4.1\n",
        "!pip install nltk\n",
        "\n",
        "import re\n",
        "import string\n",
        "import emoji\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from langdetect import detect, LangDetectException\n",
        "import contractions\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "5pFgXpHkJ1fd",
        "outputId": "54f12443-be06-4caf-8140-1150c2cbcd8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.10/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n",
            "Requirement already satisfied: emoji==1.4.1 in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set seed for reproductivity"
      ],
      "metadata": {
        "id": "Z-O5RGApBB0S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0Ud4hzR0kO5v"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qulacs pennylane-qulacs"
      ],
      "metadata": {
        "id": "f7yoa98G05eo",
        "outputId": "8306550c-7d3a-4af9-ff98-04fb1bb7ede2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qulacs in /usr/local/lib/python3.10/dist-packages (0.6.10)\n",
            "Requirement already satisfied: pennylane-qulacs in /usr/local/lib/python3.10/dist-packages (0.36.0.post0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from qulacs) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from qulacs) (1.13.1)\n",
            "Requirement already satisfied: pennylane>=0.15 in /usr/local/lib/python3.10/dist-packages (from pennylane-qulacs) (0.39.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (3.4.2)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (0.15.1)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (1.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (1.4.4)\n",
            "Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (0.7.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (5.5.0)\n",
            "Requirement already satisfied: pennylane-lightning>=0.39 in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (0.39.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (24.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane>=0.15->pennylane-qulacs) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane>=0.15->pennylane-qulacs) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane>=0.15->pennylane-qulacs) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane>=0.15->pennylane-qulacs) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit pennylane-qiskit"
      ],
      "metadata": {
        "id": "xISaHFcwvXLr",
        "outputId": "c509876a-0c85-4799-fc0f-43a84c7859e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.10/dist-packages (1.2.4)\n",
            "Requirement already satisfied: pennylane-qiskit in /usr/local/lib/python3.10/dist-packages (0.38.1)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.15.1)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.12.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.3.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit) (4.12.2)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.13.0)\n",
            "Requirement already satisfied: qiskit-aer in /usr/local/lib/python3.10/dist-packages (from pennylane-qiskit) (0.15.1)\n",
            "Requirement already satisfied: qiskit-ibm-runtime<=0.29 in /usr/local/lib/python3.10/dist-packages (from pennylane-qiskit) (0.29.0)\n",
            "Requirement already satisfied: qiskit-ibm-provider in /usr/local/lib/python3.10/dist-packages (from pennylane-qiskit) (0.11.0)\n",
            "Requirement already satisfied: pennylane>=0.38 in /usr/local/lib/python3.10/dist-packages (from pennylane-qiskit) (0.39.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from pennylane-qiskit) (3.4.2)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.38->pennylane-qiskit) (1.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.38->pennylane-qiskit) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.38->pennylane-qiskit) (1.4.4)\n",
            "Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.38->pennylane-qiskit) (0.7.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.38->pennylane-qiskit) (5.5.0)\n",
            "Requirement already satisfied: pennylane-lightning>=0.39 in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.38->pennylane-qiskit) (0.39.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.38->pennylane-qiskit) (2.32.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.38->pennylane-qiskit) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.16.0)\n",
            "Requirement already satisfied: requests-ntlm>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibm-runtime<=0.29->pennylane-qiskit) (1.3.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibm-runtime<=0.29->pennylane-qiskit) (2.2.3)\n",
            "Requirement already satisfied: websocket-client>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibm-runtime<=0.29->pennylane-qiskit) (1.8.0)\n",
            "Requirement already satisfied: ibm-platform-services>=0.22.6 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibm-runtime<=0.29->pennylane-qiskit) (0.59.0)\n",
            "Requirement already satisfied: pydantic>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibm-runtime<=0.29->pennylane-qiskit) (2.9.2)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit) (6.1.0)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer->pennylane-qiskit) (5.9.5)\n",
            "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibm-provider->pennylane-qiskit) (13.1)\n",
            "Requirement already satisfied: ibm-cloud-sdk-core<4.0.0,>=3.22.0 in /usr/local/lib/python3.10/dist-packages (from ibm-platform-services>=0.22.6->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (3.22.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.5.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane>=0.38->pennylane-qiskit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane>=0.38->pennylane-qiskit) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane>=0.38->pennylane-qiskit) (2024.8.30)\n",
            "Requirement already satisfied: cryptography>=1.3 in /usr/local/lib/python3.10/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (43.0.3)\n",
            "Requirement already satisfied: pyspnego>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (0.11.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (1.17.1)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from ibm-cloud-sdk-core<4.0.0,>=3.22.0->ibm-platform-services>=0.22.6->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (2.9.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-runtime<=0.29->pennylane-qiskit) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from qiskit_ibm_runtime import QiskitRuntimeService\n",
        "# from qiskit_ibm_provider import IBMProvider\n",
        "\n",
        "\n",
        "# IBMProvider.save_account(token='d4d5a9ed2d4b576b105b9476fd9d61b464bae4f7fc0d1e543e698e576f59f537ffbf3f97a26668e5840fd0b53ab5f84541e03529de75bf2297236b8b79873dff',\n",
        "#                          overwrite=True)\n",
        "# service = QiskitRuntimeService()\n",
        "# backend = service.backend(\"ibm_sherbrooke\")"
      ],
      "metadata": {
        "id": "Dkklh1VkvdOt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmjJoJyZkO5v",
        "outputId": "af2bb32b-6a1f-407a-8357-dcb97b5892a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('cpu',\n",
              " <LegacyDeviceFacade: <AerDevice device (wires=4, shots=1024) at 0x7f6b8d5f4280>>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "num_qubits = 4\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = \"cpu\"\n",
        "# dev = qml.device('qulacs.simulator', wires = range(num_qubits))\n",
        "# dev = qml.device(\"lightning.qubit\", wires=range(num_qubits))\n",
        "dev = qml.device('qiskit.aer', wires=range(num_qubits))\n",
        "device, dev"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import data, data preprocessing and analysis"
      ],
      "metadata": {
        "id": "wh5ts37oBzek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use \"Cyberbullying Classification\" dataset from Kaggle. You can acquire more information about the data by the following link: https://www.kaggle.com/datasets/andrewmvd/cyberbullying-classification/data"
      ],
      "metadata": {
        "id": "NZHah9RUDkV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EeV1dPx89I47",
        "outputId": "5236b2b4-70a3-4af1-c371-7a20fdcadd07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "PN22QbhmkO5v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "2ac497f8-4e27-46c0-af96-59ffd8c28fb8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'cyberbullying_tweets.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-5275f1b63bc0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cyberbullying_tweets.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cyberbullying_tweets.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('cyberbullying_tweets.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCNEZ-XakO5v"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={'tweet_text': 'text', 'cyberbullying_type': 'sentiment'})"
      ],
      "metadata": {
        "id": "92KibKseK0C7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "NoSlde7eLDdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define cleaning functions. Source: https://www.kaggle.com/code/ludovicocuoghi/detecting-bullying-tweets-pytorch-lstm-bert"
      ],
      "metadata": {
        "id": "PsXc6JwwCTMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean emojis from text\n",
        "def strip_emoji(text):\n",
        "    return emoji.get_emoji_regexp().sub(\"\", text)\n",
        "\n",
        "# Remove punctuations, stopwords, links, mentions and new line characters\n",
        "def strip_all_entities(text):\n",
        "    text = re.sub(r'\\r|\\n', ' ', text.lower())  # Replace newline and carriage return with space, and convert to lowercase\n",
        "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text)  # Remove links and mentions\n",
        "    text = re.sub(r'[^\\x00-\\x7f]', '', text)  # Remove non-ASCII characters\n",
        "    banned_list = string.punctuation\n",
        "    table = str.maketrans('', '', banned_list)\n",
        "    text = text.translate(table)\n",
        "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "    return text\n",
        "\n",
        "# Clean hashtags at the end of the sentence, and keep those in the middle of the sentence by removing just the # symbol\n",
        "def clean_hashtags(tweet):\n",
        "    # Remove hashtags at the end of the sentence\n",
        "    new_tweet = re.sub(r'(\\s+#[\\w-]+)+\\s*$', '', tweet).strip()\n",
        "\n",
        "    # Remove the # symbol from hashtags in the middle of the sentence\n",
        "    new_tweet = re.sub(r'#([\\w-]+)', r'\\1', new_tweet).strip()\n",
        "\n",
        "    return new_tweet\n",
        "\n",
        "# Filter special characters such as & and $ present in some words\n",
        "def filter_chars(text):\n",
        "    return ' '.join('' if ('$' in word) or ('&' in word) else word for word in text.split())\n",
        "\n",
        "# Remove multiple spaces\n",
        "def remove_mult_spaces(text):\n",
        "    return re.sub(r\"\\s\\s+\", \" \", text)\n",
        "\n",
        "# Function to check if the text is in English, and return an empty string if it's not\n",
        "def filter_non_english(text):\n",
        "    try:\n",
        "        lang = detect(text)\n",
        "    except LangDetectException:\n",
        "        lang = \"unknown\"\n",
        "    return text if lang == \"en\" else \"\"\n",
        "\n",
        "# Expand contractions\n",
        "def expand_contractions(text):\n",
        "    return contractions.fix(text)\n",
        "\n",
        "# Remove numbers\n",
        "def remove_numbers(text):\n",
        "    return re.sub(r'\\d+', '', text)\n",
        "\n",
        "# Lemmatize words\n",
        "def lemmatize(text):\n",
        "    words = word_tokenize(text)\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "# Remove short words\n",
        "def remove_short_words(text, min_len=2):\n",
        "    words = text.split()\n",
        "    long_words = [word for word in words if len(word) >= min_len]\n",
        "    return ' '.join(long_words)\n",
        "\n",
        "# Replace elongated words with their base form\n",
        "def replace_elongated_words(text):\n",
        "    regex_pattern = r'\\b(\\w+)((\\w)\\3{2,})(\\w*)\\b'\n",
        "    return re.sub(regex_pattern, r'\\1\\3\\4', text)\n",
        "\n",
        "# Remove repeated punctuation\n",
        "def remove_repeated_punctuation(text):\n",
        "    return re.sub(r'[\\?\\.\\!]+(?=[\\?\\.\\!])', '', text)\n",
        "\n",
        "# Remove extra whitespace\n",
        "def remove_extra_whitespace(text):\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "def remove_url_shorteners(text):\n",
        "    return re.sub(r'(?:http[s]?://)?(?:www\\.)?(?:bit\\.ly|goo\\.gl|t\\.co|tinyurl\\.com|tr\\.im|is\\.gd|cli\\.gs|u\\.nu|url\\.ie|tiny\\.cc|alturl\\.com|ow\\.ly|bit\\.do|adoro\\.to)\\S+', '', text)\n",
        "\n",
        "# Remove spaces at the beginning and end of the tweet\n",
        "def remove_spaces_tweets(tweet):\n",
        "    return tweet.strip()\n",
        "\n",
        "# Remove short tweets\n",
        "def remove_short_tweets(tweet, min_words=3):\n",
        "    words = tweet.split()\n",
        "    return tweet if len(words) >= min_words else \"\"\n",
        "\n",
        "# Function to call all the cleaning functions in the correct order\n",
        "def clean_tweet(tweet):\n",
        "    tweet = strip_emoji(tweet)\n",
        "    tweet = expand_contractions(tweet)\n",
        "    tweet = filter_non_english(tweet)\n",
        "    tweet = strip_all_entities(tweet)\n",
        "    tweet = clean_hashtags(tweet)\n",
        "    tweet = filter_chars(tweet)\n",
        "    tweet = remove_mult_spaces(tweet)\n",
        "    tweet = remove_numbers(tweet)\n",
        "    tweet = lemmatize(tweet)\n",
        "    tweet = remove_short_words(tweet)\n",
        "    tweet = replace_elongated_words(tweet)\n",
        "    tweet = remove_repeated_punctuation(tweet)\n",
        "    tweet = remove_extra_whitespace(tweet)\n",
        "    tweet = remove_url_shorteners(tweet)\n",
        "    tweet = remove_spaces_tweets(tweet)\n",
        "    tweet = remove_short_tweets(tweet)\n",
        "    tweet = ' '.join(tweet.split())  # Remove multiple spaces between words\n",
        "    return tweet"
      ],
      "metadata": {
        "id": "8RjOd2SaI8R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_clean'] = [clean_tweet(tweet) for tweet in df['text']]"
      ],
      "metadata": {
        "id": "ECncuUbvLAHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "RYNGL2_Uc4vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'There are around {int(df[\"text_clean\"].duplicated().sum())} duplicated tweets, we will remove them.')"
      ],
      "metadata": {
        "id": "Eh56r73aewhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(\"text_clean\", inplace=True)"
      ],
      "metadata": {
        "id": "LNlO3hdhez4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sentiment.value_counts()"
      ],
      "metadata": {
        "id": "LGEU8XC9e3Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, after cleaning classes are unbalanced so we will drop \"other_cyberbullying\" class as there is not enough data. Later we will oversample \"not_cyberbullying\" class."
      ],
      "metadata": {
        "id": "8qZ7PoaKC808"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df[\"sentiment\"]!=\"other_cyberbullying\"]"
      ],
      "metadata": {
        "id": "i-4tp2O8e-zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_len'] = [len(text.split()) for text in df.text_clean]"
      ],
      "metadata": {
        "id": "Q712dE4kftOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "ax = sns.countplot(x='text_len', data=df[df['text_len']<10], palette='mako')\n",
        "plt.title('Count of tweets with less than 10 words', fontsize=20)\n",
        "plt.yticks([])\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.ylabel('count')\n",
        "plt.xlabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WQjmvAMHfyG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,5))\n",
        "ax = sns.countplot(x='text_len', data=df[(df['text_len']<=1000) & (df['text_len']>10)], palette='Blues_r')\n",
        "plt.title('Count of tweets with high number of words', fontsize=25)\n",
        "plt.yticks([])\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.ylabel('count')\n",
        "plt.xlabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ir99Mjatf7Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['text_len'] < df['text_len'].quantile(0.995)]"
      ],
      "metadata": {
        "id": "Yx4uFQtBgNf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = np.max(df['text_len'])\n",
        "max_len"
      ],
      "metadata": {
        "id": "sv5RTF8ggS7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'] = df['sentiment'].replace({'religion':0,'age':1,'ethnicity':2,'gender':3,'not_cyberbullying':4})"
      ],
      "metadata": {
        "id": "QSjqH8-0gs9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text tokenization"
      ],
      "metadata": {
        "id": "oSjlhVvdEqEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Tokenize(column, seq_len):\n",
        "    ##Create vocabulary of words from column\n",
        "    corpus = [word for text in column for word in text.split()]\n",
        "    count_words = Counter(corpus)\n",
        "    sorted_words = count_words.most_common()\n",
        "    vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n",
        "\n",
        "    ##Tokenize the columns text using the vocabulary\n",
        "    text_int = []\n",
        "    for text in column:\n",
        "        r = [vocab_to_int[word] for word in text.split()]\n",
        "        text_int.append(r)\n",
        "    ##Add padding to tokens\n",
        "    features = np.zeros((len(text_int), seq_len), dtype = int)\n",
        "    for i, review in enumerate(text_int):\n",
        "        if len(review) <= seq_len:\n",
        "            zeros = list(np.zeros(seq_len - len(review)))\n",
        "            new = zeros + review\n",
        "        else:\n",
        "            new = review[: seq_len]\n",
        "        features[i, :] = np.array(new)\n",
        "\n",
        "    return sorted_words, features"
      ],
      "metadata": {
        "id": "nPIz-dF6kFEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary, tokenized_column = Tokenize(df[\"text_clean\"], max_len)"
      ],
      "metadata": {
        "id": "KqUTb1b8kd9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text_clean']\n",
        "y = df['sentiment']"
      ],
      "metadata": {
        "id": "d02_zwPL-9EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "2azevoNY-y6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text embedding with pre-trained Word2vec model"
      ],
      "metadata": {
        "id": "idKd2ISaEy9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Word2vec_train_data = list(map(lambda x: x.split(), X_train))"
      ],
      "metadata": {
        "id": "_TdbROTk7nYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 200"
      ],
      "metadata": {
        "id": "EefOe-5Y7rSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = Word2Vec(Word2vec_train_data, vector_size=EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "fSmBTU0Y7vMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(vocabulary) + 1 #+1 for the padding"
      ],
      "metadata": {
        "id": "IZyohOul7yPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an empty embedding matrix of shape (VOCAB_SIZE, EMBEDDING_DIM)\n",
        "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
        "\n",
        "# Fill the embedding matrix with pre-trained values from word2vec\n",
        "for word, token in vocabulary:\n",
        "    # Check if the word is present in the word2vec model's vocabulary\n",
        "    if word in word2vec_model.wv.key_to_index:\n",
        "        # If the word is present, retrieve its embedding vector and add it to the embedding matrix\n",
        "        embedding_vector = word2vec_model.wv[word]\n",
        "        embedding_matrix[token] = embedding_vector\n",
        "\n",
        "# Print the shape of the embedding matrix\n",
        "print(\"Embedding Matrix Shape:\", embedding_matrix.shape)"
      ],
      "metadata": {
        "id": "nx5AIcgi68QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tokenized_column\n",
        "y = df['sentiment'].values"
      ],
      "metadata": {
        "id": "tfO4cnjz7_Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "EOAc1Vm38Njv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oversampling"
      ],
      "metadata": {
        "id": "Ly-3aQBnFRcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler()\n",
        "X_train_os, y_train_os = ros.fit_resample(np.array(X_train),np.array(y_train))"
      ],
      "metadata": {
        "id": "achdE0dQ8WEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_os.shape"
      ],
      "metadata": {
        "id": "sac738LjIWXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we define our preprocessed dataset and loaders"
      ],
      "metadata": {
        "id": "dGYWBOQ0FW2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(torch.from_numpy(X_train_os), torch.from_numpy(y_train_os))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))"
      ],
      "metadata": {
        "id": "jyEGOm9Z8ffa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "WjpbNrLb8jN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE, drop_last=True)"
      ],
      "metadata": {
        "id": "mr-o8hPq8lXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of the classical model"
      ],
      "metadata": {
        "id": "g2V1uSsNFp3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this paragraph we will implement model with classical convolution and LSTM in order to compare it with its hybrid-quantum analogue"
      ],
      "metadata": {
        "id": "660eM2fEF30E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        # The attention linear layer which transforms the input data to the hidden space\n",
        "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim )\n",
        "        # The linear layer that calculates the attention scores\n",
        "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        seq_len = encoder_outputs.size(1)\n",
        "        # Concatenate the last two hidden states in case of a bidirectional LSTM\n",
        "        hidden = hidden[-1]\n",
        "        # Repeat the hidden state across the sequence length\n",
        "        hidden_repeated = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
        "        # Calculate attention weights\n",
        "        attn_weights = torch.tanh(self.attn(torch.cat((hidden_repeated, encoder_outputs), dim=2)))\n",
        "        # Compute attention scores\n",
        "        attn_weights = self.v(attn_weights).squeeze(2)\n",
        "        # Apply softmax to get valid probabilities\n",
        "        return nn.functional.softmax(attn_weights, dim=1)"
      ],
      "metadata": {
        "id": "-VTp5AVlJA3l"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassicalModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, in_channels, out_channels, kernel_size, stride, padding, hidden_dim, num_classes, lstm_layers):\n",
        "        super(ClassicalModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = lstm_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, lstm_layers, batch_first=True)\n",
        "        self.attention = Attention(hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # Transform words to embeddings\n",
        "        embedded = self.embedding(x)\n",
        "        # embedded = self.conv(embedded.unsqueeze(1))\n",
        "        # # Pass embeddings to LSTM\n",
        "        # out, hidden = self.lstm(embedded.reshape(-1, embedded.size(1)*embedded.size(2), embedded.size(-1)), hidden)\n",
        "        out, hidden = self.lstm(embedded, hidden)\n",
        "        # Calculate attention weights\n",
        "        attn_weights = self.attention(hidden[0], out)\n",
        "        # Calculate context vector by taking the weighted sum of LSTM outputs\n",
        "        context = attn_weights.unsqueeze(1).bmm(out).squeeze(1)\n",
        "        # Classify the context vector\n",
        "        out = self.softmax(self.fc(context))\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
        "        return h0, c0"
      ],
      "metadata": {
        "id": "raK4JVSHExXS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of the hybrid-quantum model"
      ],
      "metadata": {
        "id": "iFolBcU3GjzL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Zx9MSDbdkO5y"
      },
      "outputs": [],
      "source": [
        "# @qml.qnode(dev, interface='torch')\n",
        "# def quanvcirc(patch, weights, wires=range(num_qubits)):\n",
        "#     # Angle embedding of the patch (reshape to match expected size)\n",
        "#     qml.AngleEmbedding(patch, wires=wires, rotation='Y')\n",
        "\n",
        "#     # Apply RX rotations based on the weights\n",
        "#     qml.RX(weights[0][0], wires=0)\n",
        "#     qml.RX(weights[0][1], wires=1)\n",
        "#     qml.RY(weights[1][0], wires=2)\n",
        "#     qml.RY(weights[1][1], wires=3)\n",
        "\n",
        "#     # Apply CNOT gates\n",
        "#     qml.CNOT(wires=[0, 1])\n",
        "#     qml.CNOT(wires=[1, 2])\n",
        "#     qml.CNOT(wires=[2, 3])\n",
        "#     qml.CNOT(wires=[3, 0])\n",
        "#     # Apply RY rotations based on the weights\n",
        "\n",
        "\n",
        "#     # Return the expectation values of Pauli-Z measurements on all qubits\n",
        "#     return qml.expval(qml.PauliZ(0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(qml.draw(quanvcirc)(np.ones((1, 4)), np.ones((2, 2))))"
      ],
      "metadata": {
        "id": "_G1L7z_enlfZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class QuanConv2D(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "#         super(QuanConv2D, self).__init__()\n",
        "#         self.in_channels = in_channels\n",
        "#         self.out_channels = out_channels\n",
        "#         self.kernel_size = kernel_size\n",
        "#         self.stride = stride\n",
        "#         self.padding = padding\n",
        "\n",
        "#         # Define weights and biases as trainable parameters\n",
        "#         self.weights = nn.Parameter(\n",
        "#             torch.randn(out_channels, in_channels, kernel_size, kernel_size), requires_grad = True\n",
        "#         )\n",
        "\n",
        "#     def forward(self, input):\n",
        "#         # Extract dimensions\n",
        "#         batch_size, in_channels, input_height, input_width = input.shape\n",
        "\n",
        "#         # Calculate output dimensions\n",
        "#         output_height = (input_height - self.kernel_size + 2 * self.padding) // self.stride + 1\n",
        "#         output_width = (input_width - self.kernel_size + 2 * self.padding) // self.stride + 1\n",
        "\n",
        "#         # Initialize output tensor\n",
        "#         output = torch.zeros(batch_size, self.out_channels, output_height, output_width)\n",
        "\n",
        "#         # If padding is required, add it to the input\n",
        "#         if self.padding > 0:\n",
        "#             input = F.pad(input, (self.padding, self.padding, self.padding, self.padding))\n",
        "\n",
        "#         # Perform convolution\n",
        "#         for b in range(batch_size):\n",
        "#             for c_out in range(self.out_channels):\n",
        "#                 for h in range(output_height):\n",
        "#                     for w in range(output_width):\n",
        "#                         h_start = h * self.stride\n",
        "#                         h_end = h_start + self.kernel_size\n",
        "#                         w_start = w * self.stride\n",
        "#                         w_end = w_start + self.kernel_size\n",
        "\n",
        "#                         # Slice the input for the current window\n",
        "#                         input_slice = input[b, :, h_start:h_end, w_start:w_end]\n",
        "\n",
        "#                         # Perform element-wise multiplication and sum with bias\n",
        "#                         output[b, c_out, h, w] = quanvcirc(input_slice.reshape(1, self.kernel_size * self.kernel_size), self.weights[c_out].squeeze(0))\n",
        "#         return output"
      ],
      "metadata": {
        "id": "ikYNnTA1pr6A"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qdi_reps1 = 2\n",
        "qdi_reps2 = 2\n",
        "qdi_depth = 1"
      ],
      "metadata": {
        "id": "ZXzmC0KuyEDb"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@qml.qnode(dev, interface='torch')\n",
        "def qdi_circuit(weights, input_array, wires=range(num_qubits)):\n",
        "    for r in range(qdi_reps1):\n",
        "        for i in range(len(wires)):\n",
        "            qml.RX(weights[r][i], wires=wires[i])\n",
        "        for j in range(len(wires)-1):\n",
        "            qml.CNOT(wires=[wires[j], wires[j+1]])\n",
        "        qml.CNOT(wires=[wires[len(wires)-1], wires[0]])\n",
        "        # qml.Barrier()\n",
        "    for d in range(qdi_depth):\n",
        "        qml.AngleEmbedding(input_array, wires=range(num_qubits), rotation='Z')\n",
        "        for r in range(qdi_reps2):\n",
        "            for i in range(len(wires)):\n",
        "                qml.RX(weights[qdi_reps1+d*r][i], wires=wires[i])\n",
        "            for j in range(len(wires)-1):\n",
        "                qml.CNOT(wires=[wires[j], wires[j+1]])\n",
        "            qml.CNOT(wires=[wires[len(wires)-1], wires[0]])\n",
        "            # qml.Barrier()\n",
        "        # qml.Barrier()\n",
        "    return [qml.expval(qml.PauliY(w)) for w in wires]"
      ],
      "metadata": {
        "id": "QixHflZxxt-Y"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(qml.draw(qdi_circuit)(np.ones((qdi_reps1 + qdi_reps2, num_qubits)), np.ones((4, 4))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRFx50H6RkcR",
        "outputId": "9a3a0437-abd5-47a9-cb3d-e1b86d057856"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: RX(1.00)XRX(1.00)XAngleEmbedding(M0)RX(1.00)XRX(1.00)\n",
            "1: RX(1.00)XRX(1.00)XAngleEmbedding(M0)RX(1.00)XRX(1.00)\n",
            "2: RX(1.00)XRX(1.00)XAngleEmbedding(M0)RX(1.00)XRX(1.00)\n",
            "3: RX(1.00)XRX(1.00)XAngleEmbedding(M0)RX(1.00)XRX(1.00)\n",
            "\n",
            "X  <Y>\n",
            "X  <Y>\n",
            "X  <Y>\n",
            "X  <Y>\n",
            "\n",
            "M0 = \n",
            "[[1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qdi_circuit(np.ones((qdi_reps1 + qdi_reps2, num_qubits)), np.ones((4, 4)))"
      ],
      "metadata": {
        "id": "xyeMgfRs6p5_",
        "outputId": "87f0d57d-86d9-45ff-a1ce-e3aa69f2f44e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([-0.1484, -0.0703, -0.0410, -0.1094], dtype=torch.float64),\n",
              " tensor([-0.1035, -0.0391, -0.0293, -0.0508], dtype=torch.float64),\n",
              " tensor([0.1055, 0.1426, 0.1836, 0.1387], dtype=torch.float64),\n",
              " tensor([0.2676, 0.2617, 0.2441, 0.2090], dtype=torch.float64)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HQLSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_qubits):\n",
        "        super(HQLSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Combined weights for efficiency\n",
        "        self.W_input = nn.Parameter(torch.rand(4 * num_qubits, input_size), requires_grad = True).float()\n",
        "        self.W_hid = nn.Parameter(torch.rand(4 * num_qubits, hidden_size), requires_grad = True).float()\n",
        "        self.W_quan = nn.Parameter(torch.zeros(4, qdi_reps1 + qdi_reps2, num_qubits), requires_grad = True).float()\n",
        "        self.W = nn.Parameter(torch.rand(4, hidden_size, num_qubits), requires_grad = True).float()\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        h_prev, c_prev = hidden\n",
        "\n",
        "        yield_input = F.linear(x, self.W_input)\n",
        "        yield_hidden = F.linear(h_prev, self.W_hid)\n",
        "        # Concatenate input and previous hidden state\n",
        "        combined = yield_input + yield_hidden\n",
        "        # combined = torch.cat((yield_input, yield_hidden), dim=1)\n",
        "\n",
        "        # Apply linear transformation\n",
        "\n",
        "        # Split into gates\n",
        "        # combined = torch.cat([torch.stack(qdi_circuit(self.W_quan[i], combined[:, i:i*num_qubits].reshape(-1, num_qubits))) for i in range(num_qubits)], dim = 0)\n",
        "        i_gate = F.linear(torch.stack(qdi_circuit(self.W_quan[0], combined[:, :num_qubits].reshape(-1, num_qubits)))[:, :, :4].T.float(), self.W[0])\n",
        "        f_gate = F.linear(torch.stack(qdi_circuit(self.W_quan[1], combined[:, num_qubits:2*num_qubits].reshape(-1, num_qubits)))[:, :, :4].T.float(), self.W[1])\n",
        "        g_gate = F.linear(torch.stack(qdi_circuit(self.W_quan[2], combined[:, 2*num_qubits:3*num_qubits].reshape(-1, num_qubits)))[:, :, :4].T.float(), self.W[2])\n",
        "        o_gate = F.linear(torch.stack(qdi_circuit(self.W_quan[3], combined[:, 3*num_qubits:4*num_qubits].reshape(-1, num_qubits)))[:, :, :4].T.float(), self.W[3])\n",
        "\n",
        "\n",
        "\n",
        "        # combined = torch.cat((i_gate, f_gate, g_gate, o_gate), dim=0).float()\n",
        "        # gates = F.linear(combined, self.W)\n",
        "\n",
        "        # # Split into gates\n",
        "        # i_gate, f_gate, g_gate, o_gate = gates.chunk(4, 0)\n",
        "\n",
        "        # Apply non-linearities\n",
        "        i_gate = torch.sigmoid(i_gate)\n",
        "        f_gate = torch.sigmoid(f_gate)\n",
        "        g_gate = torch.tanh(g_gate)\n",
        "        o_gate = torch.sigmoid(o_gate)\n",
        "\n",
        "        # Update cell state\n",
        "        c_next = (f_gate * c_prev) + (i_gate * g_gate)\n",
        "\n",
        "        # Update hidden state\n",
        "        h_next = o_gate * torch.tanh(c_next)\n",
        "\n",
        "        return h_next, c_next\n",
        "\n",
        "\n",
        "class HQLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_qubits, num_layers=1):\n",
        "        super(HQLSTM, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm_cells = nn.ModuleList([HQLSTMCell(input_size if l==0 else hidden_size, hidden_size, num_qubits) for l in range(num_layers)])\n",
        "\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        if hidden is None:\n",
        "             h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "             c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "        else:\n",
        "            h0, c0 = hidden\n",
        "\n",
        "        output_seq = []\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            input_t = x[:, t, :] # input at current timestep\n",
        "            # print(f'step:{t}/{seq_len}, hidden:')\n",
        "\n",
        "            new_h = []\n",
        "            new_c = []\n",
        "\n",
        "            for layer in range(self.num_layers):\n",
        "\n",
        "                # Get hidden state for current layer\n",
        "                h_t, c_t = self.lstm_cells[layer](input_t, (h0[layer], c0[layer]))\n",
        "\n",
        "                # Update hidden states for next timestep, for current layer\n",
        "                new_h.append(h_t)\n",
        "                new_c.append(c_t)\n",
        "                input_t = h_t # The output of current layer is input for the next\n",
        "\n",
        "            h0 = torch.stack(new_h)\n",
        "            c0 = torch.stack(new_c)\n",
        "            # Append hidden state at the topmost layer\n",
        "            output_seq.append(h_t.unsqueeze(1))\n",
        "\n",
        "        # Concatenate the outputs over the sequence length\n",
        "        output_seq = torch.cat(output_seq, dim=1) # output_seq is of shape (batch_size, seq_len, hidden_size)\n",
        "\n",
        "        return output_seq, (h0, c0)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "v_mvdRnDqcze"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Toy hybrid-quantum model for benchmarking"
      ],
      "metadata": {
        "id": "py3iiomANCjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ToyHQModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, in_channels, out_channels, kernel_size, stride, padding, hidden_dim, num_qubits, num_classes, lstm_layers):\n",
        "        super(ToyHQModel, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.num_layers = lstm_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.attention = Attention(hidden_dim)\n",
        "        # self.conv = QuanConv2D(self.in_channels, self.out_channels, self.kernel_size, self.stride, self.padding)\n",
        "        self.lstm = HQLSTM(embedding_dim, hidden_dim, num_qubits, lstm_layers)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Transform words to embeddings\n",
        "        embedded = self.embedding(x)\n",
        "        # x = self.conv(x.unsqueeze(1)).to(device)\n",
        "        # Pass embeddings to LSTM\n",
        "        out, hidden = self.lstm(embedded)\n",
        "        # Calculate attention weights\n",
        "        attn_weights = self.attention(hidden[0], out)\n",
        "        # Calculate context vector by taking the weighted sum of LSTM outputs\n",
        "        context = attn_weights.unsqueeze(1).bmm(out).squeeze(1)\n",
        "        # Classify the context vector\n",
        "        out = self.softmax(self.fc(context))\n",
        "        return out\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
        "        return h0, c0"
      ],
      "metadata": {
        "id": "RRz02NuCLNvM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridQuantumModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, in_channels, out_channels, kernel_size, stride, padding, hidden_dim, num_qubits, num_classes, lstm_layers):\n",
        "        super(HybridQuantumModel, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = HQLSTM(embedding_dim, hidden_dim, num_qubits, lstm_layers)\n",
        "        self.attention = Attention(hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Transform words to embeddings\n",
        "        embedded = self.embedding(x)\n",
        "        # embedded = self.conv(embedded.unsqueeze(1)).to(device)\n",
        "        # Pass embeddings to LSTM\n",
        "        # out, hidden = self.lstm(embedded.reshape(-1, embedded.size(1)*embedded.size(2), embedded.size(-1)))\n",
        "        out, hidden = self.lstm(embedded)\n",
        "        # Calculate attention weights\n",
        "        attn_weights = self.attention(hidden[0], out)\n",
        "        # Calculate context vector by taking the weighted sum of LSTM outputs\n",
        "        context = attn_weights.unsqueeze(1).bmm(out).squeeze(1)\n",
        "        # Classify the context vector\n",
        "        out = self.softmax(self.fc(context))\n",
        "        return out"
      ],
      "metadata": {
        "id": "0V4YMT0JN6Sy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the models"
      ],
      "metadata": {
        "id": "uvla_k_6IWAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 5 #We are dealing with a multiclass classification of 5 classes\n",
        "HIDDEN_DIM = 100 #number of neurons of the internal state (internal neural network in the LSTM)\n",
        "LSTM_LAYERS = 1 #Number of stacked LSTM layers\n",
        "IN_CHANNELS = 1\n",
        "OUT_CHANNELS = 5\n",
        "KERNEL_SIZE = 2\n",
        "STRIDE = 1\n",
        "PADDING = 1\n",
        "\n",
        "\n",
        "LR = 8e-4 #Learning rate\n",
        "EPOCHS = 10 #Number of training epoch\n",
        "\n",
        "criterion = nn.NLLLoss()"
      ],
      "metadata": {
        "id": "bbH3jVkhSWCr"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classical_model = ClassicalModel(VOCAB_SIZE, EMBEDDING_DIM, IN_CHANNELS, OUT_CHANNELS, KERNEL_SIZE, STRIDE, PADDING, HIDDEN_DIM, NUM_CLASSES, LSTM_LAYERS)\n",
        "classical_model = classical_model.to(device)\n",
        "# classical_model = torch.compile(classical_model)\n",
        "\n",
        "cl_optimizer = torch.optim.AdamW(classical_model.parameters(), lr=LR, weight_decay = 5e-6)\n",
        "\n",
        "print(classical_model)"
      ],
      "metadata": {
        "id": "lJnLZ5GCMMNF",
        "outputId": "86871e0d-133f-4650-b9aa-77be4a5acae8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClassicalModel(\n",
            "  (embedding): Embedding(37575, 200)\n",
            "  (conv): Conv2d(1, 5, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "  (lstm): LSTM(200, 100, batch_first=True)\n",
            "  (attention): Attention(\n",
            "    (attn): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (v): Linear(in_features=100, out_features=1, bias=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(model):\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'embedding' in name:\n",
        "            nn.init.uniform_(param, -0.1, 0.1)\n",
        "        elif 'lstm' in name:\n",
        "            if 'weight' in name:\n",
        "                nn.init.orthogonal_(param)\n",
        "            elif 'bias' in name:\n",
        "                nn.init.constant_(param, 0)\n",
        "        elif 'fc' in name:\n",
        "            nn.init.xavier_uniform_(param)"
      ],
      "metadata": {
        "id": "vWLWMuTwu-ZR"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hybrid_quantum_model = HybridQuantumModel(VOCAB_SIZE, EMBEDDING_DIM, IN_CHANNELS, OUT_CHANNELS, KERNEL_SIZE, STRIDE, PADDING, HIDDEN_DIM, num_qubits, NUM_CLASSES, LSTM_LAYERS)\n",
        "hybrid_quantum_model = hybrid_quantum_model.to(device)\n",
        "# initialize_weights(hybrid_quantum_model)\n",
        "\n",
        "\n",
        "# hybrid_quantum_model = torch.compile(hybrid_quantum_model)\n",
        "\n",
        "hq_optimizer = torch.optim.AdamW(hybrid_quantum_model.parameters(), lr=LR, weight_decay = 5e-6)\n",
        "\n",
        "print(hybrid_quantum_model)"
      ],
      "metadata": {
        "id": "_yVpeUhBSeXi",
        "outputId": "e9c1fb4e-83f6-4bbf-9133-4597a65f30a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HybridQuantumModel(\n",
            "  (embedding): Embedding(37575, 200)\n",
            "  (lstm): HQLSTM(\n",
            "    (lstm_cells): ModuleList(\n",
            "      (0): HQLSTMCell()\n",
            "    )\n",
            "  )\n",
            "  (attention): Attention(\n",
            "    (attn): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (v): Linear(in_features=100, out_features=1, bias=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "ObgTsuW6kO5z"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train(model, criterion, optimizer,\n",
        "          train_dataloader, test_dataloader, num_epochs):\n",
        "\n",
        "    train_losses = np.zeros(num_epochs)\n",
        "    test_losses = np.zeros(num_epochs)\n",
        "\n",
        "    train_accuracy_arr = np.zeros(num_epochs)\n",
        "    test_accuracy_arr = np.zeros(num_epochs)\n",
        "\n",
        "    for i_epoch in tqdm(range(num_epochs)):\n",
        "        it = 0\n",
        "        train_loss = 0\n",
        "        test_loss = 0\n",
        "\n",
        "        train_accuracy = 0\n",
        "        test_accuracy = 0\n",
        "\n",
        "        # train step\n",
        "        model.train()\n",
        "        for batch in train_dataloader:\n",
        "            start_time = time.time()\n",
        "            X = batch[0].to(device)\n",
        "            y = batch[1].to(device)\n",
        "\n",
        "            h = model.init_hidden(y.size(0))\n",
        "            # model forward-pass\n",
        "            preds, h = model(X, h)\n",
        "\n",
        "            # model backward-pass\n",
        "            optimizer.zero_grad() # t.grad = torch.tensor([0., 0., 0.])\n",
        "            loss = criterion(preds, y)\n",
        "            loss.backward()\n",
        "            optimizer.step() # t = t - lr * t.grad\n",
        "            end_time = time.time()\n",
        "            execution_time = end_time - start_time\n",
        "\n",
        "            # save loss and accuracy\n",
        "            train_loss += loss.detach().cpu().numpy()\n",
        "            print(f'batch: {it+1}/{len(train_dataloader)}, loss: {train_loss/(it+1):.4f}, time: {execution_time:.4f}')\n",
        "            it += 1\n",
        "            train_accuracy += (preds.argmax(-1).detach() == y).cpu().numpy().mean()\n",
        "\n",
        "\n",
        "        train_loss /= len(train_dataloader)\n",
        "        train_accuracy /= len(train_dataloader)\n",
        "        train_losses[i_epoch] = train_loss\n",
        "        train_accuracy_arr[i_epoch] = train_accuracy\n",
        "\n",
        "        # test step\n",
        "        model.eval()\n",
        "        for batch in test_dataloader:\n",
        "            X = batch[0].to(device)\n",
        "            y = batch[1].to(device)\n",
        "\n",
        "            h = model.init_hidden(y.size(0))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # model forward-pass\n",
        "                preds, h = model(X, h)\n",
        "                loss = criterion(preds, y)\n",
        "\n",
        "                # save loss and accuracy\n",
        "                test_loss += loss.detach().cpu().numpy()\n",
        "                test_accuracy += (preds.argmax(-1) == y).cpu().numpy().mean()\n",
        "\n",
        "\n",
        "        test_loss /= len(test_dataloader)\n",
        "        test_accuracy /= len(test_dataloader)\n",
        "\n",
        "        test_losses[i_epoch] = test_loss\n",
        "        test_accuracy_arr[i_epoch] = test_accuracy\n",
        "\n",
        "    return train_losses, test_losses, train_accuracy_arr, test_accuracy_arr\n",
        "\n",
        "def train_for_hqnn(model, criterion, optimizer,\n",
        "          train_dataloader, test_dataloader, num_epochs):\n",
        "\n",
        "    train_losses = np.zeros(num_epochs)\n",
        "    test_losses = np.zeros(num_epochs)\n",
        "\n",
        "    train_accuracy_arr = np.zeros(num_epochs)\n",
        "    test_accuracy_arr = np.zeros(num_epochs)\n",
        "\n",
        "    for i_epoch in tqdm(range(num_epochs)):\n",
        "        it = 0\n",
        "\n",
        "        train_loss = 0\n",
        "        test_loss = 0\n",
        "\n",
        "        train_accuracy = 0\n",
        "        test_accuracy = 0\n",
        "\n",
        "        # train step\n",
        "        model.train()\n",
        "        for batch in train_dataloader:\n",
        "            start_time = time.time()\n",
        "            X = batch[0].to(device)\n",
        "            y = batch[1].to(device)\n",
        "\n",
        "            # model forward-pass\n",
        "            preds = model(X)\n",
        "\n",
        "            # model backward-pass\n",
        "            optimizer.zero_grad() # t.grad = torch.tensor([0., 0., 0.])\n",
        "            loss = criterion(preds, y)\n",
        "            loss.backward()\n",
        "            optimizer.step() # t = t - lr * t.grad\n",
        "            end_time = time.time()\n",
        "            execution_time = end_time - start_time\n",
        "\n",
        "            # save loss and accuracy\n",
        "            train_loss += loss.detach().cpu().numpy()\n",
        "            print(f'it: {it+1}/{len(train_dataloader)}, loss: {train_loss/(it+1):.4f}, time: {execution_time:.4f}')\n",
        "            it += 1\n",
        "            train_accuracy += (preds.argmax(-1).detach() == y).cpu().numpy().mean()\n",
        "\n",
        "\n",
        "        train_loss /= len(train_dataloader)\n",
        "        train_accuracy /= len(train_dataloader)\n",
        "        train_losses[i_epoch] = train_loss\n",
        "\n",
        "        train_accuracy_arr[i_epoch] = train_accuracy\n",
        "\n",
        "        # test step\n",
        "        model.eval()\n",
        "        for batch in test_dataloader:\n",
        "            X = batch[0].to(device)\n",
        "            y = batch[1].to(device)\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # model forward-pass\n",
        "                preds = model(X)\n",
        "                loss = criterion(preds, y)\n",
        "\n",
        "                # save loss and accuracy\n",
        "                test_loss += loss.detach().cpu().numpy()\n",
        "                test_accuracy += (preds.argmax(-1) == y).cpu().numpy().mean()\n",
        "\n",
        "\n",
        "        test_loss /= len(test_dataloader)\n",
        "        test_accuracy /= len(test_dataloader)\n",
        "\n",
        "        test_losses[i_epoch] = test_loss\n",
        "        test_accuracy_arr[i_epoch] = test_accuracy\n",
        "\n",
        "    return train_losses, test_losses, train_accuracy_arr, test_accuracy_arr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cl_train_losses, \\\n",
        "    cl_test_losses, \\\n",
        "    cl_train_accuracy_arr, \\\n",
        "    cl_test_accuracy_arr = train(classical_model, criterion=criterion,\n",
        "                              optimizer=cl_optimizer,\n",
        "                              train_dataloader=train_loader,\n",
        "                              test_dataloader=test_loader,\n",
        "                              num_epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "661cd90b76c9451f98e0ca29c4b22d44",
            "d702bf265eca4bbbbcb7a358df381c65",
            "fc30a6a4b6064be0b3c4a786a4b64952",
            "df78c6ab42474534a547a0a7ba44b754",
            "d49849d9283546c9b34517f327232757",
            "8562c9e4bc8443db82350ff5f496958b",
            "e17bf6667ccd4167af9110a09ba012ac",
            "60ed458c82de4401a7eb400c23f1338d",
            "673f3f8df9244b538ad88f1fc82442b6",
            "029421ef2fec489b8b379351e00e188a",
            "98cad26d7f274b71a04d37fca89196bf"
          ]
        },
        "id": "1swJ9EmxZKAT",
        "outputId": "17589abb-15b9-4765-8297-2967fc10a0b5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "661cd90b76c9451f98e0ca29c4b22d44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch: 1/979, loss: 1.6025, time: 0.1276\n",
            "batch: 2/979, loss: 1.5963, time: 0.0033\n",
            "batch: 3/979, loss: 1.5963, time: 0.0028\n",
            "batch: 4/979, loss: 1.5950, time: 0.0028\n",
            "batch: 5/979, loss: 1.5930, time: 0.0028\n",
            "batch: 6/979, loss: 1.6064, time: 0.0027\n",
            "batch: 7/979, loss: 1.6050, time: 0.0026\n",
            "batch: 8/979, loss: 1.6055, time: 0.0027\n",
            "batch: 9/979, loss: 1.5994, time: 0.0027\n",
            "batch: 10/979, loss: 1.5931, time: 0.0027\n",
            "batch: 11/979, loss: 1.5954, time: 0.0028\n",
            "batch: 12/979, loss: 1.5932, time: 0.0027\n",
            "batch: 13/979, loss: 1.5869, time: 0.0026\n",
            "batch: 14/979, loss: 1.5778, time: 0.0028\n",
            "batch: 15/979, loss: 1.5739, time: 0.0027\n",
            "batch: 16/979, loss: 1.5638, time: 0.0028\n",
            "batch: 17/979, loss: 1.5614, time: 0.0027\n",
            "batch: 18/979, loss: 1.5603, time: 0.0027\n",
            "batch: 19/979, loss: 1.5515, time: 0.0026\n",
            "batch: 20/979, loss: 1.5483, time: 0.0028\n",
            "batch: 21/979, loss: 1.5448, time: 0.0031\n",
            "batch: 22/979, loss: 1.5425, time: 0.0028\n",
            "batch: 23/979, loss: 1.5357, time: 0.0027\n",
            "batch: 24/979, loss: 1.5311, time: 0.0026\n",
            "batch: 25/979, loss: 1.5261, time: 0.0027\n",
            "batch: 26/979, loss: 1.5210, time: 0.0027\n",
            "batch: 27/979, loss: 1.5169, time: 0.0027\n",
            "batch: 28/979, loss: 1.5111, time: 0.0027\n",
            "batch: 29/979, loss: 1.5037, time: 0.0026\n",
            "batch: 30/979, loss: 1.4953, time: 0.0028\n",
            "batch: 31/979, loss: 1.4872, time: 0.0027\n",
            "batch: 32/979, loss: 1.4800, time: 0.0027\n",
            "batch: 33/979, loss: 1.4757, time: 0.0028\n",
            "batch: 34/979, loss: 1.4675, time: 0.0050\n",
            "batch: 35/979, loss: 1.4622, time: 0.0027\n",
            "batch: 36/979, loss: 1.4502, time: 0.0027\n",
            "batch: 37/979, loss: 1.4417, time: 0.0026\n",
            "batch: 38/979, loss: 1.4324, time: 0.0034\n",
            "batch: 39/979, loss: 1.4227, time: 0.0034\n",
            "batch: 40/979, loss: 1.4134, time: 0.0032\n",
            "batch: 41/979, loss: 1.4031, time: 0.0035\n",
            "batch: 42/979, loss: 1.3898, time: 0.0034\n",
            "batch: 43/979, loss: 1.3809, time: 0.0035\n",
            "batch: 44/979, loss: 1.3737, time: 0.0033\n",
            "batch: 45/979, loss: 1.3659, time: 0.0034\n",
            "batch: 46/979, loss: 1.3552, time: 0.0040\n",
            "batch: 47/979, loss: 1.3413, time: 0.0083\n",
            "batch: 48/979, loss: 1.3294, time: 0.0049\n",
            "batch: 49/979, loss: 1.3169, time: 0.0045\n",
            "batch: 50/979, loss: 1.3051, time: 0.0048\n",
            "batch: 51/979, loss: 1.2962, time: 0.0046\n",
            "batch: 52/979, loss: 1.2894, time: 0.0036\n",
            "batch: 53/979, loss: 1.2802, time: 0.0059\n",
            "batch: 54/979, loss: 1.2701, time: 0.0037\n",
            "batch: 55/979, loss: 1.2620, time: 0.0035\n",
            "batch: 56/979, loss: 1.2543, time: 0.0040\n",
            "batch: 57/979, loss: 1.2448, time: 0.0035\n",
            "batch: 58/979, loss: 1.2332, time: 0.0027\n",
            "batch: 59/979, loss: 1.2229, time: 0.0027\n",
            "batch: 60/979, loss: 1.2144, time: 0.0027\n",
            "batch: 61/979, loss: 1.2040, time: 0.0027\n",
            "batch: 62/979, loss: 1.1923, time: 0.0027\n",
            "batch: 63/979, loss: 1.1849, time: 0.0042\n",
            "batch: 64/979, loss: 1.1745, time: 0.0027\n",
            "batch: 65/979, loss: 1.1634, time: 0.0027\n",
            "batch: 66/979, loss: 1.1537, time: 0.0027\n",
            "batch: 67/979, loss: 1.1440, time: 0.0026\n",
            "batch: 68/979, loss: 1.1349, time: 0.0028\n",
            "batch: 69/979, loss: 1.1262, time: 0.0026\n",
            "batch: 70/979, loss: 1.1191, time: 0.0026\n",
            "batch: 71/979, loss: 1.1125, time: 0.0041\n",
            "batch: 72/979, loss: 1.1044, time: 0.0028\n",
            "batch: 73/979, loss: 1.0963, time: 0.0026\n",
            "batch: 74/979, loss: 1.0893, time: 0.0028\n",
            "batch: 75/979, loss: 1.0828, time: 0.0028\n",
            "batch: 76/979, loss: 1.0724, time: 0.0027\n",
            "batch: 77/979, loss: 1.0649, time: 0.0026\n",
            "batch: 78/979, loss: 1.0575, time: 0.0026\n",
            "batch: 79/979, loss: 1.0502, time: 0.0026\n",
            "batch: 80/979, loss: 1.0445, time: 0.0027\n",
            "batch: 81/979, loss: 1.0377, time: 0.0026\n",
            "batch: 82/979, loss: 1.0341, time: 0.0026\n",
            "batch: 83/979, loss: 1.0275, time: 0.0026\n",
            "batch: 84/979, loss: 1.0197, time: 0.0026\n",
            "batch: 85/979, loss: 1.0132, time: 0.0026\n",
            "batch: 86/979, loss: 1.0057, time: 0.0027\n",
            "batch: 87/979, loss: 1.0003, time: 0.0027\n",
            "batch: 88/979, loss: 0.9955, time: 0.0026\n",
            "batch: 89/979, loss: 0.9885, time: 0.0026\n",
            "batch: 90/979, loss: 0.9827, time: 0.0027\n",
            "batch: 91/979, loss: 0.9762, time: 0.0027\n",
            "batch: 92/979, loss: 0.9691, time: 0.0027\n",
            "batch: 93/979, loss: 0.9636, time: 0.0027\n",
            "batch: 94/979, loss: 0.9590, time: 0.0027\n",
            "batch: 95/979, loss: 0.9526, time: 0.0027\n",
            "batch: 96/979, loss: 0.9465, time: 0.0033\n",
            "batch: 97/979, loss: 0.9397, time: 0.0027\n",
            "batch: 98/979, loss: 0.9337, time: 0.0027\n",
            "batch: 99/979, loss: 0.9275, time: 0.0027\n",
            "batch: 100/979, loss: 0.9202, time: 0.0027\n",
            "batch: 101/979, loss: 0.9163, time: 0.0026\n",
            "batch: 102/979, loss: 0.9112, time: 0.0027\n",
            "batch: 103/979, loss: 0.9057, time: 0.0027\n",
            "batch: 104/979, loss: 0.9023, time: 0.0033\n",
            "batch: 105/979, loss: 0.8988, time: 0.0031\n",
            "batch: 106/979, loss: 0.8962, time: 0.0028\n",
            "batch: 107/979, loss: 0.8909, time: 0.0031\n",
            "batch: 108/979, loss: 0.8850, time: 0.0029\n",
            "batch: 109/979, loss: 0.8824, time: 0.0026\n",
            "batch: 110/979, loss: 0.8786, time: 0.0026\n",
            "batch: 111/979, loss: 0.8749, time: 0.0026\n",
            "batch: 112/979, loss: 0.8694, time: 0.0027\n",
            "batch: 113/979, loss: 0.8645, time: 0.0027\n",
            "batch: 114/979, loss: 0.8592, time: 0.0027\n",
            "batch: 115/979, loss: 0.8536, time: 0.0026\n",
            "batch: 116/979, loss: 0.8491, time: 0.0026\n",
            "batch: 117/979, loss: 0.8436, time: 0.0026\n",
            "batch: 118/979, loss: 0.8400, time: 0.0027\n",
            "batch: 119/979, loss: 0.8359, time: 0.0026\n",
            "batch: 120/979, loss: 0.8332, time: 0.0027\n",
            "batch: 121/979, loss: 0.8303, time: 0.0026\n",
            "batch: 122/979, loss: 0.8264, time: 0.0027\n",
            "batch: 123/979, loss: 0.8216, time: 0.0027\n",
            "batch: 124/979, loss: 0.8174, time: 0.0026\n",
            "batch: 125/979, loss: 0.8155, time: 0.0027\n",
            "batch: 126/979, loss: 0.8111, time: 0.0027\n",
            "batch: 127/979, loss: 0.8062, time: 0.0027\n",
            "batch: 128/979, loss: 0.8033, time: 0.0027\n",
            "batch: 129/979, loss: 0.8013, time: 0.0027\n",
            "batch: 130/979, loss: 0.7972, time: 0.0047\n",
            "batch: 131/979, loss: 0.7923, time: 0.0027\n",
            "batch: 132/979, loss: 0.7889, time: 0.0026\n",
            "batch: 133/979, loss: 0.7845, time: 0.0026\n",
            "batch: 134/979, loss: 0.7802, time: 0.0026\n",
            "batch: 135/979, loss: 0.7767, time: 0.0026\n",
            "batch: 136/979, loss: 0.7736, time: 0.0028\n",
            "batch: 137/979, loss: 0.7694, time: 0.0026\n",
            "batch: 138/979, loss: 0.7668, time: 0.0028\n",
            "batch: 139/979, loss: 0.7634, time: 0.0026\n",
            "batch: 140/979, loss: 0.7610, time: 0.0026\n",
            "batch: 141/979, loss: 0.7597, time: 0.0026\n",
            "batch: 142/979, loss: 0.7559, time: 0.0026\n",
            "batch: 143/979, loss: 0.7540, time: 0.0026\n",
            "batch: 144/979, loss: 0.7510, time: 0.0026\n",
            "batch: 145/979, loss: 0.7484, time: 0.0026\n",
            "batch: 146/979, loss: 0.7451, time: 0.0027\n",
            "batch: 147/979, loss: 0.7425, time: 0.0027\n",
            "batch: 148/979, loss: 0.7393, time: 0.0038\n",
            "batch: 149/979, loss: 0.7362, time: 0.0027\n",
            "batch: 150/979, loss: 0.7339, time: 0.0027\n",
            "batch: 151/979, loss: 0.7313, time: 0.0026\n",
            "batch: 152/979, loss: 0.7292, time: 0.0027\n",
            "batch: 153/979, loss: 0.7260, time: 0.0026\n",
            "batch: 154/979, loss: 0.7233, time: 0.0026\n",
            "batch: 155/979, loss: 0.7208, time: 0.0026\n",
            "batch: 156/979, loss: 0.7183, time: 0.0029\n",
            "batch: 157/979, loss: 0.7159, time: 0.0028\n",
            "batch: 158/979, loss: 0.7125, time: 0.0028\n",
            "batch: 159/979, loss: 0.7101, time: 0.0027\n",
            "batch: 160/979, loss: 0.7074, time: 0.0027\n",
            "batch: 161/979, loss: 0.7058, time: 0.0027\n",
            "batch: 162/979, loss: 0.7028, time: 0.0027\n",
            "batch: 163/979, loss: 0.7016, time: 0.0027\n",
            "batch: 164/979, loss: 0.6989, time: 0.0050\n",
            "batch: 165/979, loss: 0.6960, time: 0.0027\n",
            "batch: 166/979, loss: 0.6934, time: 0.0026\n",
            "batch: 167/979, loss: 0.6907, time: 0.0027\n",
            "batch: 168/979, loss: 0.6884, time: 0.0026\n",
            "batch: 169/979, loss: 0.6858, time: 0.0026\n",
            "batch: 170/979, loss: 0.6833, time: 0.0026\n",
            "batch: 171/979, loss: 0.6824, time: 0.0052\n",
            "batch: 172/979, loss: 0.6823, time: 0.0035\n",
            "batch: 173/979, loss: 0.6793, time: 0.0027\n",
            "batch: 174/979, loss: 0.6779, time: 0.0027\n",
            "batch: 175/979, loss: 0.6752, time: 0.0027\n",
            "batch: 176/979, loss: 0.6729, time: 0.0027\n",
            "batch: 177/979, loss: 0.6711, time: 0.0028\n",
            "batch: 178/979, loss: 0.6709, time: 0.0027\n",
            "batch: 179/979, loss: 0.6706, time: 0.0039\n",
            "batch: 180/979, loss: 0.6698, time: 0.0026\n",
            "batch: 181/979, loss: 0.6684, time: 0.0026\n",
            "batch: 182/979, loss: 0.6663, time: 0.0026\n",
            "batch: 183/979, loss: 0.6651, time: 0.0026\n",
            "batch: 184/979, loss: 0.6620, time: 0.0027\n",
            "batch: 185/979, loss: 0.6603, time: 0.0027\n",
            "batch: 186/979, loss: 0.6583, time: 0.0029\n",
            "batch: 187/979, loss: 0.6576, time: 0.0026\n",
            "batch: 188/979, loss: 0.6569, time: 0.0026\n",
            "batch: 189/979, loss: 0.6553, time: 0.0026\n",
            "batch: 190/979, loss: 0.6526, time: 0.0026\n",
            "batch: 191/979, loss: 0.6508, time: 0.0027\n",
            "batch: 192/979, loss: 0.6486, time: 0.0027\n",
            "batch: 193/979, loss: 0.6459, time: 0.0027\n",
            "batch: 194/979, loss: 0.6440, time: 0.0027\n",
            "batch: 195/979, loss: 0.6417, time: 0.0028\n",
            "batch: 196/979, loss: 0.6392, time: 0.0029\n",
            "batch: 197/979, loss: 0.6374, time: 0.0052\n",
            "batch: 198/979, loss: 0.6370, time: 0.0036\n",
            "batch: 199/979, loss: 0.6348, time: 0.0031\n",
            "batch: 200/979, loss: 0.6321, time: 0.0026\n",
            "batch: 201/979, loss: 0.6304, time: 0.0026\n",
            "batch: 202/979, loss: 0.6282, time: 0.0026\n",
            "batch: 203/979, loss: 0.6264, time: 0.0026\n",
            "batch: 204/979, loss: 0.6241, time: 0.0026\n",
            "batch: 205/979, loss: 0.6219, time: 0.0026\n",
            "batch: 206/979, loss: 0.6198, time: 0.0026\n",
            "batch: 207/979, loss: 0.6177, time: 0.0033\n",
            "batch: 208/979, loss: 0.6165, time: 0.0027\n",
            "batch: 209/979, loss: 0.6143, time: 0.0026\n",
            "batch: 210/979, loss: 0.6127, time: 0.0026\n",
            "batch: 211/979, loss: 0.6119, time: 0.0026\n",
            "batch: 212/979, loss: 0.6108, time: 0.0026\n",
            "batch: 213/979, loss: 0.6093, time: 0.0029\n",
            "batch: 214/979, loss: 0.6081, time: 0.0027\n",
            "batch: 215/979, loss: 0.6072, time: 0.0027\n",
            "batch: 216/979, loss: 0.6057, time: 0.0028\n",
            "batch: 217/979, loss: 0.6041, time: 0.0027\n",
            "batch: 218/979, loss: 0.6027, time: 0.0027\n",
            "batch: 219/979, loss: 0.6022, time: 0.0027\n",
            "batch: 220/979, loss: 0.6009, time: 0.0027\n",
            "batch: 221/979, loss: 0.5994, time: 0.0027\n",
            "batch: 222/979, loss: 0.5981, time: 0.0027\n",
            "batch: 223/979, loss: 0.5962, time: 0.0026\n",
            "batch: 224/979, loss: 0.5954, time: 0.0041\n",
            "batch: 225/979, loss: 0.5936, time: 0.0027\n",
            "batch: 226/979, loss: 0.5920, time: 0.0027\n",
            "batch: 227/979, loss: 0.5912, time: 0.0028\n",
            "batch: 228/979, loss: 0.5903, time: 0.0027\n",
            "batch: 229/979, loss: 0.5884, time: 0.0028\n",
            "batch: 230/979, loss: 0.5867, time: 0.0026\n",
            "batch: 231/979, loss: 0.5849, time: 0.0041\n",
            "batch: 232/979, loss: 0.5835, time: 0.0028\n",
            "batch: 233/979, loss: 0.5825, time: 0.0027\n",
            "batch: 234/979, loss: 0.5804, time: 0.0027\n",
            "batch: 235/979, loss: 0.5788, time: 0.0027\n",
            "batch: 236/979, loss: 0.5769, time: 0.0027\n",
            "batch: 237/979, loss: 0.5772, time: 0.0027\n",
            "batch: 238/979, loss: 0.5762, time: 0.0029\n",
            "batch: 239/979, loss: 0.5757, time: 0.0046\n",
            "batch: 240/979, loss: 0.5739, time: 0.0041\n",
            "batch: 241/979, loss: 0.5722, time: 0.0039\n",
            "batch: 242/979, loss: 0.5707, time: 0.0043\n",
            "batch: 243/979, loss: 0.5694, time: 0.0027\n",
            "batch: 244/979, loss: 0.5676, time: 0.0026\n",
            "batch: 245/979, loss: 0.5659, time: 0.0027\n",
            "batch: 246/979, loss: 0.5650, time: 0.0027\n",
            "batch: 247/979, loss: 0.5646, time: 0.0027\n",
            "batch: 248/979, loss: 0.5640, time: 0.0028\n",
            "batch: 249/979, loss: 0.5632, time: 0.0027\n",
            "batch: 250/979, loss: 0.5626, time: 0.0027\n",
            "batch: 251/979, loss: 0.5614, time: 0.0029\n",
            "batch: 252/979, loss: 0.5603, time: 0.0027\n",
            "batch: 253/979, loss: 0.5589, time: 0.0027\n",
            "batch: 254/979, loss: 0.5572, time: 0.0027\n",
            "batch: 255/979, loss: 0.5560, time: 0.0027\n",
            "batch: 256/979, loss: 0.5554, time: 0.0027\n",
            "batch: 257/979, loss: 0.5546, time: 0.0027\n",
            "batch: 258/979, loss: 0.5535, time: 0.0027\n",
            "batch: 259/979, loss: 0.5525, time: 0.0027\n",
            "batch: 260/979, loss: 0.5525, time: 0.0027\n",
            "batch: 261/979, loss: 0.5519, time: 0.0028\n",
            "batch: 262/979, loss: 0.5508, time: 0.0027\n",
            "batch: 263/979, loss: 0.5492, time: 0.0041\n",
            "batch: 264/979, loss: 0.5483, time: 0.0031\n",
            "batch: 265/979, loss: 0.5475, time: 0.0027\n",
            "batch: 266/979, loss: 0.5461, time: 0.0027\n",
            "batch: 267/979, loss: 0.5447, time: 0.0029\n",
            "batch: 268/979, loss: 0.5434, time: 0.0030\n",
            "batch: 269/979, loss: 0.5419, time: 0.0028\n",
            "batch: 270/979, loss: 0.5403, time: 0.0027\n",
            "batch: 271/979, loss: 0.5397, time: 0.0027\n",
            "batch: 272/979, loss: 0.5382, time: 0.0027\n",
            "batch: 273/979, loss: 0.5376, time: 0.0027\n",
            "batch: 274/979, loss: 0.5375, time: 0.0027\n",
            "batch: 275/979, loss: 0.5374, time: 0.0027\n",
            "batch: 276/979, loss: 0.5377, time: 0.0027\n",
            "batch: 277/979, loss: 0.5367, time: 0.0026\n",
            "batch: 278/979, loss: 0.5358, time: 0.0028\n",
            "batch: 279/979, loss: 0.5349, time: 0.0027\n",
            "batch: 280/979, loss: 0.5336, time: 0.0027\n",
            "batch: 281/979, loss: 0.5327, time: 0.0027\n",
            "batch: 282/979, loss: 0.5312, time: 0.0029\n",
            "batch: 283/979, loss: 0.5298, time: 0.0027\n",
            "batch: 284/979, loss: 0.5283, time: 0.0027\n",
            "batch: 285/979, loss: 0.5272, time: 0.0027\n",
            "batch: 286/979, loss: 0.5268, time: 0.0028\n",
            "batch: 287/979, loss: 0.5256, time: 0.0028\n",
            "batch: 288/979, loss: 0.5247, time: 0.0027\n",
            "batch: 289/979, loss: 0.5242, time: 0.0027\n",
            "batch: 290/979, loss: 0.5234, time: 0.0028\n",
            "batch: 291/979, loss: 0.5222, time: 0.0027\n",
            "batch: 292/979, loss: 0.5218, time: 0.0030\n",
            "batch: 293/979, loss: 0.5216, time: 0.0027\n",
            "batch: 294/979, loss: 0.5206, time: 0.0029\n",
            "batch: 295/979, loss: 0.5195, time: 0.0027\n",
            "batch: 296/979, loss: 0.5188, time: 0.0027\n",
            "batch: 297/979, loss: 0.5179, time: 0.0047\n",
            "batch: 298/979, loss: 0.5171, time: 0.0027\n",
            "batch: 299/979, loss: 0.5158, time: 0.0029\n",
            "batch: 300/979, loss: 0.5149, time: 0.0029\n",
            "batch: 301/979, loss: 0.5134, time: 0.0027\n",
            "batch: 302/979, loss: 0.5137, time: 0.0027\n",
            "batch: 303/979, loss: 0.5128, time: 0.0027\n",
            "batch: 304/979, loss: 0.5114, time: 0.0027\n",
            "batch: 305/979, loss: 0.5105, time: 0.0027\n",
            "batch: 306/979, loss: 0.5093, time: 0.0027\n",
            "batch: 307/979, loss: 0.5091, time: 0.0027\n",
            "batch: 308/979, loss: 0.5089, time: 0.0027\n",
            "batch: 309/979, loss: 0.5079, time: 0.0027\n",
            "batch: 310/979, loss: 0.5071, time: 0.0027\n",
            "batch: 311/979, loss: 0.5061, time: 0.0026\n",
            "batch: 312/979, loss: 0.5055, time: 0.0026\n",
            "batch: 313/979, loss: 0.5045, time: 0.0028\n",
            "batch: 314/979, loss: 0.5035, time: 0.0029\n",
            "batch: 315/979, loss: 0.5023, time: 0.0027\n",
            "batch: 316/979, loss: 0.5016, time: 0.0027\n",
            "batch: 317/979, loss: 0.5012, time: 0.0027\n",
            "batch: 318/979, loss: 0.5008, time: 0.0027\n",
            "batch: 319/979, loss: 0.5005, time: 0.0027\n",
            "batch: 320/979, loss: 0.4994, time: 0.0029\n",
            "batch: 321/979, loss: 0.4983, time: 0.0026\n",
            "batch: 322/979, loss: 0.4976, time: 0.0027\n",
            "batch: 323/979, loss: 0.4965, time: 0.0027\n",
            "batch: 324/979, loss: 0.4965, time: 0.0027\n",
            "batch: 325/979, loss: 0.4955, time: 0.0027\n",
            "batch: 326/979, loss: 0.4946, time: 0.0027\n",
            "batch: 327/979, loss: 0.4942, time: 0.0028\n",
            "batch: 328/979, loss: 0.4936, time: 0.0026\n",
            "batch: 329/979, loss: 0.4923, time: 0.0027\n",
            "batch: 330/979, loss: 0.4916, time: 0.0034\n",
            "batch: 331/979, loss: 0.4909, time: 0.0030\n",
            "batch: 332/979, loss: 0.4901, time: 0.0027\n",
            "batch: 333/979, loss: 0.4893, time: 0.0026\n",
            "batch: 334/979, loss: 0.4883, time: 0.0026\n",
            "batch: 335/979, loss: 0.4875, time: 0.0026\n",
            "batch: 336/979, loss: 0.4866, time: 0.0028\n",
            "batch: 337/979, loss: 0.4855, time: 0.0026\n",
            "batch: 338/979, loss: 0.4852, time: 0.0026\n",
            "batch: 339/979, loss: 0.4845, time: 0.0028\n",
            "batch: 340/979, loss: 0.4834, time: 0.0026\n",
            "batch: 341/979, loss: 0.4822, time: 0.0027\n",
            "batch: 342/979, loss: 0.4824, time: 0.0035\n",
            "batch: 343/979, loss: 0.4814, time: 0.0027\n",
            "batch: 344/979, loss: 0.4805, time: 0.0027\n",
            "batch: 345/979, loss: 0.4795, time: 0.0027\n",
            "batch: 346/979, loss: 0.4785, time: 0.0026\n",
            "batch: 347/979, loss: 0.4779, time: 0.0029\n",
            "batch: 348/979, loss: 0.4774, time: 0.0027\n",
            "batch: 349/979, loss: 0.4764, time: 0.0027\n",
            "batch: 350/979, loss: 0.4761, time: 0.0028\n",
            "batch: 351/979, loss: 0.4751, time: 0.0027\n",
            "batch: 352/979, loss: 0.4740, time: 0.0027\n",
            "batch: 353/979, loss: 0.4735, time: 0.0028\n",
            "batch: 354/979, loss: 0.4724, time: 0.0027\n",
            "batch: 355/979, loss: 0.4720, time: 0.0027\n",
            "batch: 356/979, loss: 0.4711, time: 0.0027\n",
            "batch: 357/979, loss: 0.4705, time: 0.0027\n",
            "batch: 358/979, loss: 0.4698, time: 0.0027\n",
            "batch: 359/979, loss: 0.4695, time: 0.0033\n",
            "batch: 360/979, loss: 0.4694, time: 0.0035\n",
            "batch: 361/979, loss: 0.4688, time: 0.0031\n",
            "batch: 362/979, loss: 0.4677, time: 0.0033\n",
            "batch: 363/979, loss: 0.4672, time: 0.0027\n",
            "batch: 364/979, loss: 0.4662, time: 0.0036\n",
            "batch: 365/979, loss: 0.4655, time: 0.0028\n",
            "batch: 366/979, loss: 0.4647, time: 0.0028\n",
            "batch: 367/979, loss: 0.4641, time: 0.0027\n",
            "batch: 368/979, loss: 0.4634, time: 0.0027\n",
            "batch: 369/979, loss: 0.4630, time: 0.0027\n",
            "batch: 370/979, loss: 0.4627, time: 0.0029\n",
            "batch: 371/979, loss: 0.4621, time: 0.0029\n",
            "batch: 372/979, loss: 0.4620, time: 0.0027\n",
            "batch: 373/979, loss: 0.4613, time: 0.0028\n",
            "batch: 374/979, loss: 0.4602, time: 0.0028\n",
            "batch: 375/979, loss: 0.4594, time: 0.0027\n",
            "batch: 376/979, loss: 0.4589, time: 0.0028\n",
            "batch: 377/979, loss: 0.4586, time: 0.0027\n",
            "batch: 378/979, loss: 0.4582, time: 0.0028\n",
            "batch: 379/979, loss: 0.4572, time: 0.0027\n",
            "batch: 380/979, loss: 0.4567, time: 0.0027\n",
            "batch: 381/979, loss: 0.4565, time: 0.0027\n",
            "batch: 382/979, loss: 0.4559, time: 0.0027\n",
            "batch: 383/979, loss: 0.4552, time: 0.0027\n",
            "batch: 384/979, loss: 0.4542, time: 0.0049\n",
            "batch: 385/979, loss: 0.4533, time: 0.0027\n",
            "batch: 386/979, loss: 0.4532, time: 0.0029\n",
            "batch: 387/979, loss: 0.4523, time: 0.0027\n",
            "batch: 388/979, loss: 0.4520, time: 0.0027\n",
            "batch: 389/979, loss: 0.4511, time: 0.0027\n",
            "batch: 390/979, loss: 0.4503, time: 0.0027\n",
            "batch: 391/979, loss: 0.4503, time: 0.0027\n",
            "batch: 392/979, loss: 0.4497, time: 0.0027\n",
            "batch: 393/979, loss: 0.4488, time: 0.0027\n",
            "batch: 394/979, loss: 0.4480, time: 0.0027\n",
            "batch: 395/979, loss: 0.4476, time: 0.0027\n",
            "batch: 396/979, loss: 0.4471, time: 0.0047\n",
            "batch: 397/979, loss: 0.4463, time: 0.0028\n",
            "batch: 398/979, loss: 0.4456, time: 0.0027\n",
            "batch: 399/979, loss: 0.4457, time: 0.0027\n",
            "batch: 400/979, loss: 0.4452, time: 0.0028\n",
            "batch: 401/979, loss: 0.4443, time: 0.0027\n",
            "batch: 402/979, loss: 0.4438, time: 0.0028\n",
            "batch: 403/979, loss: 0.4435, time: 0.0027\n",
            "batch: 404/979, loss: 0.4427, time: 0.0027\n",
            "batch: 405/979, loss: 0.4425, time: 0.0032\n",
            "batch: 406/979, loss: 0.4421, time: 0.0043\n",
            "batch: 407/979, loss: 0.4416, time: 0.0040\n",
            "batch: 408/979, loss: 0.4415, time: 0.0046\n",
            "batch: 409/979, loss: 0.4407, time: 0.0040\n",
            "batch: 410/979, loss: 0.4401, time: 0.0041\n",
            "batch: 411/979, loss: 0.4398, time: 0.0041\n",
            "batch: 412/979, loss: 0.4397, time: 0.0038\n",
            "batch: 413/979, loss: 0.4390, time: 0.0039\n",
            "batch: 414/979, loss: 0.4383, time: 0.0041\n",
            "batch: 415/979, loss: 0.4377, time: 0.0040\n",
            "batch: 416/979, loss: 0.4380, time: 0.0038\n",
            "batch: 417/979, loss: 0.4376, time: 0.0041\n",
            "batch: 418/979, loss: 0.4370, time: 0.0039\n",
            "batch: 419/979, loss: 0.4364, time: 0.0038\n",
            "batch: 420/979, loss: 0.4359, time: 0.0040\n",
            "batch: 421/979, loss: 0.4352, time: 0.0039\n",
            "batch: 422/979, loss: 0.4348, time: 0.0039\n",
            "batch: 423/979, loss: 0.4347, time: 0.0037\n",
            "batch: 424/979, loss: 0.4339, time: 0.0041\n",
            "batch: 425/979, loss: 0.4337, time: 0.0084\n",
            "batch: 426/979, loss: 0.4338, time: 0.0040\n",
            "batch: 427/979, loss: 0.4338, time: 0.0040\n",
            "batch: 428/979, loss: 0.4334, time: 0.0035\n",
            "batch: 429/979, loss: 0.4329, time: 0.0037\n",
            "batch: 430/979, loss: 0.4322, time: 0.0034\n",
            "batch: 431/979, loss: 0.4326, time: 0.0033\n",
            "batch: 432/979, loss: 0.4320, time: 0.0034\n",
            "batch: 433/979, loss: 0.4325, time: 0.0033\n",
            "batch: 434/979, loss: 0.4322, time: 0.0038\n",
            "batch: 435/979, loss: 0.4318, time: 0.0039\n",
            "batch: 436/979, loss: 0.4315, time: 0.0041\n",
            "batch: 437/979, loss: 0.4309, time: 0.0039\n",
            "batch: 438/979, loss: 0.4305, time: 0.0045\n",
            "batch: 439/979, loss: 0.4298, time: 0.0041\n",
            "batch: 440/979, loss: 0.4293, time: 0.0034\n",
            "batch: 441/979, loss: 0.4290, time: 0.0034\n",
            "batch: 442/979, loss: 0.4281, time: 0.0034\n",
            "batch: 443/979, loss: 0.4276, time: 0.0034\n",
            "batch: 444/979, loss: 0.4272, time: 0.0034\n",
            "batch: 445/979, loss: 0.4268, time: 0.0034\n",
            "batch: 446/979, loss: 0.4266, time: 0.0034\n",
            "batch: 447/979, loss: 0.4259, time: 0.0045\n",
            "batch: 448/979, loss: 0.4254, time: 0.0034\n",
            "batch: 449/979, loss: 0.4251, time: 0.0041\n",
            "batch: 450/979, loss: 0.4245, time: 0.0037\n",
            "batch: 451/979, loss: 0.4243, time: 0.0033\n",
            "batch: 452/979, loss: 0.4244, time: 0.0039\n",
            "batch: 453/979, loss: 0.4243, time: 0.0036\n",
            "batch: 454/979, loss: 0.4238, time: 0.0033\n",
            "batch: 455/979, loss: 0.4235, time: 0.0033\n",
            "batch: 456/979, loss: 0.4227, time: 0.0033\n",
            "batch: 457/979, loss: 0.4224, time: 0.0033\n",
            "batch: 458/979, loss: 0.4217, time: 0.0033\n",
            "batch: 459/979, loss: 0.4215, time: 0.0038\n",
            "batch: 460/979, loss: 0.4213, time: 0.0039\n",
            "batch: 461/979, loss: 0.4208, time: 0.0038\n",
            "batch: 462/979, loss: 0.4207, time: 0.0034\n",
            "batch: 463/979, loss: 0.4202, time: 0.0034\n",
            "batch: 464/979, loss: 0.4194, time: 0.0034\n",
            "batch: 465/979, loss: 0.4194, time: 0.0037\n",
            "batch: 466/979, loss: 0.4190, time: 0.0035\n",
            "batch: 467/979, loss: 0.4185, time: 0.0035\n",
            "batch: 468/979, loss: 0.4184, time: 0.0035\n",
            "batch: 469/979, loss: 0.4179, time: 0.0036\n",
            "batch: 470/979, loss: 0.4172, time: 0.0035\n",
            "batch: 471/979, loss: 0.4174, time: 0.0035\n",
            "batch: 472/979, loss: 0.4169, time: 0.0034\n",
            "batch: 473/979, loss: 0.4171, time: 0.0035\n",
            "batch: 474/979, loss: 0.4166, time: 0.0035\n",
            "batch: 475/979, loss: 0.4167, time: 0.0036\n",
            "batch: 476/979, loss: 0.4161, time: 0.0039\n",
            "batch: 477/979, loss: 0.4161, time: 0.0034\n",
            "batch: 478/979, loss: 0.4156, time: 0.0034\n",
            "batch: 479/979, loss: 0.4152, time: 0.0034\n",
            "batch: 480/979, loss: 0.4148, time: 0.0034\n",
            "batch: 481/979, loss: 0.4144, time: 0.0035\n",
            "batch: 482/979, loss: 0.4142, time: 0.0035\n",
            "batch: 483/979, loss: 0.4139, time: 0.0043\n",
            "batch: 484/979, loss: 0.4139, time: 0.0034\n",
            "batch: 485/979, loss: 0.4133, time: 0.0034\n",
            "batch: 486/979, loss: 0.4130, time: 0.0035\n",
            "batch: 487/979, loss: 0.4126, time: 0.0036\n",
            "batch: 488/979, loss: 0.4121, time: 0.0034\n",
            "batch: 489/979, loss: 0.4119, time: 0.0046\n",
            "batch: 490/979, loss: 0.4123, time: 0.0034\n",
            "batch: 491/979, loss: 0.4124, time: 0.0034\n",
            "batch: 492/979, loss: 0.4120, time: 0.0034\n",
            "batch: 493/979, loss: 0.4121, time: 0.0034\n",
            "batch: 494/979, loss: 0.4120, time: 0.0036\n",
            "batch: 495/979, loss: 0.4114, time: 0.0035\n",
            "batch: 496/979, loss: 0.4110, time: 0.0035\n",
            "batch: 497/979, loss: 0.4104, time: 0.0034\n",
            "batch: 498/979, loss: 0.4107, time: 0.0041\n",
            "batch: 499/979, loss: 0.4101, time: 0.0034\n",
            "batch: 500/979, loss: 0.4095, time: 0.0034\n",
            "batch: 501/979, loss: 0.4088, time: 0.0035\n",
            "batch: 502/979, loss: 0.4083, time: 0.0034\n",
            "batch: 503/979, loss: 0.4083, time: 0.0039\n",
            "batch: 504/979, loss: 0.4079, time: 0.0049\n",
            "batch: 505/979, loss: 0.4075, time: 0.0058\n",
            "batch: 506/979, loss: 0.4069, time: 0.0045\n",
            "batch: 507/979, loss: 0.4064, time: 0.0034\n",
            "batch: 508/979, loss: 0.4060, time: 0.0034\n",
            "batch: 509/979, loss: 0.4059, time: 0.0034\n",
            "batch: 510/979, loss: 0.4053, time: 0.0083\n",
            "batch: 511/979, loss: 0.4050, time: 0.0035\n",
            "batch: 512/979, loss: 0.4049, time: 0.0037\n",
            "batch: 513/979, loss: 0.4046, time: 0.0037\n",
            "batch: 514/979, loss: 0.4045, time: 0.0035\n",
            "batch: 515/979, loss: 0.4047, time: 0.0034\n",
            "batch: 516/979, loss: 0.4044, time: 0.0039\n",
            "batch: 517/979, loss: 0.4040, time: 0.0034\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-d4e9dde2bbab>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcl_test_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcl_train_accuracy_arr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     cl_test_accuracy_arr = train(classical_model, criterion=criterion,\n\u001b[0m\u001b[1;32m      5\u001b[0m                               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcl_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-eb7c6ba335b4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_dataloader, test_dataloader, num_epochs)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# t.grad = torch.tensor([0., 0., 0.])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# t = t - lr * t.grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cl_test_accuracy_arr"
      ],
      "metadata": {
        "id": "1SQ4xsOVd0bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hq_train_losses, \\\n",
        "    hq_test_losses, \\\n",
        "    hq_train_accuracy_arr, \\\n",
        "    hq_test_accuracy_arr = train_for_hqnn(hybrid_quantum_model, criterion=criterion,\n",
        "                              optimizer=hq_optimizer,\n",
        "                              train_dataloader=train_loader,\n",
        "                              test_dataloader=test_loader,\n",
        "                              num_epochs=1)"
      ],
      "metadata": {
        "id": "2CqcSaKTTMhJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "a2c92dc7fab442cab155640d3eff1d98",
            "568590cffe4a4bd9ab910a56a38c6be6",
            "56ce1b55162f49f3911de184abd830c0",
            "2217eeddc231445389684f908cc151e9",
            "260970bb1be34e0eb6ae0b4df3569a95",
            "b427e72e1c2d4823ad6359701feef977",
            "03a2e444acc5454ba9ad15153e2b9a11",
            "93b5477e79114423b8800f34da7762bf",
            "e3be60fcb2724f64aeab0600b4630291",
            "ab96638e0e5842eb9090b27cb17f0e79",
            "d713c621ab33437583be9f40a3543a3f"
          ]
        },
        "outputId": "04e77787-4db5-4a8e-cf24-e51fbceb16c1"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2c92dc7fab442cab155640d3eff1d98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-dc1107e005b8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mhq_test_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mhq_train_accuracy_arr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     hq_test_accuracy_arr = train_for_hqnn(hybrid_quantum_model, criterion=criterion,\n\u001b[0m\u001b[1;32m      5\u001b[0m                               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhq_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-108-eb7c6ba335b4>\u001b[0m in \u001b[0;36mtrain_for_hqnn\u001b[0;34m(model, criterion, optimizer, train_dataloader, test_dataloader, num_epochs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# model forward-pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# model backward-pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-103-a221820fc599>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Pass embeddings to LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# out, hidden = self.lstm(embedded.reshape(-1, embedded.size(1)*embedded.size(2), embedded.size(-1)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Calculate attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-c23f92b39e6e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;31m# Get hidden state for current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mh_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_cells\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;31m# Update hidden states for next timestep, for current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-c23f92b39e6e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Split into gates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# combined = torch.cat([torch.stack(qdi_circuit(self.W_quan[i], combined[:, i:i*num_qubits].reshape(-1, num_qubits))) for i in range(num_qubits)], dim = 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mi_gate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqdi_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_quan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mnum_qubits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_qubits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mf_gate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqdi_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_quan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_qubits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_qubits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_qubits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mg_gate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqdi_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_quan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_qubits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_qubits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_qubits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/workflow/qnode.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnode_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/workflow/qnode.py\u001b[0m in \u001b[0;36m_impl_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_component\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mold_interface\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/workflow/qnode.py\u001b[0m in \u001b[0;36m_execution_component\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;31m# pylint: disable=unexpected-keyword-arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         res = qml.execute(\n\u001b[0m\u001b[1;32m    936\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/workflow/execution.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(tapes, device, gradient_fn, interface, transform_program, inner_transform, config, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, device_vjp, mcm_config)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minterface\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjpc_interfaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml_boundary_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecute_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         results = ml_boundary_execute(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/workflow/interfaces/torch.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(tapes, execute_fn, jpc, device)\u001b[0m\n\u001b[1;32m    234\u001b[0m     }\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mExecuteTapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/workflow/interfaces/torch.py\u001b[0m in \u001b[0;36mnew_apply\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Inputs already flat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mout_struct_holder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mflat_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_struct_holder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_struct_holder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_setup_ctx_defined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/workflow/interfaces/torch.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(ctx, out_struct_holder, *inp)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_struct_holder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_fw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mflat_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_struct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpytree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_out_struct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_struct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/workflow/interfaces/torch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, kwargs, *parameters)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjpc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"jpc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"execute_fn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# if any input tensor uses the GPU, the output should as well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/workflow/execution.py\u001b[0m in \u001b[0;36minner_execute\u001b[0;34m(tapes, **_)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransformed_tapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_tapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecution_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane_qiskit/qiskit_device.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracked_execute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDefaultExecutionConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracked_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/devices/modifiers/simulator_tracking.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muntracked_execute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDefaultExecutionConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muntracked_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecution_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQuantumScript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcircuits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane_qiskit/qiskit_device.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mexecute_circuits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane_qiskit/qiskit_device.py\u001b[0m in \u001b[0;36mexecute_circuits\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                         \u001b[0mexecute_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_sampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcirc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane_qiskit/qiskit_device.py\u001b[0m in \u001b[0;36m_execute_estimator\u001b[0;34m(self, circuit, session)\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mcirc_and_obs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_shots\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshots\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         ).result()\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_estimator_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasurements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit_ibm_runtime/runtime_job_v2.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout, decoder)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \"\"\"\n\u001b[1;32m    132\u001b[0m         \u001b[0m_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_result_decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_final_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ERROR\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reason\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reason\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit_ibm_runtime/runtime_job_v2.py\u001b[0m in \u001b[0;36mwait_for_final_state\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    251\u001b[0m                     )\n\u001b[1;32m    252\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             raise RuntimeJobTimeoutError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit_ibm_runtime/runtime_job_v2.py\u001b[0m in \u001b[0;36mstatus\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mStatus\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \"\"\"\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_status_and_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit_ibm_runtime/base_runtime_job.py\u001b[0m in \u001b[0;36m_set_status_and_error_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;34m\"\"\"Fetch and set status and error message.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOB_FINAL_STATES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit_ibm_runtime/api/clients/runtime.py\u001b[0m in \u001b[0;36mjob_get\u001b[0;34m(self, job_id, exclude_params)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mJSON\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \"\"\"\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogram_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Runtime job get response: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit_ibm_runtime/api/rest/program_job.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, exclude_params)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexclude_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mpayload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"exclude_params\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"true\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRuntimeDecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allow_redirects\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/qiskit_ibm_runtime/api/session.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, bare, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;34m\"circuit_knitting_toolbox\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             }\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mstack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m   1671\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;34m\"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1673\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetouterframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36mgetouterframes\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1648\u001b[0m     \u001b[0mframelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m         \u001b[0mframeinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgetframeinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m         \u001b[0mframelist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrameInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mframeinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36mgetframeinfo\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1624\u001b[0;31m             \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1625\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    938\u001b[0m     is raised if the source code cannot be retrieved.\"\"\"\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;31m# Invalidate cache if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;31m# only return a non-existent filename if the module has a PEP 302 loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__loader__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/inspect.py\u001b[0m in \u001b[0;36mgetmodule\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mismodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__file__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_filesbymodname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m                 \u001b[0;31m# Have already mapped this module, so skip it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hq_test_accuracy_arr"
      ],
      "metadata": {
        "id": "Jgjxi_GhTVZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hq_train_accuracy_arr"
      ],
      "metadata": {
        "id": "Tsr4BWl-PGF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "in_channels = 1\n",
        "out_channels = 3\n",
        "length = 31\n",
        "num_classes = 5\n",
        "kernel_size = 2\n",
        "embedding_dim = 200\n",
        "hidden_dim = 100\n",
        "padding = 1\n",
        "stride = 1\n",
        "num_qubits = 4\n",
        "\n",
        "# Create dummy data & labels\n",
        "train_dummy_data = torch.randint(0, 1000, (batch_size, length)).to(device)\n",
        "train_dummy_labels = torch.randint(0, num_classes, (batch_size,)).to(device)\n",
        "\n",
        "test_dummy_data = torch.randn(batch_size, length)\n",
        "test_dummy_labels = torch.randint(0, num_classes, (batch_size,))\n",
        "\n",
        "# Create a simple Dataset and DataLoader\n",
        "train_dummy_dataset = TensorDataset(train_dummy_data, train_dummy_labels)\n",
        "train_dummy_loader = DataLoader(train_dummy_dataset, batch_size)\n",
        "\n",
        "test_dummy_dataset = TensorDataset(test_dummy_data, test_dummy_labels)\n",
        "test_dummy_loader = DataLoader(test_dummy_dataset, batch_size)\n"
      ],
      "metadata": {
        "id": "pF1KSYMGTdHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 8e-4 #Learning rate\n",
        "\n",
        "toy_hq_model = ToyHQModel(VOCAB_SIZE, embedding_dim, in_channels, out_channels, kernel_size, stride, padding, hidden_dim, num_qubits, num_classes, lstm_layers = 1)\n",
        "\n",
        "toy_hq_model = toy_hq_model.to(device)\n",
        "# Set up the criterion (loss function)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.AdamW(toy_hq_model.parameters(), lr=LR, weight_decay = 5e-6)\n",
        "\n",
        "print(toy_hq_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZjYDvFJLG0z",
        "outputId": "108bfc04-5bdf-43dc-8322-3659a2112648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ToyHQModel(\n",
            "  (embedding): Embedding(37569, 200)\n",
            "  (attention): Attention(\n",
            "    (attn): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (v): Linear(in_features=100, out_features=1, bias=False)\n",
            "  )\n",
            "  (lstm): HQLSTM(\n",
            "    (lstm_cells): ModuleList(\n",
            "      (0): HQLSTMCell()\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toy_hq_model(train_dummy_data)"
      ],
      "metadata": {
        "id": "AH2z4g_A5FjA",
        "outputId": "ca9d8fa0-d80c-4a16-b9b9-f4bb0df18bb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.6381, -1.6118, -1.5608, -1.6813, -1.5606],\n",
              "        [-1.6472, -1.6141, -1.5558, -1.6795, -1.5565]], device='cuda:0',\n",
              "       grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "metadata": {
        "id": "rActVEdigY8M",
        "outputId": "05ad61af-0c0d-4c9a-aeb7-d989abf48ac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28985, 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dummy_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "# test_dummy_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))"
      ],
      "metadata": {
        "id": "Cps3yt0-eIKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BATCH_SIZE = 2"
      ],
      "metadata": {
        "id": "18tjNlfVeIKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dummy_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
        "test_dummy_loader = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE, drop_last=True)"
      ],
      "metadata": {
        "id": "qQRprRrveIKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, \\\n",
        "    test_losses, \\\n",
        "    train_accuracy_arr, \\\n",
        "    test_accuracy_arr = train_for_hqnn(toy_hq_model, criterion=criterion,\n",
        "                              optimizer=optimizer,\n",
        "                              train_dataloader=train_dummy_loader,\n",
        "                              test_dataloader=test_dummy_loader,\n",
        "                              num_epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "06a8e085c5684549b8564f24bd762e4f",
            "3a33592a8c0f4c3e9e42f2d092dd0889",
            "885eeace639140e2a01b16692b64accc",
            "ca36aa40d1e64ad496b3b838462acaa0",
            "62374ed5a97a431c942ba275585d7d57",
            "6281ff12628a44da968a820165064dd1",
            "a32f46d1b39247d69617fd8d08255dde",
            "e437002cee7c48468d608ac3b6419490",
            "d4d7dc520db647d9bd626ee52f8a35bd",
            "27d5e2469ff444539de5d7d4b4ab6278",
            "875eff2116cf45b9b386071a7d8cc1c7"
          ]
        },
        "id": "RBB6oiTGG02t",
        "outputId": "48e1fb56-cbc4-4c18-9836-1a3a5342eb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06a8e085c5684549b8564f24bd762e4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-fd0fa7cb832d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_accuracy_arr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     test_accuracy_arr = train_for_hqnn(toy_hq_model, criterion=criterion,\n\u001b[0m\u001b[1;32m      5\u001b[0m                               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dummy_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-0036f823edc8>\u001b[0m in \u001b[0;36mtrain_for_hqnn\u001b[0;34m(model, criterion, optimizer, train_dataloader, test_dataloader, num_epochs)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# t.grad = torch.tensor([0., 0., 0.])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# t = t - lr * t.grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses"
      ],
      "metadata": {
        "id": "lPCx3xe9zXNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FysnlhgaW4TF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06a8e085c5684549b8564f24bd762e4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a33592a8c0f4c3e9e42f2d092dd0889",
              "IPY_MODEL_885eeace639140e2a01b16692b64accc",
              "IPY_MODEL_ca36aa40d1e64ad496b3b838462acaa0"
            ],
            "layout": "IPY_MODEL_62374ed5a97a431c942ba275585d7d57"
          }
        },
        "3a33592a8c0f4c3e9e42f2d092dd0889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6281ff12628a44da968a820165064dd1",
            "placeholder": "",
            "style": "IPY_MODEL_a32f46d1b39247d69617fd8d08255dde",
            "value": "0%"
          }
        },
        "885eeace639140e2a01b16692b64accc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e437002cee7c48468d608ac3b6419490",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4d7dc520db647d9bd626ee52f8a35bd",
            "value": 0
          }
        },
        "ca36aa40d1e64ad496b3b838462acaa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27d5e2469ff444539de5d7d4b4ab6278",
            "placeholder": "",
            "style": "IPY_MODEL_875eff2116cf45b9b386071a7d8cc1c7",
            "value": "0/2[30:03&lt;?,?it/s]"
          }
        },
        "62374ed5a97a431c942ba275585d7d57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6281ff12628a44da968a820165064dd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a32f46d1b39247d69617fd8d08255dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e437002cee7c48468d608ac3b6419490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d7dc520db647d9bd626ee52f8a35bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27d5e2469ff444539de5d7d4b4ab6278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "875eff2116cf45b9b386071a7d8cc1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "661cd90b76c9451f98e0ca29c4b22d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d702bf265eca4bbbbcb7a358df381c65",
              "IPY_MODEL_fc30a6a4b6064be0b3c4a786a4b64952",
              "IPY_MODEL_df78c6ab42474534a547a0a7ba44b754"
            ],
            "layout": "IPY_MODEL_d49849d9283546c9b34517f327232757"
          }
        },
        "d702bf265eca4bbbbcb7a358df381c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8562c9e4bc8443db82350ff5f496958b",
            "placeholder": "",
            "style": "IPY_MODEL_e17bf6667ccd4167af9110a09ba012ac",
            "value": "0%"
          }
        },
        "fc30a6a4b6064be0b3c4a786a4b64952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60ed458c82de4401a7eb400c23f1338d",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_673f3f8df9244b538ad88f1fc82442b6",
            "value": 0
          }
        },
        "df78c6ab42474534a547a0a7ba44b754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_029421ef2fec489b8b379351e00e188a",
            "placeholder": "",
            "style": "IPY_MODEL_98cad26d7f274b71a04d37fca89196bf",
            "value": "0/10[00:03&lt;?,?it/s]"
          }
        },
        "d49849d9283546c9b34517f327232757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8562c9e4bc8443db82350ff5f496958b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e17bf6667ccd4167af9110a09ba012ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60ed458c82de4401a7eb400c23f1338d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "673f3f8df9244b538ad88f1fc82442b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "029421ef2fec489b8b379351e00e188a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98cad26d7f274b71a04d37fca89196bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2c92dc7fab442cab155640d3eff1d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_568590cffe4a4bd9ab910a56a38c6be6",
              "IPY_MODEL_56ce1b55162f49f3911de184abd830c0",
              "IPY_MODEL_2217eeddc231445389684f908cc151e9"
            ],
            "layout": "IPY_MODEL_260970bb1be34e0eb6ae0b4df3569a95"
          }
        },
        "568590cffe4a4bd9ab910a56a38c6be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b427e72e1c2d4823ad6359701feef977",
            "placeholder": "",
            "style": "IPY_MODEL_03a2e444acc5454ba9ad15153e2b9a11",
            "value": "0%"
          }
        },
        "56ce1b55162f49f3911de184abd830c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93b5477e79114423b8800f34da7762bf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3be60fcb2724f64aeab0600b4630291",
            "value": 0
          }
        },
        "2217eeddc231445389684f908cc151e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab96638e0e5842eb9090b27cb17f0e79",
            "placeholder": "",
            "style": "IPY_MODEL_d713c621ab33437583be9f40a3543a3f",
            "value": "0/1[09:15&lt;?,?it/s]"
          }
        },
        "260970bb1be34e0eb6ae0b4df3569a95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b427e72e1c2d4823ad6359701feef977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03a2e444acc5454ba9ad15153e2b9a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93b5477e79114423b8800f34da7762bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3be60fcb2724f64aeab0600b4630291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab96638e0e5842eb9090b27cb17f0e79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d713c621ab33437583be9f40a3543a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}