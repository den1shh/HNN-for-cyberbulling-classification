{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text classification with Quanvolutional layer + Attention + HQLSTM"
      ],
      "metadata": {
        "id": "IOw7Xm_A-Msu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "yXYmXj3x_Z3k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports for computations"
      ],
      "metadata": {
        "id": "fklFBxOt_n0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install custatevec_cu12\n",
        "!pip install pennylane pennylane-lightning-gpu\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "9KMjztfO_iLH",
        "outputId": "20143246-0e7b-4af0-d715-17167e02c356",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting custatevec_cu12\n",
            "  Downloading custatevec_cu12-1.6.0.post1-py3-none-manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Downloading custatevec_cu12-1.6.0.post1-py3-none-manylinux2014_x86_64.whl (38.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.7/38.7 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: custatevec_cu12\n",
            "Successfully installed custatevec_cu12-1.6.0.post1\n",
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.38.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting pennylane-lightning-gpu\n",
            "  Downloading PennyLane_Lightning_GPU-0.38.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.4.2)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.5.0)\n",
            "Collecting pennylane-lightning>=0.38 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.38.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane) (24.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.8.30)\n",
            "Downloading PennyLane-0.38.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning_GPU-0.38.0-cp310-cp310-manylinux_2_28_x86_64.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.38.0-cp310-cp310-manylinux_2_28_x86_64.whl (15.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.0-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.0/930.0 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: appdirs, rustworkx, autoray, pennylane-lightning, pennylane, pennylane-lightning-gpu\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.0 pennylane-0.38.0 pennylane-lightning-0.38.0 pennylane-lightning-gpu-0.38.0 rustworkx-0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For plotting data"
      ],
      "metadata": {
        "id": "pNda1wZNADCt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0HzKYqfvkO5s",
        "outputId": "31d2ebeb-b99e-4e46-a490-a4a8aa952bf6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.despine()\n",
        "# plt.style.use(\"seaborn-whitegrid\")\n",
        "plt.rc(\"figure\", autolayout=True)\n",
        "plt.rc(\"axes\", labelweight=\"bold\", labelsize=\"large\", titleweight=\"bold\", titlepad=10)\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For data preprocessing and text cleaning"
      ],
      "metadata": {
        "id": "qEByIz_FAyoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect\n",
        "!pip install contractions\n",
        "!pip install emoji==1.4.1\n",
        "!pip install nltk\n",
        "\n",
        "import re\n",
        "import string\n",
        "import emoji\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from langdetect import detect, LangDetectException\n",
        "import contractions\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "5pFgXpHkJ1fd",
        "outputId": "fc0be830-fe62-411f-c97b-12d3933962fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m655.4/981.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=500a54637bc8ad56ea15997c41da4acb4b0c8f5778e693b995afe3156f48ca26\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (13 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n",
            "Collecting emoji==1.4.1\n",
            "  Downloading emoji-1.4.1.tar.gz (185 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.1/185.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.4.1-py3-none-any.whl size=186377 sha256=73674577af882ccfb73d9f8ba7f97cf88b6b406bd5c006b46aefacc60b8a350e\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/27/d6/a425b9b845119a8e2f1fb85f405bc4ba2a836bd2805c3c8403\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.4.1\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set seed for reproductivity"
      ],
      "metadata": {
        "id": "Z-O5RGApBB0S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0Ud4hzR0kO5v"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qulacs pennylane-qulacs"
      ],
      "metadata": {
        "id": "f7yoa98G05eo",
        "outputId": "0f3a0ca3-3d9d-477c-c96d-0fa0de2816fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qulacs\n",
            "  Downloading qulacs-0.6.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting pennylane-qulacs\n",
            "  Downloading pennylane_qulacs-0.36.0.post0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from qulacs) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from qulacs) (1.13.1)\n",
            "Requirement already satisfied: pennylane>=0.15 in /usr/local/lib/python3.10/dist-packages (from pennylane-qulacs) (0.38.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (3.4.2)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (0.15.1)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (1.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (1.4.4)\n",
            "Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (0.7.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (5.5.0)\n",
            "Requirement already satisfied: pennylane-lightning>=0.38 in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (0.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane>=0.15->pennylane-qulacs) (24.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane>=0.15->pennylane-qulacs) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane>=0.15->pennylane-qulacs) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane>=0.15->pennylane-qulacs) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane>=0.15->pennylane-qulacs) (2024.8.30)\n",
            "Downloading qulacs-0.6.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (960 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.8/960.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pennylane_qulacs-0.36.0.post0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: qulacs, pennylane-qulacs\n",
            "Successfully installed pennylane-qulacs-0.36.0.post0 qulacs-0.6.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs_tn = {\n",
        "    # Contraction strategy to apply gates\n",
        "    \"contract\": False,\n",
        "    # Simplification sequence to apply to the tensor network\n",
        "    \"local_simplify\": \"DCRS\",\n",
        "    # Contraction optimizer to use\n",
        "    \"contraction_optimizer\": None,\n",
        "}"
      ],
      "metadata": {
        "id": "Cg2ZJiZj2UqE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmjJoJyZkO5v",
        "outputId": "f1c8b41c-e728-4c51-9d12-3fbe200d9c2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('cpu', <lightning.qubit device (wires=4) at 0x7edede104ee0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "num_qubits = 4\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = \"cpu\"\n",
        "# dev = qml.device('qulacs.simulator', wires = range(num_qubits))\n",
        "dev = qml.device(\"lightning.qubit\", wires=range(num_qubits))\n",
        "# dev = qml.device(\"default.tensor\", method=\"tn\", wires = range(num_qubits), **kwargs_tn)\n",
        "device, dev"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import data, data preprocessing and analysis"
      ],
      "metadata": {
        "id": "wh5ts37oBzek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use \"Cyberbullying Classification\" dataset from Kaggle. You can acquire more information about the data by the following link: https://www.kaggle.com/datasets/andrewmvd/cyberbullying-classification/data"
      ],
      "metadata": {
        "id": "NZHah9RUDkV1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PN22QbhmkO5v"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('cyberbullying_tweets.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rCNEZ-XakO5v",
        "outputId": "f60da740-fc14-4217-ba61-407d1de67a15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              tweet_text cyberbullying_type\n",
              "0      In other words #katandandre, your food was cra...  not_cyberbullying\n",
              "1      Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
              "2      @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
              "3      @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
              "4      @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying\n",
              "...                                                  ...                ...\n",
              "47687  Black ppl aren't expected to do anything, depe...          ethnicity\n",
              "47688  Turner did not withhold his disappointment. Tu...          ethnicity\n",
              "47689  I swear to God. This dumb nigger bitch. I have...          ethnicity\n",
              "47690  Yea fuck you RT @therealexel: IF YOURE A NIGGE...          ethnicity\n",
              "47691  Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...          ethnicity\n",
              "\n",
              "[47692 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08259583-5dc0-4176-abfc-f34d37913afc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>cyberbullying_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In other words #katandandre, your food was cra...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47687</th>\n",
              "      <td>Black ppl aren't expected to do anything, depe...</td>\n",
              "      <td>ethnicity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47688</th>\n",
              "      <td>Turner did not withhold his disappointment. Tu...</td>\n",
              "      <td>ethnicity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47689</th>\n",
              "      <td>I swear to God. This dumb nigger bitch. I have...</td>\n",
              "      <td>ethnicity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47690</th>\n",
              "      <td>Yea fuck you RT @therealexel: IF YOURE A NIGGE...</td>\n",
              "      <td>ethnicity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47691</th>\n",
              "      <td>Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...</td>\n",
              "      <td>ethnicity</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>47692 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08259583-5dc0-4176-abfc-f34d37913afc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-08259583-5dc0-4176-abfc-f34d37913afc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-08259583-5dc0-4176-abfc-f34d37913afc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eef26693-680f-4e73-9878-087f196c62c3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eef26693-680f-4e73-9878-087f196c62c3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eef26693-680f-4e73-9878-087f196c62c3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 47692,\n  \"fields\": [\n    {\n      \"column\": \"tweet_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 46017,\n        \"samples\": [\n          \"@AndyEaston85 Love how we are teaching the Bullshitters a lesson in football. Miss Bully and his message board posts.\",\n          \"GYUK | Anti-feminist YouTuber doubles down on vile Jess Phillips rape joke while leaping to the defence ...: In a video uploaded Thursday (April 23), former UKIP candidate Benjamin jumped to the defence of retired gay porn actor turned men's rights\\u2026 http://dlvr.it/RVRS8h\",\n          \"@Truth_Haqq Islam declared war on all mankind 1400 years ago. Now we return the favor. http://t.co/av4B4yCQzY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cyberbullying_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"not_cyberbullying\",\n          \"gender\",\n          \"ethnicity\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={'tweet_text': 'text', 'cyberbullying_type': 'sentiment'})"
      ],
      "metadata": {
        "id": "92KibKseK0C7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "NoSlde7eLDdp",
        "outputId": "cd8c0c41-c9d6-4215-c320-90bc4c1906a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text          sentiment\n",
              "0  In other words #katandandre, your food was cra...  not_cyberbullying\n",
              "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
              "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
              "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
              "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b86c5b8-35e5-41cc-9a49-e44f158739b6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In other words #katandandre, your food was cra...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b86c5b8-35e5-41cc-9a49-e44f158739b6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3b86c5b8-35e5-41cc-9a49-e44f158739b6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3b86c5b8-35e5-41cc-9a49-e44f158739b6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-34b4e619-a63a-4114-8607-c4b8a1cb855c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34b4e619-a63a-4114-8607-c4b8a1cb855c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-34b4e619-a63a-4114-8607-c4b8a1cb855c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 47692,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 46017,\n        \"samples\": [\n          \"@AndyEaston85 Love how we are teaching the Bullshitters a lesson in football. Miss Bully and his message board posts.\",\n          \"GYUK | Anti-feminist YouTuber doubles down on vile Jess Phillips rape joke while leaping to the defence ...: In a video uploaded Thursday (April 23), former UKIP candidate Benjamin jumped to the defence of retired gay porn actor turned men's rights\\u2026 http://dlvr.it/RVRS8h\",\n          \"@Truth_Haqq Islam declared war on all mankind 1400 years ago. Now we return the favor. http://t.co/av4B4yCQzY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"not_cyberbullying\",\n          \"gender\",\n          \"ethnicity\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define cleaning functions. Source: https://www.kaggle.com/code/ludovicocuoghi/detecting-bullying-tweets-pytorch-lstm-bert"
      ],
      "metadata": {
        "id": "PsXc6JwwCTMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean emojis from text\n",
        "def strip_emoji(text):\n",
        "    return emoji.get_emoji_regexp().sub(\"\", text)\n",
        "\n",
        "# Remove punctuations, stopwords, links, mentions and new line characters\n",
        "def strip_all_entities(text):\n",
        "    text = re.sub(r'\\r|\\n', ' ', text.lower())  # Replace newline and carriage return with space, and convert to lowercase\n",
        "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text)  # Remove links and mentions\n",
        "    text = re.sub(r'[^\\x00-\\x7f]', '', text)  # Remove non-ASCII characters\n",
        "    banned_list = string.punctuation\n",
        "    table = str.maketrans('', '', banned_list)\n",
        "    text = text.translate(table)\n",
        "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
        "    return text\n",
        "\n",
        "# Clean hashtags at the end of the sentence, and keep those in the middle of the sentence by removing just the # symbol\n",
        "def clean_hashtags(tweet):\n",
        "    # Remove hashtags at the end of the sentence\n",
        "    new_tweet = re.sub(r'(\\s+#[\\w-]+)+\\s*$', '', tweet).strip()\n",
        "\n",
        "    # Remove the # symbol from hashtags in the middle of the sentence\n",
        "    new_tweet = re.sub(r'#([\\w-]+)', r'\\1', new_tweet).strip()\n",
        "\n",
        "    return new_tweet\n",
        "\n",
        "# Filter special characters such as & and $ present in some words\n",
        "def filter_chars(text):\n",
        "    return ' '.join('' if ('$' in word) or ('&' in word) else word for word in text.split())\n",
        "\n",
        "# Remove multiple spaces\n",
        "def remove_mult_spaces(text):\n",
        "    return re.sub(r\"\\s\\s+\", \" \", text)\n",
        "\n",
        "# Function to check if the text is in English, and return an empty string if it's not\n",
        "def filter_non_english(text):\n",
        "    try:\n",
        "        lang = detect(text)\n",
        "    except LangDetectException:\n",
        "        lang = \"unknown\"\n",
        "    return text if lang == \"en\" else \"\"\n",
        "\n",
        "# Expand contractions\n",
        "def expand_contractions(text):\n",
        "    return contractions.fix(text)\n",
        "\n",
        "# Remove numbers\n",
        "def remove_numbers(text):\n",
        "    return re.sub(r'\\d+', '', text)\n",
        "\n",
        "# Lemmatize words\n",
        "def lemmatize(text):\n",
        "    words = word_tokenize(text)\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "# Remove short words\n",
        "def remove_short_words(text, min_len=2):\n",
        "    words = text.split()\n",
        "    long_words = [word for word in words if len(word) >= min_len]\n",
        "    return ' '.join(long_words)\n",
        "\n",
        "# Replace elongated words with their base form\n",
        "def replace_elongated_words(text):\n",
        "    regex_pattern = r'\\b(\\w+)((\\w)\\3{2,})(\\w*)\\b'\n",
        "    return re.sub(regex_pattern, r'\\1\\3\\4', text)\n",
        "\n",
        "# Remove repeated punctuation\n",
        "def remove_repeated_punctuation(text):\n",
        "    return re.sub(r'[\\?\\.\\!]+(?=[\\?\\.\\!])', '', text)\n",
        "\n",
        "# Remove extra whitespace\n",
        "def remove_extra_whitespace(text):\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "def remove_url_shorteners(text):\n",
        "    return re.sub(r'(?:http[s]?://)?(?:www\\.)?(?:bit\\.ly|goo\\.gl|t\\.co|tinyurl\\.com|tr\\.im|is\\.gd|cli\\.gs|u\\.nu|url\\.ie|tiny\\.cc|alturl\\.com|ow\\.ly|bit\\.do|adoro\\.to)\\S+', '', text)\n",
        "\n",
        "# Remove spaces at the beginning and end of the tweet\n",
        "def remove_spaces_tweets(tweet):\n",
        "    return tweet.strip()\n",
        "\n",
        "# Remove short tweets\n",
        "def remove_short_tweets(tweet, min_words=3):\n",
        "    words = tweet.split()\n",
        "    return tweet if len(words) >= min_words else \"\"\n",
        "\n",
        "# Function to call all the cleaning functions in the correct order\n",
        "def clean_tweet(tweet):\n",
        "    tweet = strip_emoji(tweet)\n",
        "    tweet = expand_contractions(tweet)\n",
        "    tweet = filter_non_english(tweet)\n",
        "    tweet = strip_all_entities(tweet)\n",
        "    tweet = clean_hashtags(tweet)\n",
        "    tweet = filter_chars(tweet)\n",
        "    tweet = remove_mult_spaces(tweet)\n",
        "    tweet = remove_numbers(tweet)\n",
        "    tweet = lemmatize(tweet)\n",
        "    tweet = remove_short_words(tweet)\n",
        "    tweet = replace_elongated_words(tweet)\n",
        "    tweet = remove_repeated_punctuation(tweet)\n",
        "    tweet = remove_extra_whitespace(tweet)\n",
        "    tweet = remove_url_shorteners(tweet)\n",
        "    tweet = remove_spaces_tweets(tweet)\n",
        "    tweet = remove_short_tweets(tweet)\n",
        "    tweet = ' '.join(tweet.split())  # Remove multiple spaces between words\n",
        "    return tweet"
      ],
      "metadata": {
        "id": "8RjOd2SaI8R_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_clean'] = [clean_tweet(tweet) for tweet in df['text']]"
      ],
      "metadata": {
        "id": "ECncuUbvLAHI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "RYNGL2_Uc4vP",
        "outputId": "9b8507c9-cac5-43b8-8b90-e762b4efc881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text          sentiment  \\\n",
              "0  In other words #katandandre, your food was cra...  not_cyberbullying   \n",
              "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying   \n",
              "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying   \n",
              "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying   \n",
              "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying   \n",
              "\n",
              "                                          text_clean  \n",
              "0             word katandandre food crapilicious mkr  \n",
              "1  aussietv white mkr theblock imacelebrityau tod...  \n",
              "2                    classy whore red velvet cupcake  \n",
              "3  meh thanks head concerned another angry dude t...  \n",
              "4  isi account pretending kurdish account like is...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25fe4e0a-1d2a-423e-9ec6-9a9f97471103\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In other words #katandandre, your food was cra...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>word katandandre food crapilicious mkr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>aussietv white mkr theblock imacelebrityau tod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>classy whore red velvet cupcake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>meh thanks head concerned another angry dude t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "      <td>isi account pretending kurdish account like is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25fe4e0a-1d2a-423e-9ec6-9a9f97471103')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-25fe4e0a-1d2a-423e-9ec6-9a9f97471103 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-25fe4e0a-1d2a-423e-9ec6-9a9f97471103');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb8dc463-afb9-4f39-951d-b7cab8f158da\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb8dc463-afb9-4f39-951d-b7cab8f158da')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb8dc463-afb9-4f39-951d-b7cab8f158da button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 47692,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 46017,\n        \"samples\": [\n          \"@AndyEaston85 Love how we are teaching the Bullshitters a lesson in football. Miss Bully and his message board posts.\",\n          \"GYUK | Anti-feminist YouTuber doubles down on vile Jess Phillips rape joke while leaping to the defence ...: In a video uploaded Thursday (April 23), former UKIP candidate Benjamin jumped to the defence of retired gay porn actor turned men's rights\\u2026 http://dlvr.it/RVRS8h\",\n          \"@Truth_Haqq Islam declared war on all mankind 1400 years ago. Now we return the favor. http://t.co/av4B4yCQzY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"not_cyberbullying\",\n          \"gender\",\n          \"ethnicity\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_clean\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 41370,\n        \"samples\": [\n          \"ooh good one bully girl unoreversecard shit high school saying can not handle called making dumb as comment fault making mine telling dumb hell\",\n          \"president make gay rape joke mocking molestation victim jordan even make news\",\n          \"donald trump bully elementary school would tattletale teacher anyone stood\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'There are around {int(df[\"text_clean\"].duplicated().sum())} duplicated tweets, we will remove them.')"
      ],
      "metadata": {
        "id": "Eh56r73aewhE",
        "outputId": "e0bcd169-4a09-4934-f874-4f8b66f10651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are around 6322 duplicated tweets, we will remove them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(\"text_clean\", inplace=True)"
      ],
      "metadata": {
        "id": "LNlO3hdhez4-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sentiment.value_counts()"
      ],
      "metadata": {
        "id": "LGEU8XC9e3Ue",
        "outputId": "30a08ebb-5b77-40c0-b84e-796ce19fdbcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "religion               7916\n",
              "age                    7813\n",
              "ethnicity              7407\n",
              "gender                 7279\n",
              "not_cyberbullying      6062\n",
              "other_cyberbullying    4893\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>religion</th>\n",
              "      <td>7916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>7813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ethnicity</th>\n",
              "      <td>7407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <td>7279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>not_cyberbullying</th>\n",
              "      <td>6062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>other_cyberbullying</th>\n",
              "      <td>4893</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, after cleaning classes are unbalanced so we will drop \"other_cyberbullying\" class as there is not enough data. Later we will oversample \"not_cyberbullying\" class."
      ],
      "metadata": {
        "id": "8qZ7PoaKC808"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df[\"sentiment\"]!=\"other_cyberbullying\"]"
      ],
      "metadata": {
        "id": "i-4tp2O8e-zw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_len'] = [len(text.split()) for text in df.text_clean]"
      ],
      "metadata": {
        "id": "Q712dE4kftOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e653bc8f-996d-4c87-a15e-e5265df95cd1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-fe586f79ef4e>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['text_len'] = [len(text.split()) for text in df.text_clean]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "ax = sns.countplot(x='text_len', data=df[df['text_len']<10], palette='mako')\n",
        "plt.title('Count of tweets with less than 10 words', fontsize=20)\n",
        "plt.yticks([])\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.ylabel('count')\n",
        "plt.xlabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WQjmvAMHfyG6",
        "outputId": "2a4d2a28-3e89-4178-e9c5-217e036ea37c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-1c28dcd112f5>:2: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x='text_len', data=df[df['text_len']<10], palette='mako')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,5))\n",
        "ax = sns.countplot(x='text_len', data=df[(df['text_len']<=1000) & (df['text_len']>10)], palette='Blues_r')\n",
        "plt.title('Count of tweets with high number of words', fontsize=25)\n",
        "plt.yticks([])\n",
        "ax.bar_label(ax.containers[0])\n",
        "plt.ylabel('count')\n",
        "plt.xlabel('')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ir99Mjatf7Sz",
        "outputId": "a2fa6798-54ff-419e-8fcf-1fb2b40c8614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-c8466336e1b1>:2: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x='text_len', data=df[(df['text_len']<=1000) & (df['text_len']>10)], palette='Blues_r')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['text_len'] < df['text_len'].quantile(0.995)]"
      ],
      "metadata": {
        "id": "Yx4uFQtBgNf_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = np.max(df['text_len'])\n",
        "max_len"
      ],
      "metadata": {
        "id": "sv5RTF8ggS7a",
        "outputId": "58a4dd8d-c18e-4023-9134-b49ddfe2549d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'] = df['sentiment'].replace({'religion':0,'age':1,'ethnicity':2,'gender':3,'not_cyberbullying':4})"
      ],
      "metadata": {
        "id": "QSjqH8-0gs9X",
        "outputId": "7ef2ad60-a121-497d-cb14-a4d739109ed8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-5cd3204e082e>:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['sentiment'] = df['sentiment'].replace({'religion':0,'age':1,'ethnicity':2,'gender':3,'not_cyberbullying':4})\n",
            "<ipython-input-24-5cd3204e082e>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['sentiment'] = df['sentiment'].replace({'religion':0,'age':1,'ethnicity':2,'gender':3,'not_cyberbullying':4})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text tokenization"
      ],
      "metadata": {
        "id": "oSjlhVvdEqEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Tokenize(column, seq_len):\n",
        "    ##Create vocabulary of words from column\n",
        "    corpus = [word for text in column for word in text.split()]\n",
        "    count_words = Counter(corpus)\n",
        "    sorted_words = count_words.most_common()\n",
        "    vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n",
        "\n",
        "    ##Tokenize the columns text using the vocabulary\n",
        "    text_int = []\n",
        "    for text in column:\n",
        "        r = [vocab_to_int[word] for word in text.split()]\n",
        "        text_int.append(r)\n",
        "    ##Add padding to tokens\n",
        "    features = np.zeros((len(text_int), seq_len), dtype = int)\n",
        "    for i, review in enumerate(text_int):\n",
        "        if len(review) <= seq_len:\n",
        "            zeros = list(np.zeros(seq_len - len(review)))\n",
        "            new = zeros + review\n",
        "        else:\n",
        "            new = review[: seq_len]\n",
        "        features[i, :] = np.array(new)\n",
        "\n",
        "    return sorted_words, features"
      ],
      "metadata": {
        "id": "nPIz-dF6kFEH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary, tokenized_column = Tokenize(df[\"text_clean\"], max_len)"
      ],
      "metadata": {
        "id": "KqUTb1b8kd9P"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text_clean']\n",
        "y = df['sentiment']"
      ],
      "metadata": {
        "id": "d02_zwPL-9EZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "2azevoNY-y6g"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text embedding with pre-trained Word2vec model"
      ],
      "metadata": {
        "id": "idKd2ISaEy9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Word2vec_train_data = list(map(lambda x: x.split(), X_train))"
      ],
      "metadata": {
        "id": "_TdbROTk7nYE"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 200"
      ],
      "metadata": {
        "id": "EefOe-5Y7rSm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = Word2Vec(Word2vec_train_data, vector_size=EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "fSmBTU0Y7vMO"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(vocabulary) + 1 #+1 for the padding"
      ],
      "metadata": {
        "id": "IZyohOul7yPO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an empty embedding matrix of shape (VOCAB_SIZE, EMBEDDING_DIM)\n",
        "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
        "\n",
        "# Fill the embedding matrix with pre-trained values from word2vec\n",
        "for word, token in vocabulary:\n",
        "    # Check if the word is present in the word2vec model's vocabulary\n",
        "    if word in word2vec_model.wv.key_to_index:\n",
        "        # If the word is present, retrieve its embedding vector and add it to the embedding matrix\n",
        "        embedding_vector = word2vec_model.wv[word]\n",
        "        embedding_matrix[token] = embedding_vector\n",
        "\n",
        "# Print the shape of the embedding matrix\n",
        "print(\"Embedding Matrix Shape:\", embedding_matrix.shape)"
      ],
      "metadata": {
        "id": "nx5AIcgi68QL",
        "outputId": "94715133-007a-4b77-faa8-b7bb1fad6019",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Matrix Shape: (37560, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = tokenized_column\n",
        "y = df['sentiment'].values"
      ],
      "metadata": {
        "id": "tfO4cnjz7_Ot"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "EOAc1Vm38Njv"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oversampling"
      ],
      "metadata": {
        "id": "Ly-3aQBnFRcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler()\n",
        "X_train_os, y_train_os = ros.fit_resample(np.array(X_train),np.array(y_train))"
      ],
      "metadata": {
        "id": "achdE0dQ8WEO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_os.shape"
      ],
      "metadata": {
        "id": "sac738LjIWXP",
        "outputId": "864194da-252b-44c6-8f3f-a21764cad6f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31350, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we define our preprocessed dataset and loaders"
      ],
      "metadata": {
        "id": "dGYWBOQ0FW2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TensorDataset(torch.from_numpy(X_train_os), torch.from_numpy(y_train_os))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))"
      ],
      "metadata": {
        "id": "jyEGOm9Z8ffa"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "WjpbNrLb8jN2"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE, drop_last=True)"
      ],
      "metadata": {
        "id": "mr-o8hPq8lXW"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of the classical model"
      ],
      "metadata": {
        "id": "g2V1uSsNFp3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this paragraph we will implement model with classical convolution and LSTM in order to compare it with its hybrid-quantum analogue"
      ],
      "metadata": {
        "id": "660eM2fEF30E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(Attention, self).__init__()\n",
        "        # The attention linear layer which transforms the input data to the hidden space\n",
        "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim )\n",
        "        # The linear layer that calculates the attention scores\n",
        "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        seq_len = encoder_outputs.size(1)\n",
        "        # Concatenate the last two hidden states in case of a bidirectional LSTM\n",
        "        hidden = hidden[-1]\n",
        "        # Repeat the hidden state across the sequence length\n",
        "        hidden_repeated = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
        "        # Calculate attention weights\n",
        "        attn_weights = torch.tanh(self.attn(torch.cat((hidden_repeated, encoder_outputs), dim=2)))\n",
        "        # Compute attention scores\n",
        "        attn_weights = self.v(attn_weights).squeeze(2)\n",
        "        # Apply softmax to get valid probabilities\n",
        "        return nn.functional.softmax(attn_weights, dim=1)"
      ],
      "metadata": {
        "id": "-VTp5AVlJA3l"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassicalModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, in_channels, out_channels, kernel_size, stride, padding, hidden_dim, num_classes, lstm_layers):\n",
        "        super(ClassicalModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = lstm_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, lstm_layers, batch_first=True)\n",
        "        self.attention = Attention(hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # Transform words to embeddings\n",
        "        embedded = self.embedding(x)\n",
        "        # embedded = self.conv(embedded.unsqueeze(1))\n",
        "        # # Pass embeddings to LSTM\n",
        "        # out, hidden = self.lstm(embedded.reshape(-1, embedded.size(1)*embedded.size(2), embedded.size(-1)), hidden)\n",
        "        out, hidden = self.lstm(embedded, hidden)\n",
        "        # Calculate attention weights\n",
        "        attn_weights = self.attention(hidden[0], out)\n",
        "        # Calculate context vector by taking the weighted sum of LSTM outputs\n",
        "        context = attn_weights.unsqueeze(1).bmm(out).squeeze(1)\n",
        "        # Classify the context vector\n",
        "        out = self.softmax(self.fc(context))\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
        "        return h0, c0"
      ],
      "metadata": {
        "id": "raK4JVSHExXS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of the hybrid-quantum model"
      ],
      "metadata": {
        "id": "iFolBcU3GjzL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Zx9MSDbdkO5y"
      },
      "outputs": [],
      "source": [
        "@qml.qnode(dev, interface='torch')\n",
        "def quanvcirc(patch, weights, wires=range(num_qubits)):\n",
        "    # Angle embedding of the patch (reshape to match expected size)\n",
        "    qml.AngleEmbedding(patch, wires=wires, rotation='Y')\n",
        "\n",
        "    # Apply RX rotations based on the weights\n",
        "    qml.RX(weights[0][0], wires=0)\n",
        "    qml.RX(weights[0][1], wires=1)\n",
        "    qml.RY(weights[1][0], wires=2)\n",
        "    qml.RY(weights[1][1], wires=3)\n",
        "\n",
        "    # Apply CNOT gates\n",
        "    qml.CNOT(wires=[0, 1])\n",
        "    qml.CNOT(wires=[1, 2])\n",
        "    qml.CNOT(wires=[2, 3])\n",
        "    qml.CNOT(wires=[3, 0])\n",
        "    # Apply RY rotations based on the weights\n",
        "\n",
        "\n",
        "    # Return the expectation values of Pauli-Z measurements on all qubits\n",
        "    return qml.expval(qml.PauliZ(0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(qml.draw(quanvcirc)(np.ones((1, 4)), np.ones((2, 2))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G1L7z_enlfZ",
        "outputId": "2bec97be-b42e-49eb-e113-1f50e6649e28"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: ─╭AngleEmbedding(M0)──RX(1.00)─╭●───────╭X─┤  <Z>\n",
            "1: ─├AngleEmbedding(M0)──RX(1.00)─╰X─╭●────│──┤     \n",
            "2: ─├AngleEmbedding(M0)──RY(1.00)────╰X─╭●─│──┤     \n",
            "3: ─╰AngleEmbedding(M0)──RY(1.00)───────╰X─╰●─┤     \n",
            "\n",
            "M0 = \n",
            "[[1. 1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QuanConv2D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        super(QuanConv2D, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "        # Define weights and biases as trainable parameters\n",
        "        self.weights = nn.Parameter(\n",
        "            torch.randn(out_channels, in_channels, kernel_size, kernel_size), requires_grad = True\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Extract dimensions\n",
        "        batch_size, in_channels, input_height, input_width = input.shape\n",
        "\n",
        "        # Calculate output dimensions\n",
        "        output_height = (input_height - self.kernel_size + 2 * self.padding) // self.stride + 1\n",
        "        output_width = (input_width - self.kernel_size + 2 * self.padding) // self.stride + 1\n",
        "\n",
        "        # Initialize output tensor\n",
        "        output = torch.zeros(batch_size, self.out_channels, output_height, output_width)\n",
        "\n",
        "        # If padding is required, add it to the input\n",
        "        if self.padding > 0:\n",
        "            input = F.pad(input, (self.padding, self.padding, self.padding, self.padding))\n",
        "\n",
        "        # Perform convolution\n",
        "        for b in range(batch_size):\n",
        "            for c_out in range(self.out_channels):\n",
        "                for h in range(output_height):\n",
        "                    for w in range(output_width):\n",
        "                        h_start = h * self.stride\n",
        "                        h_end = h_start + self.kernel_size\n",
        "                        w_start = w * self.stride\n",
        "                        w_end = w_start + self.kernel_size\n",
        "\n",
        "                        # Slice the input for the current window\n",
        "                        input_slice = input[b, :, h_start:h_end, w_start:w_end]\n",
        "\n",
        "                        # Perform element-wise multiplication and sum with bias\n",
        "                        output[b, c_out, h, w] = quanvcirc(input_slice.reshape(1, self.kernel_size * self.kernel_size), self.weights[c_out].squeeze(0))\n",
        "        return output"
      ],
      "metadata": {
        "id": "ikYNnTA1pr6A"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qdi_reps1 = 2\n",
        "qdi_reps2 = 2\n",
        "qdi_depth = 1"
      ],
      "metadata": {
        "id": "ZXzmC0KuyEDb"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@qml.qnode(dev, interface='torch', diff_method=\"adjoint\")\n",
        "def qdi_circuit(weights, input_array, wires=range(num_qubits)):\n",
        "    for r in range(qdi_reps1):\n",
        "        for i in range(len(wires)):\n",
        "            qml.RX(weights[r][i], wires=wires[i])\n",
        "        for j in range(len(wires)-1):\n",
        "            qml.CNOT(wires=[wires[j], wires[j+1]])\n",
        "        qml.CNOT(wires=[wires[len(wires)-1], wires[0]])\n",
        "        # qml.Barrier()\n",
        "    for d in range(qdi_depth):\n",
        "        qml.AngleEmbedding(input_array, wires=range(num_qubits), rotation='Z')\n",
        "        for r in range(qdi_reps2):\n",
        "            for i in range(len(wires)):\n",
        "                qml.RX(weights[qdi_reps1+d*r][i], wires=wires[i])\n",
        "            for j in range(len(wires)-1):\n",
        "                qml.CNOT(wires=[wires[j], wires[j+1]])\n",
        "            qml.CNOT(wires=[wires[len(wires)-1], wires[0]])\n",
        "            # qml.Barrier()\n",
        "        # qml.Barrier()\n",
        "    return [qml.expval(qml.PauliY(w)) for w in wires]"
      ],
      "metadata": {
        "id": "QixHflZxxt-Y"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(qml.draw(qdi_circuit)(np.ones((qdi_reps1 + qdi_reps2, num_qubits)), np.ones((4, 4))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRFx50H6RkcR",
        "outputId": "6c3c5367-a2d3-4332-d6b1-e9e445cc563f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: ──RX(1.00)─╭●───────╭X──RX(1.00)─╭●───────╭X─╭AngleEmbedding(M0)──RX(1.00)─╭●───────╭X──RX(1.00)\n",
            "1: ──RX(1.00)─╰X─╭●────│───RX(1.00)─╰X─╭●────│──├AngleEmbedding(M0)──RX(1.00)─╰X─╭●────│───RX(1.00)\n",
            "2: ──RX(1.00)────╰X─╭●─│───RX(1.00)────╰X─╭●─│──├AngleEmbedding(M0)──RX(1.00)────╰X─╭●─│───RX(1.00)\n",
            "3: ──RX(1.00)───────╰X─╰●──RX(1.00)───────╰X─╰●─╰AngleEmbedding(M0)──RX(1.00)───────╰X─╰●──RX(1.00)\n",
            "\n",
            "──╭●───────╭X─┤  <Y>\n",
            "──╰X─╭●────│──┤  <Y>\n",
            "─────╰X─╭●─│──┤  <Y>\n",
            "────────╰X─╰●─┤  <Y>\n",
            "\n",
            "M0 = \n",
            "[[1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HQLSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_qubits):\n",
        "        super(HQLSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Combined weights for efficiency\n",
        "        self.W_input = nn.Parameter(torch.rand(4 * num_qubits, input_size), requires_grad = True).float()\n",
        "        self.W_hid = nn.Parameter(torch.rand(4 * num_qubits, hidden_size), requires_grad = True).float()\n",
        "        self.W_quan = nn.Parameter(torch.zeros(4, qdi_reps1 + qdi_reps2, num_qubits), requires_grad = True).float()\n",
        "        self.W = nn.Parameter(torch.rand(4, hidden_size, num_qubits), requires_grad = True).float()\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        h_prev, c_prev = hidden\n",
        "\n",
        "        yield_input = F.linear(x, self.W_input)\n",
        "        yield_hidden = F.linear(h_prev, self.W_hid)\n",
        "        # Concatenate input and previous hidden state\n",
        "        combined = yield_input + yield_hidden\n",
        "        # combined = torch.cat((yield_input, yield_hidden), dim=1)\n",
        "\n",
        "        # Apply linear transformation\n",
        "\n",
        "        # Split into gates\n",
        "        # combined = torch.cat([torch.stack(qdi_circuit(self.W_quan[i], combined[:, i:i*num_qubits].reshape(-1, num_qubits))) for i in range(num_qubits)], dim = 0)\n",
        "        i_gate = F.linear(torch.stack(qdi_circuit(self.W_quan[0], combined[:, :num_qubits].reshape(-1, num_qubits))).T.float(), self.W[0])\n",
        "        f_gate = F.linear(torch.stack(qdi_circuit(self.W_quan[1], combined[:, num_qubits:2*num_qubits].reshape(-1, num_qubits))).T.float(), self.W[1])\n",
        "        g_gate = F.linear(torch.stack(qdi_circuit(self.W_quan[2], combined[:, 2*num_qubits:3*num_qubits].reshape(-1, num_qubits))).T.float(), self.W[2])\n",
        "        o_gate = F.linear(torch.stack(qdi_circuit(self.W_quan[3], combined[:, 3*num_qubits:4*num_qubits].reshape(-1, num_qubits))).T.float(), self.W[3])\n",
        "\n",
        "\n",
        "\n",
        "        # combined = torch.cat((i_gate, f_gate, g_gate, o_gate), dim=0).float()\n",
        "        # gates = F.linear(combined, self.W)\n",
        "\n",
        "        # # Split into gates\n",
        "        # i_gate, f_gate, g_gate, o_gate = gates.chunk(4, 0)\n",
        "\n",
        "        # Apply non-linearities\n",
        "        i_gate = torch.sigmoid(i_gate)\n",
        "        f_gate = torch.sigmoid(f_gate)\n",
        "        g_gate = torch.tanh(g_gate)\n",
        "        o_gate = torch.sigmoid(o_gate)\n",
        "\n",
        "        # Update cell state\n",
        "        c_next = (f_gate * c_prev) + (i_gate * g_gate)\n",
        "\n",
        "        # Update hidden state\n",
        "        h_next = o_gate * torch.tanh(c_next)\n",
        "\n",
        "        return h_next, c_next\n",
        "\n",
        "\n",
        "class HQLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_qubits, num_layers=1):\n",
        "        super(HQLSTM, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm_cells = nn.ModuleList([HQLSTMCell(input_size if l==0 else hidden_size, hidden_size, num_qubits) for l in range(num_layers)])\n",
        "\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        if hidden is None:\n",
        "             h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "             c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "        else:\n",
        "            h0, c0 = hidden\n",
        "\n",
        "        output_seq = []\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            input_t = x[:, t, :] # input at current timestep\n",
        "            # print(f'step:{t}/{seq_len}, hidden:')\n",
        "\n",
        "            new_h = []\n",
        "            new_c = []\n",
        "\n",
        "            for layer in range(self.num_layers):\n",
        "\n",
        "                # Get hidden state for current layer\n",
        "                h_t, c_t = self.lstm_cells[layer](input_t, (h0[layer], c0[layer]))\n",
        "\n",
        "                # Update hidden states for next timestep, for current layer\n",
        "                new_h.append(h_t)\n",
        "                new_c.append(c_t)\n",
        "                input_t = h_t # The output of current layer is input for the next\n",
        "\n",
        "            h0 = torch.stack(new_h)\n",
        "            c0 = torch.stack(new_c)\n",
        "            # Append hidden state at the topmost layer\n",
        "            output_seq.append(h_t.unsqueeze(1))\n",
        "\n",
        "        # Concatenate the outputs over the sequence length\n",
        "        output_seq = torch.cat(output_seq, dim=1) # output_seq is of shape (batch_size, seq_len, hidden_size)\n",
        "\n",
        "        return output_seq, (h0, c0)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "v_mvdRnDqcze"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Toy hybrid-quantum model for benchmarking"
      ],
      "metadata": {
        "id": "py3iiomANCjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ToyHQModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, in_channels, out_channels, kernel_size, stride, padding, hidden_dim, num_qubits, num_classes, lstm_layers):\n",
        "        super(ToyHQModel, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.num_layers = lstm_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.attention = Attention(hidden_dim)\n",
        "        # self.conv = QuanConv2D(self.in_channels, self.out_channels, self.kernel_size, self.stride, self.padding)\n",
        "        self.lstm = HQLSTM(embedding_dim, hidden_dim, num_qubits, lstm_layers)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Transform words to embeddings\n",
        "        embedded = self.embedding(x)\n",
        "        # x = self.conv(x.unsqueeze(1)).to(device)\n",
        "        # Pass embeddings to LSTM\n",
        "        out, hidden = self.lstm(embedded)\n",
        "        # Calculate attention weights\n",
        "        attn_weights = self.attention(hidden[0], out)\n",
        "        # Calculate context vector by taking the weighted sum of LSTM outputs\n",
        "        context = attn_weights.unsqueeze(1).bmm(out).squeeze(1)\n",
        "        # Classify the context vector\n",
        "        out = self.softmax(self.fc(context))\n",
        "        return out\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
        "        return h0, c0"
      ],
      "metadata": {
        "id": "RRz02NuCLNvM"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridQuantumModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, in_channels, out_channels, kernel_size, stride, padding, hidden_dim, num_qubits, num_classes, lstm_layers):\n",
        "        super(HybridQuantumModel, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = HQLSTM(embedding_dim, hidden_dim, num_qubits, lstm_layers)\n",
        "        self.attention = Attention(hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Transform words to embeddings\n",
        "        embedded = self.embedding(x)\n",
        "        # embedded = self.conv(embedded.unsqueeze(1)).to(device)\n",
        "        # Pass embeddings to LSTM\n",
        "        # out, hidden = self.lstm(embedded.reshape(-1, embedded.size(1)*embedded.size(2), embedded.size(-1)))\n",
        "        out, hidden = self.lstm(embedded)\n",
        "        # Calculate attention weights\n",
        "        attn_weights = self.attention(hidden[0], out)\n",
        "        # Calculate context vector by taking the weighted sum of LSTM outputs\n",
        "        context = attn_weights.unsqueeze(1).bmm(out).squeeze(1)\n",
        "        # Classify the context vector\n",
        "        out = self.softmax(self.fc(context))\n",
        "        return out"
      ],
      "metadata": {
        "id": "0V4YMT0JN6Sy"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the models"
      ],
      "metadata": {
        "id": "uvla_k_6IWAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 5 #We are dealing with a multiclass classification of 5 classes\n",
        "HIDDEN_DIM = 100 #number of neurons of the internal state (internal neural network in the LSTM)\n",
        "LSTM_LAYERS = 1 #Number of stacked LSTM layers\n",
        "IN_CHANNELS = 1\n",
        "OUT_CHANNELS = 5\n",
        "KERNEL_SIZE = 2\n",
        "STRIDE = 1\n",
        "PADDING = 1\n",
        "\n",
        "\n",
        "LR = 8e-4 #Learning rate\n",
        "EPOCHS = 10 #Number of training epoch\n",
        "\n",
        "criterion = nn.NLLLoss()"
      ],
      "metadata": {
        "id": "bbH3jVkhSWCr"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classical_model = ClassicalModel(VOCAB_SIZE, EMBEDDING_DIM, IN_CHANNELS, OUT_CHANNELS, KERNEL_SIZE, STRIDE, PADDING, HIDDEN_DIM, NUM_CLASSES, LSTM_LAYERS)\n",
        "classical_model = classical_model.to(device)\n",
        "# classical_model = torch.compile(classical_model)\n",
        "\n",
        "cl_optimizer = torch.optim.AdamW(classical_model.parameters(), lr=LR, weight_decay = 5e-6)\n",
        "\n",
        "print(classical_model)"
      ],
      "metadata": {
        "id": "lJnLZ5GCMMNF",
        "outputId": "6bbdfd11-9d94-4d5f-dd61-3d08452a43fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClassicalModel(\n",
            "  (embedding): Embedding(37584, 200)\n",
            "  (conv): Conv2d(1, 5, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "  (lstm): LSTM(200, 100, batch_first=True)\n",
            "  (attention): Attention(\n",
            "    (attn): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (v): Linear(in_features=100, out_features=1, bias=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(model):\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'embedding' in name:\n",
        "            nn.init.uniform_(param, -0.1, 0.1)\n",
        "        elif 'lstm' in name:\n",
        "            if 'weight' in name:\n",
        "                nn.init.orthogonal_(param)\n",
        "            elif 'bias' in name:\n",
        "                nn.init.constant_(param, 0)\n",
        "        elif 'fc' in name:\n",
        "            nn.init.xavier_uniform_(param)"
      ],
      "metadata": {
        "id": "vWLWMuTwu-ZR"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hybrid_quantum_model = HybridQuantumModel(VOCAB_SIZE, EMBEDDING_DIM, IN_CHANNELS, OUT_CHANNELS, KERNEL_SIZE, STRIDE, PADDING, HIDDEN_DIM, num_qubits, NUM_CLASSES, LSTM_LAYERS)\n",
        "hybrid_quantum_model = hybrid_quantum_model.to(device)\n",
        "# initialize_weights(hybrid_quantum_model)\n",
        "\n",
        "\n",
        "# hybrid_quantum_model = torch.compile(hybrid_quantum_model)\n",
        "\n",
        "hq_optimizer = torch.optim.AdamW(hybrid_quantum_model.parameters(), lr=LR, weight_decay = 5e-6)\n",
        "\n",
        "print(hybrid_quantum_model)"
      ],
      "metadata": {
        "id": "_yVpeUhBSeXi",
        "outputId": "82533239-fb6e-47c4-bd0f-4462701a9b0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HybridQuantumModel(\n",
            "  (embedding): Embedding(37560, 200)\n",
            "  (lstm): HQLSTM(\n",
            "    (lstm_cells): ModuleList(\n",
            "      (0): HQLSTMCell()\n",
            "    )\n",
            "  )\n",
            "  (attention): Attention(\n",
            "    (attn): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (v): Linear(in_features=100, out_features=1, bias=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ObgTsuW6kO5z"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train(model, criterion, optimizer,\n",
        "          train_dataloader, test_dataloader, num_epochs):\n",
        "\n",
        "    train_losses = np.zeros(num_epochs)\n",
        "    test_losses = np.zeros(num_epochs)\n",
        "\n",
        "    train_accuracy_arr = np.zeros(num_epochs)\n",
        "    test_accuracy_arr = np.zeros(num_epochs)\n",
        "\n",
        "    for i_epoch in tqdm(range(num_epochs)):\n",
        "        it = 0\n",
        "        train_loss = 0\n",
        "        test_loss = 0\n",
        "\n",
        "        train_accuracy = 0\n",
        "        test_accuracy = 0\n",
        "\n",
        "        # train step\n",
        "        model.train()\n",
        "        for batch in train_dataloader:\n",
        "            start_time = time.time()\n",
        "            X = batch[0].to(device)\n",
        "            y = batch[1].to(device)\n",
        "\n",
        "            h = model.init_hidden(y.size(0))\n",
        "            # model forward-pass\n",
        "            preds, h = model(X, h)\n",
        "\n",
        "            # model backward-pass\n",
        "            optimizer.zero_grad() # t.grad = torch.tensor([0., 0., 0.])\n",
        "            loss = criterion(preds, y)\n",
        "            loss.backward()\n",
        "            optimizer.step() # t = t - lr * t.grad\n",
        "            end_time = time.time()\n",
        "            execution_time = end_time - start_time\n",
        "\n",
        "            # save loss and accuracy\n",
        "            train_loss += loss.detach().cpu().numpy()\n",
        "            print(f'batch: {it+1}/{len(train_dataloader)}, loss: {train_loss/(it+1):.4f}, time: {execution_time:.4f}')\n",
        "            it += 1\n",
        "            train_accuracy += (preds.argmax(-1).detach() == y).cpu().numpy().mean()\n",
        "\n",
        "\n",
        "        train_loss /= len(train_dataloader)\n",
        "        train_accuracy /= len(train_dataloader)\n",
        "        train_losses[i_epoch] = train_loss\n",
        "        train_accuracy_arr[i_epoch] = train_accuracy\n",
        "\n",
        "        # test step\n",
        "        model.eval()\n",
        "        for batch in test_dataloader:\n",
        "            X = batch[0].to(device)\n",
        "            y = batch[1].to(device)\n",
        "\n",
        "            h = model.init_hidden(y.size(0))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # model forward-pass\n",
        "                preds, h = model(X, h)\n",
        "                loss = criterion(preds, y)\n",
        "\n",
        "                # save loss and accuracy\n",
        "                test_loss += loss.detach().cpu().numpy()\n",
        "                test_accuracy += (preds.argmax(-1) == y).cpu().numpy().mean()\n",
        "\n",
        "\n",
        "        test_loss /= len(test_dataloader)\n",
        "        test_accuracy /= len(test_dataloader)\n",
        "\n",
        "        test_losses[i_epoch] = test_loss\n",
        "        test_accuracy_arr[i_epoch] = test_accuracy\n",
        "\n",
        "    return train_losses, test_losses, train_accuracy_arr, test_accuracy_arr\n",
        "\n",
        "def train_for_hqnn(model, criterion, optimizer,\n",
        "          train_dataloader, test_dataloader, num_epochs):\n",
        "\n",
        "    train_losses = np.zeros(num_epochs)\n",
        "    test_losses = np.zeros(num_epochs)\n",
        "\n",
        "    train_accuracy_arr = np.zeros(num_epochs)\n",
        "    test_accuracy_arr = np.zeros(num_epochs)\n",
        "\n",
        "    for i_epoch in tqdm(range(num_epochs)):\n",
        "        it = 0\n",
        "\n",
        "        train_loss = 0\n",
        "        test_loss = 0\n",
        "\n",
        "        train_accuracy = 0\n",
        "        test_accuracy = 0\n",
        "\n",
        "        # train step\n",
        "        model.train()\n",
        "        for batch in train_dataloader:\n",
        "            start_time = time.time()\n",
        "            X = batch[0].to(device)\n",
        "            y = batch[1].to(device)\n",
        "\n",
        "            # model forward-pass\n",
        "            preds = model(X)\n",
        "\n",
        "            # model backward-pass\n",
        "            optimizer.zero_grad() # t.grad = torch.tensor([0., 0., 0.])\n",
        "            loss = criterion(preds, y)\n",
        "            loss.backward()\n",
        "            optimizer.step() # t = t - lr * t.grad\n",
        "            end_time = time.time()\n",
        "            execution_time = end_time - start_time\n",
        "\n",
        "            # save loss and accuracy\n",
        "            train_loss += loss.detach().cpu().numpy()\n",
        "            print(f'it: {it+1}/{len(train_dataloader)}, loss: {train_loss/(it+1):.4f}, time: {execution_time:.4f}')\n",
        "            it += 1\n",
        "            train_accuracy += (preds.argmax(-1).detach() == y).cpu().numpy().mean()\n",
        "\n",
        "\n",
        "        train_loss /= len(train_dataloader)\n",
        "        train_accuracy /= len(train_dataloader)\n",
        "        train_losses[i_epoch] = train_loss\n",
        "\n",
        "        train_accuracy_arr[i_epoch] = train_accuracy\n",
        "\n",
        "        # test step\n",
        "        model.eval()\n",
        "        for batch in test_dataloader:\n",
        "            X = batch[0].to(device)\n",
        "            y = batch[1].to(device)\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # model forward-pass\n",
        "                preds = model(X)\n",
        "                loss = criterion(preds, y)\n",
        "\n",
        "                # save loss and accuracy\n",
        "                test_loss += loss.detach().cpu().numpy()\n",
        "                test_accuracy += (preds.argmax(-1) == y).cpu().numpy().mean()\n",
        "\n",
        "\n",
        "        test_loss /= len(test_dataloader)\n",
        "        test_accuracy /= len(test_dataloader)\n",
        "\n",
        "        test_losses[i_epoch] = test_loss\n",
        "        test_accuracy_arr[i_epoch] = test_accuracy\n",
        "\n",
        "    return train_losses, test_losses, train_accuracy_arr, test_accuracy_arr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cl_train_losses, \\\n",
        "    cl_test_losses, \\\n",
        "    cl_train_accuracy_arr, \\\n",
        "    cl_test_accuracy_arr = train(classical_model, criterion=criterion,\n",
        "                              optimizer=cl_optimizer,\n",
        "                              train_dataloader=train_loader,\n",
        "                              test_dataloader=test_loader,\n",
        "                              num_epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "661cd90b76c9451f98e0ca29c4b22d44",
            "d702bf265eca4bbbbcb7a358df381c65",
            "fc30a6a4b6064be0b3c4a786a4b64952",
            "df78c6ab42474534a547a0a7ba44b754",
            "d49849d9283546c9b34517f327232757",
            "8562c9e4bc8443db82350ff5f496958b",
            "e17bf6667ccd4167af9110a09ba012ac",
            "60ed458c82de4401a7eb400c23f1338d",
            "673f3f8df9244b538ad88f1fc82442b6",
            "029421ef2fec489b8b379351e00e188a",
            "98cad26d7f274b71a04d37fca89196bf"
          ]
        },
        "id": "1swJ9EmxZKAT",
        "outputId": "17589abb-15b9-4765-8297-2967fc10a0b5",
        "collapsed": true
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "661cd90b76c9451f98e0ca29c4b22d44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch: 1/979, loss: 1.6025, time: 0.1276\n",
            "batch: 2/979, loss: 1.5963, time: 0.0033\n",
            "batch: 3/979, loss: 1.5963, time: 0.0028\n",
            "batch: 4/979, loss: 1.5950, time: 0.0028\n",
            "batch: 5/979, loss: 1.5930, time: 0.0028\n",
            "batch: 6/979, loss: 1.6064, time: 0.0027\n",
            "batch: 7/979, loss: 1.6050, time: 0.0026\n",
            "batch: 8/979, loss: 1.6055, time: 0.0027\n",
            "batch: 9/979, loss: 1.5994, time: 0.0027\n",
            "batch: 10/979, loss: 1.5931, time: 0.0027\n",
            "batch: 11/979, loss: 1.5954, time: 0.0028\n",
            "batch: 12/979, loss: 1.5932, time: 0.0027\n",
            "batch: 13/979, loss: 1.5869, time: 0.0026\n",
            "batch: 14/979, loss: 1.5778, time: 0.0028\n",
            "batch: 15/979, loss: 1.5739, time: 0.0027\n",
            "batch: 16/979, loss: 1.5638, time: 0.0028\n",
            "batch: 17/979, loss: 1.5614, time: 0.0027\n",
            "batch: 18/979, loss: 1.5603, time: 0.0027\n",
            "batch: 19/979, loss: 1.5515, time: 0.0026\n",
            "batch: 20/979, loss: 1.5483, time: 0.0028\n",
            "batch: 21/979, loss: 1.5448, time: 0.0031\n",
            "batch: 22/979, loss: 1.5425, time: 0.0028\n",
            "batch: 23/979, loss: 1.5357, time: 0.0027\n",
            "batch: 24/979, loss: 1.5311, time: 0.0026\n",
            "batch: 25/979, loss: 1.5261, time: 0.0027\n",
            "batch: 26/979, loss: 1.5210, time: 0.0027\n",
            "batch: 27/979, loss: 1.5169, time: 0.0027\n",
            "batch: 28/979, loss: 1.5111, time: 0.0027\n",
            "batch: 29/979, loss: 1.5037, time: 0.0026\n",
            "batch: 30/979, loss: 1.4953, time: 0.0028\n",
            "batch: 31/979, loss: 1.4872, time: 0.0027\n",
            "batch: 32/979, loss: 1.4800, time: 0.0027\n",
            "batch: 33/979, loss: 1.4757, time: 0.0028\n",
            "batch: 34/979, loss: 1.4675, time: 0.0050\n",
            "batch: 35/979, loss: 1.4622, time: 0.0027\n",
            "batch: 36/979, loss: 1.4502, time: 0.0027\n",
            "batch: 37/979, loss: 1.4417, time: 0.0026\n",
            "batch: 38/979, loss: 1.4324, time: 0.0034\n",
            "batch: 39/979, loss: 1.4227, time: 0.0034\n",
            "batch: 40/979, loss: 1.4134, time: 0.0032\n",
            "batch: 41/979, loss: 1.4031, time: 0.0035\n",
            "batch: 42/979, loss: 1.3898, time: 0.0034\n",
            "batch: 43/979, loss: 1.3809, time: 0.0035\n",
            "batch: 44/979, loss: 1.3737, time: 0.0033\n",
            "batch: 45/979, loss: 1.3659, time: 0.0034\n",
            "batch: 46/979, loss: 1.3552, time: 0.0040\n",
            "batch: 47/979, loss: 1.3413, time: 0.0083\n",
            "batch: 48/979, loss: 1.3294, time: 0.0049\n",
            "batch: 49/979, loss: 1.3169, time: 0.0045\n",
            "batch: 50/979, loss: 1.3051, time: 0.0048\n",
            "batch: 51/979, loss: 1.2962, time: 0.0046\n",
            "batch: 52/979, loss: 1.2894, time: 0.0036\n",
            "batch: 53/979, loss: 1.2802, time: 0.0059\n",
            "batch: 54/979, loss: 1.2701, time: 0.0037\n",
            "batch: 55/979, loss: 1.2620, time: 0.0035\n",
            "batch: 56/979, loss: 1.2543, time: 0.0040\n",
            "batch: 57/979, loss: 1.2448, time: 0.0035\n",
            "batch: 58/979, loss: 1.2332, time: 0.0027\n",
            "batch: 59/979, loss: 1.2229, time: 0.0027\n",
            "batch: 60/979, loss: 1.2144, time: 0.0027\n",
            "batch: 61/979, loss: 1.2040, time: 0.0027\n",
            "batch: 62/979, loss: 1.1923, time: 0.0027\n",
            "batch: 63/979, loss: 1.1849, time: 0.0042\n",
            "batch: 64/979, loss: 1.1745, time: 0.0027\n",
            "batch: 65/979, loss: 1.1634, time: 0.0027\n",
            "batch: 66/979, loss: 1.1537, time: 0.0027\n",
            "batch: 67/979, loss: 1.1440, time: 0.0026\n",
            "batch: 68/979, loss: 1.1349, time: 0.0028\n",
            "batch: 69/979, loss: 1.1262, time: 0.0026\n",
            "batch: 70/979, loss: 1.1191, time: 0.0026\n",
            "batch: 71/979, loss: 1.1125, time: 0.0041\n",
            "batch: 72/979, loss: 1.1044, time: 0.0028\n",
            "batch: 73/979, loss: 1.0963, time: 0.0026\n",
            "batch: 74/979, loss: 1.0893, time: 0.0028\n",
            "batch: 75/979, loss: 1.0828, time: 0.0028\n",
            "batch: 76/979, loss: 1.0724, time: 0.0027\n",
            "batch: 77/979, loss: 1.0649, time: 0.0026\n",
            "batch: 78/979, loss: 1.0575, time: 0.0026\n",
            "batch: 79/979, loss: 1.0502, time: 0.0026\n",
            "batch: 80/979, loss: 1.0445, time: 0.0027\n",
            "batch: 81/979, loss: 1.0377, time: 0.0026\n",
            "batch: 82/979, loss: 1.0341, time: 0.0026\n",
            "batch: 83/979, loss: 1.0275, time: 0.0026\n",
            "batch: 84/979, loss: 1.0197, time: 0.0026\n",
            "batch: 85/979, loss: 1.0132, time: 0.0026\n",
            "batch: 86/979, loss: 1.0057, time: 0.0027\n",
            "batch: 87/979, loss: 1.0003, time: 0.0027\n",
            "batch: 88/979, loss: 0.9955, time: 0.0026\n",
            "batch: 89/979, loss: 0.9885, time: 0.0026\n",
            "batch: 90/979, loss: 0.9827, time: 0.0027\n",
            "batch: 91/979, loss: 0.9762, time: 0.0027\n",
            "batch: 92/979, loss: 0.9691, time: 0.0027\n",
            "batch: 93/979, loss: 0.9636, time: 0.0027\n",
            "batch: 94/979, loss: 0.9590, time: 0.0027\n",
            "batch: 95/979, loss: 0.9526, time: 0.0027\n",
            "batch: 96/979, loss: 0.9465, time: 0.0033\n",
            "batch: 97/979, loss: 0.9397, time: 0.0027\n",
            "batch: 98/979, loss: 0.9337, time: 0.0027\n",
            "batch: 99/979, loss: 0.9275, time: 0.0027\n",
            "batch: 100/979, loss: 0.9202, time: 0.0027\n",
            "batch: 101/979, loss: 0.9163, time: 0.0026\n",
            "batch: 102/979, loss: 0.9112, time: 0.0027\n",
            "batch: 103/979, loss: 0.9057, time: 0.0027\n",
            "batch: 104/979, loss: 0.9023, time: 0.0033\n",
            "batch: 105/979, loss: 0.8988, time: 0.0031\n",
            "batch: 106/979, loss: 0.8962, time: 0.0028\n",
            "batch: 107/979, loss: 0.8909, time: 0.0031\n",
            "batch: 108/979, loss: 0.8850, time: 0.0029\n",
            "batch: 109/979, loss: 0.8824, time: 0.0026\n",
            "batch: 110/979, loss: 0.8786, time: 0.0026\n",
            "batch: 111/979, loss: 0.8749, time: 0.0026\n",
            "batch: 112/979, loss: 0.8694, time: 0.0027\n",
            "batch: 113/979, loss: 0.8645, time: 0.0027\n",
            "batch: 114/979, loss: 0.8592, time: 0.0027\n",
            "batch: 115/979, loss: 0.8536, time: 0.0026\n",
            "batch: 116/979, loss: 0.8491, time: 0.0026\n",
            "batch: 117/979, loss: 0.8436, time: 0.0026\n",
            "batch: 118/979, loss: 0.8400, time: 0.0027\n",
            "batch: 119/979, loss: 0.8359, time: 0.0026\n",
            "batch: 120/979, loss: 0.8332, time: 0.0027\n",
            "batch: 121/979, loss: 0.8303, time: 0.0026\n",
            "batch: 122/979, loss: 0.8264, time: 0.0027\n",
            "batch: 123/979, loss: 0.8216, time: 0.0027\n",
            "batch: 124/979, loss: 0.8174, time: 0.0026\n",
            "batch: 125/979, loss: 0.8155, time: 0.0027\n",
            "batch: 126/979, loss: 0.8111, time: 0.0027\n",
            "batch: 127/979, loss: 0.8062, time: 0.0027\n",
            "batch: 128/979, loss: 0.8033, time: 0.0027\n",
            "batch: 129/979, loss: 0.8013, time: 0.0027\n",
            "batch: 130/979, loss: 0.7972, time: 0.0047\n",
            "batch: 131/979, loss: 0.7923, time: 0.0027\n",
            "batch: 132/979, loss: 0.7889, time: 0.0026\n",
            "batch: 133/979, loss: 0.7845, time: 0.0026\n",
            "batch: 134/979, loss: 0.7802, time: 0.0026\n",
            "batch: 135/979, loss: 0.7767, time: 0.0026\n",
            "batch: 136/979, loss: 0.7736, time: 0.0028\n",
            "batch: 137/979, loss: 0.7694, time: 0.0026\n",
            "batch: 138/979, loss: 0.7668, time: 0.0028\n",
            "batch: 139/979, loss: 0.7634, time: 0.0026\n",
            "batch: 140/979, loss: 0.7610, time: 0.0026\n",
            "batch: 141/979, loss: 0.7597, time: 0.0026\n",
            "batch: 142/979, loss: 0.7559, time: 0.0026\n",
            "batch: 143/979, loss: 0.7540, time: 0.0026\n",
            "batch: 144/979, loss: 0.7510, time: 0.0026\n",
            "batch: 145/979, loss: 0.7484, time: 0.0026\n",
            "batch: 146/979, loss: 0.7451, time: 0.0027\n",
            "batch: 147/979, loss: 0.7425, time: 0.0027\n",
            "batch: 148/979, loss: 0.7393, time: 0.0038\n",
            "batch: 149/979, loss: 0.7362, time: 0.0027\n",
            "batch: 150/979, loss: 0.7339, time: 0.0027\n",
            "batch: 151/979, loss: 0.7313, time: 0.0026\n",
            "batch: 152/979, loss: 0.7292, time: 0.0027\n",
            "batch: 153/979, loss: 0.7260, time: 0.0026\n",
            "batch: 154/979, loss: 0.7233, time: 0.0026\n",
            "batch: 155/979, loss: 0.7208, time: 0.0026\n",
            "batch: 156/979, loss: 0.7183, time: 0.0029\n",
            "batch: 157/979, loss: 0.7159, time: 0.0028\n",
            "batch: 158/979, loss: 0.7125, time: 0.0028\n",
            "batch: 159/979, loss: 0.7101, time: 0.0027\n",
            "batch: 160/979, loss: 0.7074, time: 0.0027\n",
            "batch: 161/979, loss: 0.7058, time: 0.0027\n",
            "batch: 162/979, loss: 0.7028, time: 0.0027\n",
            "batch: 163/979, loss: 0.7016, time: 0.0027\n",
            "batch: 164/979, loss: 0.6989, time: 0.0050\n",
            "batch: 165/979, loss: 0.6960, time: 0.0027\n",
            "batch: 166/979, loss: 0.6934, time: 0.0026\n",
            "batch: 167/979, loss: 0.6907, time: 0.0027\n",
            "batch: 168/979, loss: 0.6884, time: 0.0026\n",
            "batch: 169/979, loss: 0.6858, time: 0.0026\n",
            "batch: 170/979, loss: 0.6833, time: 0.0026\n",
            "batch: 171/979, loss: 0.6824, time: 0.0052\n",
            "batch: 172/979, loss: 0.6823, time: 0.0035\n",
            "batch: 173/979, loss: 0.6793, time: 0.0027\n",
            "batch: 174/979, loss: 0.6779, time: 0.0027\n",
            "batch: 175/979, loss: 0.6752, time: 0.0027\n",
            "batch: 176/979, loss: 0.6729, time: 0.0027\n",
            "batch: 177/979, loss: 0.6711, time: 0.0028\n",
            "batch: 178/979, loss: 0.6709, time: 0.0027\n",
            "batch: 179/979, loss: 0.6706, time: 0.0039\n",
            "batch: 180/979, loss: 0.6698, time: 0.0026\n",
            "batch: 181/979, loss: 0.6684, time: 0.0026\n",
            "batch: 182/979, loss: 0.6663, time: 0.0026\n",
            "batch: 183/979, loss: 0.6651, time: 0.0026\n",
            "batch: 184/979, loss: 0.6620, time: 0.0027\n",
            "batch: 185/979, loss: 0.6603, time: 0.0027\n",
            "batch: 186/979, loss: 0.6583, time: 0.0029\n",
            "batch: 187/979, loss: 0.6576, time: 0.0026\n",
            "batch: 188/979, loss: 0.6569, time: 0.0026\n",
            "batch: 189/979, loss: 0.6553, time: 0.0026\n",
            "batch: 190/979, loss: 0.6526, time: 0.0026\n",
            "batch: 191/979, loss: 0.6508, time: 0.0027\n",
            "batch: 192/979, loss: 0.6486, time: 0.0027\n",
            "batch: 193/979, loss: 0.6459, time: 0.0027\n",
            "batch: 194/979, loss: 0.6440, time: 0.0027\n",
            "batch: 195/979, loss: 0.6417, time: 0.0028\n",
            "batch: 196/979, loss: 0.6392, time: 0.0029\n",
            "batch: 197/979, loss: 0.6374, time: 0.0052\n",
            "batch: 198/979, loss: 0.6370, time: 0.0036\n",
            "batch: 199/979, loss: 0.6348, time: 0.0031\n",
            "batch: 200/979, loss: 0.6321, time: 0.0026\n",
            "batch: 201/979, loss: 0.6304, time: 0.0026\n",
            "batch: 202/979, loss: 0.6282, time: 0.0026\n",
            "batch: 203/979, loss: 0.6264, time: 0.0026\n",
            "batch: 204/979, loss: 0.6241, time: 0.0026\n",
            "batch: 205/979, loss: 0.6219, time: 0.0026\n",
            "batch: 206/979, loss: 0.6198, time: 0.0026\n",
            "batch: 207/979, loss: 0.6177, time: 0.0033\n",
            "batch: 208/979, loss: 0.6165, time: 0.0027\n",
            "batch: 209/979, loss: 0.6143, time: 0.0026\n",
            "batch: 210/979, loss: 0.6127, time: 0.0026\n",
            "batch: 211/979, loss: 0.6119, time: 0.0026\n",
            "batch: 212/979, loss: 0.6108, time: 0.0026\n",
            "batch: 213/979, loss: 0.6093, time: 0.0029\n",
            "batch: 214/979, loss: 0.6081, time: 0.0027\n",
            "batch: 215/979, loss: 0.6072, time: 0.0027\n",
            "batch: 216/979, loss: 0.6057, time: 0.0028\n",
            "batch: 217/979, loss: 0.6041, time: 0.0027\n",
            "batch: 218/979, loss: 0.6027, time: 0.0027\n",
            "batch: 219/979, loss: 0.6022, time: 0.0027\n",
            "batch: 220/979, loss: 0.6009, time: 0.0027\n",
            "batch: 221/979, loss: 0.5994, time: 0.0027\n",
            "batch: 222/979, loss: 0.5981, time: 0.0027\n",
            "batch: 223/979, loss: 0.5962, time: 0.0026\n",
            "batch: 224/979, loss: 0.5954, time: 0.0041\n",
            "batch: 225/979, loss: 0.5936, time: 0.0027\n",
            "batch: 226/979, loss: 0.5920, time: 0.0027\n",
            "batch: 227/979, loss: 0.5912, time: 0.0028\n",
            "batch: 228/979, loss: 0.5903, time: 0.0027\n",
            "batch: 229/979, loss: 0.5884, time: 0.0028\n",
            "batch: 230/979, loss: 0.5867, time: 0.0026\n",
            "batch: 231/979, loss: 0.5849, time: 0.0041\n",
            "batch: 232/979, loss: 0.5835, time: 0.0028\n",
            "batch: 233/979, loss: 0.5825, time: 0.0027\n",
            "batch: 234/979, loss: 0.5804, time: 0.0027\n",
            "batch: 235/979, loss: 0.5788, time: 0.0027\n",
            "batch: 236/979, loss: 0.5769, time: 0.0027\n",
            "batch: 237/979, loss: 0.5772, time: 0.0027\n",
            "batch: 238/979, loss: 0.5762, time: 0.0029\n",
            "batch: 239/979, loss: 0.5757, time: 0.0046\n",
            "batch: 240/979, loss: 0.5739, time: 0.0041\n",
            "batch: 241/979, loss: 0.5722, time: 0.0039\n",
            "batch: 242/979, loss: 0.5707, time: 0.0043\n",
            "batch: 243/979, loss: 0.5694, time: 0.0027\n",
            "batch: 244/979, loss: 0.5676, time: 0.0026\n",
            "batch: 245/979, loss: 0.5659, time: 0.0027\n",
            "batch: 246/979, loss: 0.5650, time: 0.0027\n",
            "batch: 247/979, loss: 0.5646, time: 0.0027\n",
            "batch: 248/979, loss: 0.5640, time: 0.0028\n",
            "batch: 249/979, loss: 0.5632, time: 0.0027\n",
            "batch: 250/979, loss: 0.5626, time: 0.0027\n",
            "batch: 251/979, loss: 0.5614, time: 0.0029\n",
            "batch: 252/979, loss: 0.5603, time: 0.0027\n",
            "batch: 253/979, loss: 0.5589, time: 0.0027\n",
            "batch: 254/979, loss: 0.5572, time: 0.0027\n",
            "batch: 255/979, loss: 0.5560, time: 0.0027\n",
            "batch: 256/979, loss: 0.5554, time: 0.0027\n",
            "batch: 257/979, loss: 0.5546, time: 0.0027\n",
            "batch: 258/979, loss: 0.5535, time: 0.0027\n",
            "batch: 259/979, loss: 0.5525, time: 0.0027\n",
            "batch: 260/979, loss: 0.5525, time: 0.0027\n",
            "batch: 261/979, loss: 0.5519, time: 0.0028\n",
            "batch: 262/979, loss: 0.5508, time: 0.0027\n",
            "batch: 263/979, loss: 0.5492, time: 0.0041\n",
            "batch: 264/979, loss: 0.5483, time: 0.0031\n",
            "batch: 265/979, loss: 0.5475, time: 0.0027\n",
            "batch: 266/979, loss: 0.5461, time: 0.0027\n",
            "batch: 267/979, loss: 0.5447, time: 0.0029\n",
            "batch: 268/979, loss: 0.5434, time: 0.0030\n",
            "batch: 269/979, loss: 0.5419, time: 0.0028\n",
            "batch: 270/979, loss: 0.5403, time: 0.0027\n",
            "batch: 271/979, loss: 0.5397, time: 0.0027\n",
            "batch: 272/979, loss: 0.5382, time: 0.0027\n",
            "batch: 273/979, loss: 0.5376, time: 0.0027\n",
            "batch: 274/979, loss: 0.5375, time: 0.0027\n",
            "batch: 275/979, loss: 0.5374, time: 0.0027\n",
            "batch: 276/979, loss: 0.5377, time: 0.0027\n",
            "batch: 277/979, loss: 0.5367, time: 0.0026\n",
            "batch: 278/979, loss: 0.5358, time: 0.0028\n",
            "batch: 279/979, loss: 0.5349, time: 0.0027\n",
            "batch: 280/979, loss: 0.5336, time: 0.0027\n",
            "batch: 281/979, loss: 0.5327, time: 0.0027\n",
            "batch: 282/979, loss: 0.5312, time: 0.0029\n",
            "batch: 283/979, loss: 0.5298, time: 0.0027\n",
            "batch: 284/979, loss: 0.5283, time: 0.0027\n",
            "batch: 285/979, loss: 0.5272, time: 0.0027\n",
            "batch: 286/979, loss: 0.5268, time: 0.0028\n",
            "batch: 287/979, loss: 0.5256, time: 0.0028\n",
            "batch: 288/979, loss: 0.5247, time: 0.0027\n",
            "batch: 289/979, loss: 0.5242, time: 0.0027\n",
            "batch: 290/979, loss: 0.5234, time: 0.0028\n",
            "batch: 291/979, loss: 0.5222, time: 0.0027\n",
            "batch: 292/979, loss: 0.5218, time: 0.0030\n",
            "batch: 293/979, loss: 0.5216, time: 0.0027\n",
            "batch: 294/979, loss: 0.5206, time: 0.0029\n",
            "batch: 295/979, loss: 0.5195, time: 0.0027\n",
            "batch: 296/979, loss: 0.5188, time: 0.0027\n",
            "batch: 297/979, loss: 0.5179, time: 0.0047\n",
            "batch: 298/979, loss: 0.5171, time: 0.0027\n",
            "batch: 299/979, loss: 0.5158, time: 0.0029\n",
            "batch: 300/979, loss: 0.5149, time: 0.0029\n",
            "batch: 301/979, loss: 0.5134, time: 0.0027\n",
            "batch: 302/979, loss: 0.5137, time: 0.0027\n",
            "batch: 303/979, loss: 0.5128, time: 0.0027\n",
            "batch: 304/979, loss: 0.5114, time: 0.0027\n",
            "batch: 305/979, loss: 0.5105, time: 0.0027\n",
            "batch: 306/979, loss: 0.5093, time: 0.0027\n",
            "batch: 307/979, loss: 0.5091, time: 0.0027\n",
            "batch: 308/979, loss: 0.5089, time: 0.0027\n",
            "batch: 309/979, loss: 0.5079, time: 0.0027\n",
            "batch: 310/979, loss: 0.5071, time: 0.0027\n",
            "batch: 311/979, loss: 0.5061, time: 0.0026\n",
            "batch: 312/979, loss: 0.5055, time: 0.0026\n",
            "batch: 313/979, loss: 0.5045, time: 0.0028\n",
            "batch: 314/979, loss: 0.5035, time: 0.0029\n",
            "batch: 315/979, loss: 0.5023, time: 0.0027\n",
            "batch: 316/979, loss: 0.5016, time: 0.0027\n",
            "batch: 317/979, loss: 0.5012, time: 0.0027\n",
            "batch: 318/979, loss: 0.5008, time: 0.0027\n",
            "batch: 319/979, loss: 0.5005, time: 0.0027\n",
            "batch: 320/979, loss: 0.4994, time: 0.0029\n",
            "batch: 321/979, loss: 0.4983, time: 0.0026\n",
            "batch: 322/979, loss: 0.4976, time: 0.0027\n",
            "batch: 323/979, loss: 0.4965, time: 0.0027\n",
            "batch: 324/979, loss: 0.4965, time: 0.0027\n",
            "batch: 325/979, loss: 0.4955, time: 0.0027\n",
            "batch: 326/979, loss: 0.4946, time: 0.0027\n",
            "batch: 327/979, loss: 0.4942, time: 0.0028\n",
            "batch: 328/979, loss: 0.4936, time: 0.0026\n",
            "batch: 329/979, loss: 0.4923, time: 0.0027\n",
            "batch: 330/979, loss: 0.4916, time: 0.0034\n",
            "batch: 331/979, loss: 0.4909, time: 0.0030\n",
            "batch: 332/979, loss: 0.4901, time: 0.0027\n",
            "batch: 333/979, loss: 0.4893, time: 0.0026\n",
            "batch: 334/979, loss: 0.4883, time: 0.0026\n",
            "batch: 335/979, loss: 0.4875, time: 0.0026\n",
            "batch: 336/979, loss: 0.4866, time: 0.0028\n",
            "batch: 337/979, loss: 0.4855, time: 0.0026\n",
            "batch: 338/979, loss: 0.4852, time: 0.0026\n",
            "batch: 339/979, loss: 0.4845, time: 0.0028\n",
            "batch: 340/979, loss: 0.4834, time: 0.0026\n",
            "batch: 341/979, loss: 0.4822, time: 0.0027\n",
            "batch: 342/979, loss: 0.4824, time: 0.0035\n",
            "batch: 343/979, loss: 0.4814, time: 0.0027\n",
            "batch: 344/979, loss: 0.4805, time: 0.0027\n",
            "batch: 345/979, loss: 0.4795, time: 0.0027\n",
            "batch: 346/979, loss: 0.4785, time: 0.0026\n",
            "batch: 347/979, loss: 0.4779, time: 0.0029\n",
            "batch: 348/979, loss: 0.4774, time: 0.0027\n",
            "batch: 349/979, loss: 0.4764, time: 0.0027\n",
            "batch: 350/979, loss: 0.4761, time: 0.0028\n",
            "batch: 351/979, loss: 0.4751, time: 0.0027\n",
            "batch: 352/979, loss: 0.4740, time: 0.0027\n",
            "batch: 353/979, loss: 0.4735, time: 0.0028\n",
            "batch: 354/979, loss: 0.4724, time: 0.0027\n",
            "batch: 355/979, loss: 0.4720, time: 0.0027\n",
            "batch: 356/979, loss: 0.4711, time: 0.0027\n",
            "batch: 357/979, loss: 0.4705, time: 0.0027\n",
            "batch: 358/979, loss: 0.4698, time: 0.0027\n",
            "batch: 359/979, loss: 0.4695, time: 0.0033\n",
            "batch: 360/979, loss: 0.4694, time: 0.0035\n",
            "batch: 361/979, loss: 0.4688, time: 0.0031\n",
            "batch: 362/979, loss: 0.4677, time: 0.0033\n",
            "batch: 363/979, loss: 0.4672, time: 0.0027\n",
            "batch: 364/979, loss: 0.4662, time: 0.0036\n",
            "batch: 365/979, loss: 0.4655, time: 0.0028\n",
            "batch: 366/979, loss: 0.4647, time: 0.0028\n",
            "batch: 367/979, loss: 0.4641, time: 0.0027\n",
            "batch: 368/979, loss: 0.4634, time: 0.0027\n",
            "batch: 369/979, loss: 0.4630, time: 0.0027\n",
            "batch: 370/979, loss: 0.4627, time: 0.0029\n",
            "batch: 371/979, loss: 0.4621, time: 0.0029\n",
            "batch: 372/979, loss: 0.4620, time: 0.0027\n",
            "batch: 373/979, loss: 0.4613, time: 0.0028\n",
            "batch: 374/979, loss: 0.4602, time: 0.0028\n",
            "batch: 375/979, loss: 0.4594, time: 0.0027\n",
            "batch: 376/979, loss: 0.4589, time: 0.0028\n",
            "batch: 377/979, loss: 0.4586, time: 0.0027\n",
            "batch: 378/979, loss: 0.4582, time: 0.0028\n",
            "batch: 379/979, loss: 0.4572, time: 0.0027\n",
            "batch: 380/979, loss: 0.4567, time: 0.0027\n",
            "batch: 381/979, loss: 0.4565, time: 0.0027\n",
            "batch: 382/979, loss: 0.4559, time: 0.0027\n",
            "batch: 383/979, loss: 0.4552, time: 0.0027\n",
            "batch: 384/979, loss: 0.4542, time: 0.0049\n",
            "batch: 385/979, loss: 0.4533, time: 0.0027\n",
            "batch: 386/979, loss: 0.4532, time: 0.0029\n",
            "batch: 387/979, loss: 0.4523, time: 0.0027\n",
            "batch: 388/979, loss: 0.4520, time: 0.0027\n",
            "batch: 389/979, loss: 0.4511, time: 0.0027\n",
            "batch: 390/979, loss: 0.4503, time: 0.0027\n",
            "batch: 391/979, loss: 0.4503, time: 0.0027\n",
            "batch: 392/979, loss: 0.4497, time: 0.0027\n",
            "batch: 393/979, loss: 0.4488, time: 0.0027\n",
            "batch: 394/979, loss: 0.4480, time: 0.0027\n",
            "batch: 395/979, loss: 0.4476, time: 0.0027\n",
            "batch: 396/979, loss: 0.4471, time: 0.0047\n",
            "batch: 397/979, loss: 0.4463, time: 0.0028\n",
            "batch: 398/979, loss: 0.4456, time: 0.0027\n",
            "batch: 399/979, loss: 0.4457, time: 0.0027\n",
            "batch: 400/979, loss: 0.4452, time: 0.0028\n",
            "batch: 401/979, loss: 0.4443, time: 0.0027\n",
            "batch: 402/979, loss: 0.4438, time: 0.0028\n",
            "batch: 403/979, loss: 0.4435, time: 0.0027\n",
            "batch: 404/979, loss: 0.4427, time: 0.0027\n",
            "batch: 405/979, loss: 0.4425, time: 0.0032\n",
            "batch: 406/979, loss: 0.4421, time: 0.0043\n",
            "batch: 407/979, loss: 0.4416, time: 0.0040\n",
            "batch: 408/979, loss: 0.4415, time: 0.0046\n",
            "batch: 409/979, loss: 0.4407, time: 0.0040\n",
            "batch: 410/979, loss: 0.4401, time: 0.0041\n",
            "batch: 411/979, loss: 0.4398, time: 0.0041\n",
            "batch: 412/979, loss: 0.4397, time: 0.0038\n",
            "batch: 413/979, loss: 0.4390, time: 0.0039\n",
            "batch: 414/979, loss: 0.4383, time: 0.0041\n",
            "batch: 415/979, loss: 0.4377, time: 0.0040\n",
            "batch: 416/979, loss: 0.4380, time: 0.0038\n",
            "batch: 417/979, loss: 0.4376, time: 0.0041\n",
            "batch: 418/979, loss: 0.4370, time: 0.0039\n",
            "batch: 419/979, loss: 0.4364, time: 0.0038\n",
            "batch: 420/979, loss: 0.4359, time: 0.0040\n",
            "batch: 421/979, loss: 0.4352, time: 0.0039\n",
            "batch: 422/979, loss: 0.4348, time: 0.0039\n",
            "batch: 423/979, loss: 0.4347, time: 0.0037\n",
            "batch: 424/979, loss: 0.4339, time: 0.0041\n",
            "batch: 425/979, loss: 0.4337, time: 0.0084\n",
            "batch: 426/979, loss: 0.4338, time: 0.0040\n",
            "batch: 427/979, loss: 0.4338, time: 0.0040\n",
            "batch: 428/979, loss: 0.4334, time: 0.0035\n",
            "batch: 429/979, loss: 0.4329, time: 0.0037\n",
            "batch: 430/979, loss: 0.4322, time: 0.0034\n",
            "batch: 431/979, loss: 0.4326, time: 0.0033\n",
            "batch: 432/979, loss: 0.4320, time: 0.0034\n",
            "batch: 433/979, loss: 0.4325, time: 0.0033\n",
            "batch: 434/979, loss: 0.4322, time: 0.0038\n",
            "batch: 435/979, loss: 0.4318, time: 0.0039\n",
            "batch: 436/979, loss: 0.4315, time: 0.0041\n",
            "batch: 437/979, loss: 0.4309, time: 0.0039\n",
            "batch: 438/979, loss: 0.4305, time: 0.0045\n",
            "batch: 439/979, loss: 0.4298, time: 0.0041\n",
            "batch: 440/979, loss: 0.4293, time: 0.0034\n",
            "batch: 441/979, loss: 0.4290, time: 0.0034\n",
            "batch: 442/979, loss: 0.4281, time: 0.0034\n",
            "batch: 443/979, loss: 0.4276, time: 0.0034\n",
            "batch: 444/979, loss: 0.4272, time: 0.0034\n",
            "batch: 445/979, loss: 0.4268, time: 0.0034\n",
            "batch: 446/979, loss: 0.4266, time: 0.0034\n",
            "batch: 447/979, loss: 0.4259, time: 0.0045\n",
            "batch: 448/979, loss: 0.4254, time: 0.0034\n",
            "batch: 449/979, loss: 0.4251, time: 0.0041\n",
            "batch: 450/979, loss: 0.4245, time: 0.0037\n",
            "batch: 451/979, loss: 0.4243, time: 0.0033\n",
            "batch: 452/979, loss: 0.4244, time: 0.0039\n",
            "batch: 453/979, loss: 0.4243, time: 0.0036\n",
            "batch: 454/979, loss: 0.4238, time: 0.0033\n",
            "batch: 455/979, loss: 0.4235, time: 0.0033\n",
            "batch: 456/979, loss: 0.4227, time: 0.0033\n",
            "batch: 457/979, loss: 0.4224, time: 0.0033\n",
            "batch: 458/979, loss: 0.4217, time: 0.0033\n",
            "batch: 459/979, loss: 0.4215, time: 0.0038\n",
            "batch: 460/979, loss: 0.4213, time: 0.0039\n",
            "batch: 461/979, loss: 0.4208, time: 0.0038\n",
            "batch: 462/979, loss: 0.4207, time: 0.0034\n",
            "batch: 463/979, loss: 0.4202, time: 0.0034\n",
            "batch: 464/979, loss: 0.4194, time: 0.0034\n",
            "batch: 465/979, loss: 0.4194, time: 0.0037\n",
            "batch: 466/979, loss: 0.4190, time: 0.0035\n",
            "batch: 467/979, loss: 0.4185, time: 0.0035\n",
            "batch: 468/979, loss: 0.4184, time: 0.0035\n",
            "batch: 469/979, loss: 0.4179, time: 0.0036\n",
            "batch: 470/979, loss: 0.4172, time: 0.0035\n",
            "batch: 471/979, loss: 0.4174, time: 0.0035\n",
            "batch: 472/979, loss: 0.4169, time: 0.0034\n",
            "batch: 473/979, loss: 0.4171, time: 0.0035\n",
            "batch: 474/979, loss: 0.4166, time: 0.0035\n",
            "batch: 475/979, loss: 0.4167, time: 0.0036\n",
            "batch: 476/979, loss: 0.4161, time: 0.0039\n",
            "batch: 477/979, loss: 0.4161, time: 0.0034\n",
            "batch: 478/979, loss: 0.4156, time: 0.0034\n",
            "batch: 479/979, loss: 0.4152, time: 0.0034\n",
            "batch: 480/979, loss: 0.4148, time: 0.0034\n",
            "batch: 481/979, loss: 0.4144, time: 0.0035\n",
            "batch: 482/979, loss: 0.4142, time: 0.0035\n",
            "batch: 483/979, loss: 0.4139, time: 0.0043\n",
            "batch: 484/979, loss: 0.4139, time: 0.0034\n",
            "batch: 485/979, loss: 0.4133, time: 0.0034\n",
            "batch: 486/979, loss: 0.4130, time: 0.0035\n",
            "batch: 487/979, loss: 0.4126, time: 0.0036\n",
            "batch: 488/979, loss: 0.4121, time: 0.0034\n",
            "batch: 489/979, loss: 0.4119, time: 0.0046\n",
            "batch: 490/979, loss: 0.4123, time: 0.0034\n",
            "batch: 491/979, loss: 0.4124, time: 0.0034\n",
            "batch: 492/979, loss: 0.4120, time: 0.0034\n",
            "batch: 493/979, loss: 0.4121, time: 0.0034\n",
            "batch: 494/979, loss: 0.4120, time: 0.0036\n",
            "batch: 495/979, loss: 0.4114, time: 0.0035\n",
            "batch: 496/979, loss: 0.4110, time: 0.0035\n",
            "batch: 497/979, loss: 0.4104, time: 0.0034\n",
            "batch: 498/979, loss: 0.4107, time: 0.0041\n",
            "batch: 499/979, loss: 0.4101, time: 0.0034\n",
            "batch: 500/979, loss: 0.4095, time: 0.0034\n",
            "batch: 501/979, loss: 0.4088, time: 0.0035\n",
            "batch: 502/979, loss: 0.4083, time: 0.0034\n",
            "batch: 503/979, loss: 0.4083, time: 0.0039\n",
            "batch: 504/979, loss: 0.4079, time: 0.0049\n",
            "batch: 505/979, loss: 0.4075, time: 0.0058\n",
            "batch: 506/979, loss: 0.4069, time: 0.0045\n",
            "batch: 507/979, loss: 0.4064, time: 0.0034\n",
            "batch: 508/979, loss: 0.4060, time: 0.0034\n",
            "batch: 509/979, loss: 0.4059, time: 0.0034\n",
            "batch: 510/979, loss: 0.4053, time: 0.0083\n",
            "batch: 511/979, loss: 0.4050, time: 0.0035\n",
            "batch: 512/979, loss: 0.4049, time: 0.0037\n",
            "batch: 513/979, loss: 0.4046, time: 0.0037\n",
            "batch: 514/979, loss: 0.4045, time: 0.0035\n",
            "batch: 515/979, loss: 0.4047, time: 0.0034\n",
            "batch: 516/979, loss: 0.4044, time: 0.0039\n",
            "batch: 517/979, loss: 0.4040, time: 0.0034\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-d4e9dde2bbab>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcl_test_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcl_train_accuracy_arr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     cl_test_accuracy_arr = train(classical_model, criterion=criterion,\n\u001b[0m\u001b[1;32m      5\u001b[0m                               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcl_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-eb7c6ba335b4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_dataloader, test_dataloader, num_epochs)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# t.grad = torch.tensor([0., 0., 0.])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# t = t - lr * t.grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cl_test_accuracy_arr"
      ],
      "metadata": {
        "id": "1SQ4xsOVd0bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hq_train_losses, \\\n",
        "    hq_test_losses, \\\n",
        "    hq_train_accuracy_arr, \\\n",
        "    hq_test_accuracy_arr = train_for_hqnn(hybrid_quantum_model, criterion=criterion,\n",
        "                              optimizer=hq_optimizer,\n",
        "                              train_dataloader=train_loader,\n",
        "                              test_dataloader=test_loader,\n",
        "                              num_epochs=1)"
      ],
      "metadata": {
        "id": "2CqcSaKTTMhJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "7f2f4512c03d4d6d86d51f2f8a3a5fed",
            "22607ed241a74d4f9dc9d471f18e1690",
            "d5590ae5cbe246c8a3b97a1794582dec",
            "889ece199b2a469388992df645c9977e",
            "97def7d09b1a4359bda9237e1a46d28c",
            "b9b9d71402eb46b595cfc84dd522acfb",
            "8f43314093db461f8f90e91e48dbd0da",
            "d623bf979daa40e8af2598e247099b4e",
            "c6fd02082a4342fbb9b9da6449325cfb",
            "d788e171ee934b0d9275fcb6c88d69c8",
            "8ee7f59198f44ac6af6a747b4d7c505a"
          ]
        },
        "outputId": "30bdea22-b24c-40d6-f4e4-f220e5e04264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f2f4512c03d4d6d86d51f2f8a3a5fed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it: 1/979, loss: 1.6147, time: 18.4406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7edf9c10bd90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 96, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it: 2/979, loss: 1.6102, time: 17.3446\n",
            "it: 3/979, loss: 1.6104, time: 17.1891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hq_test_accuracy_arr"
      ],
      "metadata": {
        "id": "Jgjxi_GhTVZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hq_train_accuracy_arr"
      ],
      "metadata": {
        "id": "Tsr4BWl-PGF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "in_channels = 1\n",
        "out_channels = 3\n",
        "length = 31\n",
        "num_classes = 5\n",
        "kernel_size = 2\n",
        "embedding_dim = 200\n",
        "hidden_dim = 100\n",
        "padding = 1\n",
        "stride = 1\n",
        "num_qubits = 4\n",
        "\n",
        "# Create dummy data & labels\n",
        "train_dummy_data = torch.randint(0, 1000, (batch_size, length)).to(device)\n",
        "train_dummy_labels = torch.randint(0, num_classes, (batch_size,)).to(device)\n",
        "\n",
        "test_dummy_data = torch.randn(batch_size, length)\n",
        "test_dummy_labels = torch.randint(0, num_classes, (batch_size,))\n",
        "\n",
        "# Create a simple Dataset and DataLoader\n",
        "train_dummy_dataset = TensorDataset(train_dummy_data, train_dummy_labels)\n",
        "train_dummy_loader = DataLoader(train_dummy_dataset, batch_size)\n",
        "\n",
        "test_dummy_dataset = TensorDataset(test_dummy_data, test_dummy_labels)\n",
        "test_dummy_loader = DataLoader(test_dummy_dataset, batch_size)\n"
      ],
      "metadata": {
        "id": "pF1KSYMGTdHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 8e-4 #Learning rate\n",
        "\n",
        "toy_hq_model = ToyHQModel(VOCAB_SIZE, embedding_dim, in_channels, out_channels, kernel_size, stride, padding, hidden_dim, num_qubits, num_classes, lstm_layers = 1)\n",
        "\n",
        "toy_hq_model = toy_hq_model.to(device)\n",
        "# Set up the criterion (loss function)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.AdamW(toy_hq_model.parameters(), lr=LR, weight_decay = 5e-6)\n",
        "\n",
        "print(toy_hq_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZjYDvFJLG0z",
        "outputId": "108bfc04-5bdf-43dc-8322-3659a2112648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ToyHQModel(\n",
            "  (embedding): Embedding(37569, 200)\n",
            "  (attention): Attention(\n",
            "    (attn): Linear(in_features=200, out_features=100, bias=True)\n",
            "    (v): Linear(in_features=100, out_features=1, bias=False)\n",
            "  )\n",
            "  (lstm): HQLSTM(\n",
            "    (lstm_cells): ModuleList(\n",
            "      (0): HQLSTMCell()\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toy_hq_model(train_dummy_data)"
      ],
      "metadata": {
        "id": "AH2z4g_A5FjA",
        "outputId": "ca9d8fa0-d80c-4a16-b9b9-f4bb0df18bb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n",
            "torch.Size([2, 16])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.6381, -1.6118, -1.5608, -1.6813, -1.5606],\n",
              "        [-1.6472, -1.6141, -1.5558, -1.6795, -1.5565]], device='cuda:0',\n",
              "       grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "metadata": {
        "id": "rActVEdigY8M",
        "outputId": "05ad61af-0c0d-4c9a-aeb7-d989abf48ac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28985, 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dummy_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "# test_dummy_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))"
      ],
      "metadata": {
        "id": "Cps3yt0-eIKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BATCH_SIZE = 2"
      ],
      "metadata": {
        "id": "18tjNlfVeIKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dummy_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
        "test_dummy_loader = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE, drop_last=True)"
      ],
      "metadata": {
        "id": "qQRprRrveIKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, \\\n",
        "    test_losses, \\\n",
        "    train_accuracy_arr, \\\n",
        "    test_accuracy_arr = train_for_hqnn(toy_hq_model, criterion=criterion,\n",
        "                              optimizer=optimizer,\n",
        "                              train_dataloader=train_dummy_loader,\n",
        "                              test_dataloader=test_dummy_loader,\n",
        "                              num_epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388,
          "referenced_widgets": [
            "06a8e085c5684549b8564f24bd762e4f",
            "3a33592a8c0f4c3e9e42f2d092dd0889",
            "885eeace639140e2a01b16692b64accc",
            "ca36aa40d1e64ad496b3b838462acaa0",
            "62374ed5a97a431c942ba275585d7d57",
            "6281ff12628a44da968a820165064dd1",
            "a32f46d1b39247d69617fd8d08255dde",
            "e437002cee7c48468d608ac3b6419490",
            "d4d7dc520db647d9bd626ee52f8a35bd",
            "27d5e2469ff444539de5d7d4b4ab6278",
            "875eff2116cf45b9b386071a7d8cc1c7"
          ]
        },
        "id": "RBB6oiTGG02t",
        "outputId": "48e1fb56-cbc4-4c18-9836-1a3a5342eb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06a8e085c5684549b8564f24bd762e4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-fd0fa7cb832d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_accuracy_arr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     test_accuracy_arr = train_for_hqnn(toy_hq_model, criterion=criterion,\n\u001b[0m\u001b[1;32m      5\u001b[0m                               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dummy_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-0036f823edc8>\u001b[0m in \u001b[0;36mtrain_for_hqnn\u001b[0;34m(model, criterion, optimizer, train_dataloader, test_dataloader, num_epochs)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# t.grad = torch.tensor([0., 0., 0.])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# t = t - lr * t.grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses"
      ],
      "metadata": {
        "id": "lPCx3xe9zXNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FysnlhgaW4TF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06a8e085c5684549b8564f24bd762e4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a33592a8c0f4c3e9e42f2d092dd0889",
              "IPY_MODEL_885eeace639140e2a01b16692b64accc",
              "IPY_MODEL_ca36aa40d1e64ad496b3b838462acaa0"
            ],
            "layout": "IPY_MODEL_62374ed5a97a431c942ba275585d7d57"
          }
        },
        "3a33592a8c0f4c3e9e42f2d092dd0889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6281ff12628a44da968a820165064dd1",
            "placeholder": "​",
            "style": "IPY_MODEL_a32f46d1b39247d69617fd8d08255dde",
            "value": "  0%"
          }
        },
        "885eeace639140e2a01b16692b64accc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e437002cee7c48468d608ac3b6419490",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4d7dc520db647d9bd626ee52f8a35bd",
            "value": 0
          }
        },
        "ca36aa40d1e64ad496b3b838462acaa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27d5e2469ff444539de5d7d4b4ab6278",
            "placeholder": "​",
            "style": "IPY_MODEL_875eff2116cf45b9b386071a7d8cc1c7",
            "value": " 0/2 [30:03&lt;?, ?it/s]"
          }
        },
        "62374ed5a97a431c942ba275585d7d57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6281ff12628a44da968a820165064dd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a32f46d1b39247d69617fd8d08255dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e437002cee7c48468d608ac3b6419490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d7dc520db647d9bd626ee52f8a35bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27d5e2469ff444539de5d7d4b4ab6278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "875eff2116cf45b9b386071a7d8cc1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "661cd90b76c9451f98e0ca29c4b22d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d702bf265eca4bbbbcb7a358df381c65",
              "IPY_MODEL_fc30a6a4b6064be0b3c4a786a4b64952",
              "IPY_MODEL_df78c6ab42474534a547a0a7ba44b754"
            ],
            "layout": "IPY_MODEL_d49849d9283546c9b34517f327232757"
          }
        },
        "d702bf265eca4bbbbcb7a358df381c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8562c9e4bc8443db82350ff5f496958b",
            "placeholder": "​",
            "style": "IPY_MODEL_e17bf6667ccd4167af9110a09ba012ac",
            "value": "  0%"
          }
        },
        "fc30a6a4b6064be0b3c4a786a4b64952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60ed458c82de4401a7eb400c23f1338d",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_673f3f8df9244b538ad88f1fc82442b6",
            "value": 0
          }
        },
        "df78c6ab42474534a547a0a7ba44b754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_029421ef2fec489b8b379351e00e188a",
            "placeholder": "​",
            "style": "IPY_MODEL_98cad26d7f274b71a04d37fca89196bf",
            "value": " 0/10 [00:03&lt;?, ?it/s]"
          }
        },
        "d49849d9283546c9b34517f327232757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8562c9e4bc8443db82350ff5f496958b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e17bf6667ccd4167af9110a09ba012ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60ed458c82de4401a7eb400c23f1338d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "673f3f8df9244b538ad88f1fc82442b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "029421ef2fec489b8b379351e00e188a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98cad26d7f274b71a04d37fca89196bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f2f4512c03d4d6d86d51f2f8a3a5fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22607ed241a74d4f9dc9d471f18e1690",
              "IPY_MODEL_d5590ae5cbe246c8a3b97a1794582dec",
              "IPY_MODEL_889ece199b2a469388992df645c9977e"
            ],
            "layout": "IPY_MODEL_97def7d09b1a4359bda9237e1a46d28c"
          }
        },
        "22607ed241a74d4f9dc9d471f18e1690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9b9d71402eb46b595cfc84dd522acfb",
            "placeholder": "​",
            "style": "IPY_MODEL_8f43314093db461f8f90e91e48dbd0da",
            "value": "  0%"
          }
        },
        "d5590ae5cbe246c8a3b97a1794582dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d623bf979daa40e8af2598e247099b4e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6fd02082a4342fbb9b9da6449325cfb",
            "value": 0
          }
        },
        "889ece199b2a469388992df645c9977e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d788e171ee934b0d9275fcb6c88d69c8",
            "placeholder": "​",
            "style": "IPY_MODEL_8ee7f59198f44ac6af6a747b4d7c505a",
            "value": " 0/1 [00:00&lt;?, ?it/s]"
          }
        },
        "97def7d09b1a4359bda9237e1a46d28c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9b9d71402eb46b595cfc84dd522acfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f43314093db461f8f90e91e48dbd0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d623bf979daa40e8af2598e247099b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6fd02082a4342fbb9b9da6449325cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d788e171ee934b0d9275fcb6c88d69c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee7f59198f44ac6af6a747b4d7c505a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
