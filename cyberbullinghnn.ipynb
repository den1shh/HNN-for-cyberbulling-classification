{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOw7Xm_A-Msu"
   },
   "source": [
    "# Text classification with Quanvolutional layer + Attention + HQLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXYmXj3x_Z3k"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fklFBxOt_n0r"
   },
   "source": [
    "Imports for computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9KMjztfO_iLH",
    "outputId": "20143246-0e7b-4af0-d715-17167e02c356"
   },
   "outputs": [],
   "source": [
    "# !pip install custatevec_cu12\n",
    "# !pip install pennylane pennylane-lightning\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNda1wZNADCt"
   },
   "source": [
    "For plotting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "0HzKYqfvkO5s",
    "outputId": "31d2ebeb-b99e-4e46-a490-a4a8aa952bf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.despine()\n",
    "# plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\"axes\", labelweight=\"bold\", labelsize=\"large\", titleweight=\"bold\", titlepad=10)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEByIz_FAyoB"
   },
   "source": [
    "For data preprocessing and text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5pFgXpHkJ1fd",
    "outputId": "fc0be830-fe62-411f-c97b-12d3933962fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\den1s\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\den1s\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\den1s\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\den1s\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# !pip install langdetect\n",
    "# !pip install contractions\n",
    "# !pip install emoji==1.4.1\n",
    "# !pip install nltk\n",
    "\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from langdetect import detect, LangDetectException\n",
    "import contractions\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-O5RGApBB0S"
   },
   "source": [
    "Set seed for reproductivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "id": "0Ud4hzR0kO5v"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pmjJoJyZkO5v",
    "outputId": "f1c8b41c-e728-4c51-9d12-3fbe200d9c2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightning.qubit device (wires=4) at 0x26838348950>"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_qubits = 4\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "# dev = qml.device('qulacs.simulator', wires = range(num_qubits))\n",
    "device = \"cpu\"\n",
    "dev = qml.device(\"lightning.qubit\", wires=range(num_qubits))\n",
    "# dev = qml.device(\"default.tensor\", method=\"tn\", wires = range(num_qubits), **kwargs_tn)\n",
    "dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wh5ts37oBzek"
   },
   "source": [
    "# Import data, data preprocessing and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZHah9RUDkV1"
   },
   "source": [
    "We use \"Cyberbullying Classification\" dataset from Kaggle. You can acquire more information about the data by the following link: https://www.kaggle.com/datasets/andrewmvd/cyberbullying-classification/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "id": "PN22QbhmkO5v"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('cyberbullying_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "rCNEZ-XakO5v",
    "outputId": "f60da740-fc14-4217-ba61-407d1de67a15"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>Black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>Turner did not withhold his disappointment. Tu...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>I swear to God. This dumb nigger bitch. I have...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>Yea fuck you RT @therealexel: IF YOURE A NIGGE...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47692 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text cyberbullying_type\n",
       "0      In other words #katandandre, your food was cra...  not_cyberbullying\n",
       "1      Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
       "2      @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
       "3      @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
       "4      @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying\n",
       "...                                                  ...                ...\n",
       "47687  Black ppl aren't expected to do anything, depe...          ethnicity\n",
       "47688  Turner did not withhold his disappointment. Tu...          ethnicity\n",
       "47689  I swear to God. This dumb nigger bitch. I have...          ethnicity\n",
       "47690  Yea fuck you RT @therealexel: IF YOURE A NIGGE...          ethnicity\n",
       "47691  Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...          ethnicity\n",
       "\n",
       "[47692 rows x 2 columns]"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "id": "92KibKseK0C7"
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'tweet_text': 'text', 'cyberbullying_type': 'sentiment'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NoSlde7eLDdp",
    "outputId": "cd8c0c41-c9d6-4215-c320-90bc4c1906a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          sentiment\n",
       "0  In other words #katandandre, your food was cra...  not_cyberbullying\n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
       "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsXc6JwwCTMQ"
   },
   "source": [
    "Define cleaning functions. Source: https://www.kaggle.com/code/ludovicocuoghi/detecting-bullying-tweets-pytorch-lstm-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "id": "8RjOd2SaI8R_"
   },
   "outputs": [],
   "source": [
    "# Clean emojis from text\n",
    "def strip_emoji(text):\n",
    "    return emoji.get_emoji_regexp().sub(\"\", text)\n",
    "\n",
    "# Remove punctuations, stopwords, links, mentions and new line characters\n",
    "def strip_all_entities(text):\n",
    "    text = re.sub(r'\\r|\\n', ' ', text.lower())  # Replace newline and carriage return with space, and convert to lowercase\n",
    "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text)  # Remove links and mentions\n",
    "    text = re.sub(r'[^\\x00-\\x7f]', '', text)  # Remove non-ASCII characters\n",
    "    banned_list = string.punctuation\n",
    "    table = str.maketrans('', '', banned_list)\n",
    "    text = text.translate(table)\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "# Clean hashtags at the end of the sentence, and keep those in the middle of the sentence by removing just the # symbol\n",
    "def clean_hashtags(tweet):\n",
    "    # Remove hashtags at the end of the sentence\n",
    "    new_tweet = re.sub(r'(\\s+#[\\w-]+)+\\s*$', '', tweet).strip()\n",
    "\n",
    "    # Remove the # symbol from hashtags in the middle of the sentence\n",
    "    new_tweet = re.sub(r'#([\\w-]+)', r'\\1', new_tweet).strip()\n",
    "\n",
    "    return new_tweet\n",
    "\n",
    "# Filter special characters such as & and $ present in some words\n",
    "def filter_chars(text):\n",
    "    return ' '.join('' if ('$' in word) or ('&' in word) else word for word in text.split())\n",
    "\n",
    "# Remove multiple spaces\n",
    "def remove_mult_spaces(text):\n",
    "    return re.sub(r\"\\s\\s+\", \" \", text)\n",
    "\n",
    "# Function to check if the text is in English, and return an empty string if it's not\n",
    "def filter_non_english(text):\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "    except LangDetectException:\n",
    "        lang = \"unknown\"\n",
    "    return text if lang == \"en\" else \"\"\n",
    "\n",
    "# Expand contractions\n",
    "def expand_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "# Remove numbers\n",
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "# Lemmatize words\n",
    "def lemmatize(text):\n",
    "    words = word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Remove short words\n",
    "def remove_short_words(text, min_len=2):\n",
    "    words = text.split()\n",
    "    long_words = [word for word in words if len(word) >= min_len]\n",
    "    return ' '.join(long_words)\n",
    "\n",
    "# Replace elongated words with their base form\n",
    "def replace_elongated_words(text):\n",
    "    regex_pattern = r'\\b(\\w+)((\\w)\\3{2,})(\\w*)\\b'\n",
    "    return re.sub(regex_pattern, r'\\1\\3\\4', text)\n",
    "\n",
    "# Remove repeated punctuation\n",
    "def remove_repeated_punctuation(text):\n",
    "    return re.sub(r'[\\?\\.\\!]+(?=[\\?\\.\\!])', '', text)\n",
    "\n",
    "# Remove extra whitespace\n",
    "def remove_extra_whitespace(text):\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def remove_url_shorteners(text):\n",
    "    return re.sub(r'(?:http[s]?://)?(?:www\\.)?(?:bit\\.ly|goo\\.gl|t\\.co|tinyurl\\.com|tr\\.im|is\\.gd|cli\\.gs|u\\.nu|url\\.ie|tiny\\.cc|alturl\\.com|ow\\.ly|bit\\.do|adoro\\.to)\\S+', '', text)\n",
    "\n",
    "# Remove spaces at the beginning and end of the tweet\n",
    "def remove_spaces_tweets(tweet):\n",
    "    return tweet.strip()\n",
    "\n",
    "# Remove short tweets\n",
    "def remove_short_tweets(tweet, min_words=3):\n",
    "    words = tweet.split()\n",
    "    return tweet if len(words) >= min_words else \"\"\n",
    "\n",
    "# Function to call all the cleaning functions in the correct order\n",
    "def clean_tweet(tweet):\n",
    "    tweet = strip_emoji(tweet)\n",
    "    tweet = expand_contractions(tweet)\n",
    "    tweet = filter_non_english(tweet)\n",
    "    tweet = strip_all_entities(tweet)\n",
    "    tweet = clean_hashtags(tweet)\n",
    "    tweet = filter_chars(tweet)\n",
    "    tweet = remove_mult_spaces(tweet)\n",
    "    tweet = remove_numbers(tweet)\n",
    "    tweet = lemmatize(tweet)\n",
    "    tweet = remove_short_words(tweet)\n",
    "    tweet = replace_elongated_words(tweet)\n",
    "    tweet = remove_repeated_punctuation(tweet)\n",
    "    tweet = remove_extra_whitespace(tweet)\n",
    "    tweet = remove_url_shorteners(tweet)\n",
    "    tweet = remove_spaces_tweets(tweet)\n",
    "    tweet = remove_short_tweets(tweet)\n",
    "    tweet = ' '.join(tweet.split())  # Remove multiple spaces between words\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "id": "ECncuUbvLAHI"
   },
   "outputs": [],
   "source": [
    "df['text_clean'] = [clean_tweet(tweet) for tweet in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "RYNGL2_Uc4vP",
    "outputId": "9b8507c9-cac5-43b8-8b90-e762b4efc881"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>word katandandre food crapilicious mkr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>aussietv white mkr theblock imacelebrityau tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>classy whore red velvet cupcake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>meh thanks head concerned another angry dude t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>isi account pretending kurdish account like is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          sentiment  \\\n",
       "0  In other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying   \n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying   \n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying   \n",
       "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying   \n",
       "\n",
       "                                          text_clean  \n",
       "0             word katandandre food crapilicious mkr  \n",
       "1  aussietv white mkr theblock imacelebrityau tod...  \n",
       "2                    classy whore red velvet cupcake  \n",
       "3  meh thanks head concerned another angry dude t...  \n",
       "4  isi account pretending kurdish account like is...  "
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eh56r73aewhE",
    "outputId": "e0bcd169-4a09-4934-f874-4f8b66f10651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are around 6290 duplicated tweets, we will remove them.\n"
     ]
    }
   ],
   "source": [
    "print(f'There are around {int(df[\"text_clean\"].duplicated().sum())} duplicated tweets, we will remove them.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "id": "LNlO3hdhez4-"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(\"text_clean\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "LGEU8XC9e3Ue",
    "outputId": "30a08ebb-5b77-40c0-b84e-796ce19fdbcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "religion               7917\n",
       "age                    7819\n",
       "ethnicity              7414\n",
       "gender                 7278\n",
       "not_cyberbullying      6063\n",
       "other_cyberbullying    4911\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qZ7PoaKC808"
   },
   "source": [
    "As we can see, after cleaning classes are unbalanced so we will drop \"other_cyberbullying\" class as there is not enough data. Later we will oversample \"not_cyberbullying\" class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "id": "i-4tp2O8e-zw"
   },
   "outputs": [],
   "source": [
    "df = df[df[\"sentiment\"]!=\"other_cyberbullying\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q712dE4kftOe",
    "outputId": "e653bc8f-996d-4c87-a15e-e5265df95cd1"
   },
   "outputs": [],
   "source": [
    "df['text_len'] = [len(text.split()) for text in df.text_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set target count\n",
    "# target_count = 4901\n",
    "\n",
    "# # Dropping random items to equalize the counts\n",
    "# for column in df.columns:\n",
    "#     current_count = df[column].value_counts().iloc[0]  # Get current count of the first category\n",
    "#     if current_count > target_count:\n",
    "#         # Calculate the number of items to drop\n",
    "#         n_to_drop = current_count - target_count\n",
    "        \n",
    "#         # Select random indices to drop\n",
    "#         indices_to_drop = df[df[column] == df[column].value_counts().index[0]].sample(n=n_to_drop, random_state=1).index\n",
    "\n",
    "#         # Drop the selected rows\n",
    "#         df = df.drop(indices_to_drop)\n",
    "\n",
    "# # Resulting DataFrame value counts\n",
    "# print(\"Value Counts after Dropping Random Items:\")\n",
    "# print(df.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "religion             7917\n",
       "age                  7819\n",
       "ethnicity            7414\n",
       "gender               7278\n",
       "not_cyberbullying    6063\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract a middle portion of sorted DataFrame\n",
    "def select_middle_texts(df, label, n):\n",
    "    # Filter the DataFrame for a specific label\n",
    "    df_filtered = df[df['sentiment'] == label]\n",
    "    \n",
    "    # Add a column for text length\n",
    "    \n",
    "    # Sort by text length\n",
    "    df_sorted = df_filtered.sort_values(by='text_len')\n",
    "    \n",
    "    # Calculate middle index\n",
    "    mid_index = len(df_sorted) // 2\n",
    "    \n",
    "    # Calculate start and end indices\n",
    "    start_index = max(0, mid_index - n // 2)\n",
    "    end_index = start_index + n\n",
    "    \n",
    "    # Select the middle 'n' rows\n",
    "    middle_subset = df_sorted.iloc[start_index:end_index].drop(columns=['text_len'])\n",
    "    \n",
    "    return middle_subset\n",
    "\n",
    "# Selection criteria\n",
    "value_counts = {\n",
    "    'sentiment': 750,\n",
    "    'religion': 750,\n",
    "    'age': 750,\n",
    "    'gender': 750,\n",
    "    'not_cyberbullying': 3000\n",
    "}\n",
    "\n",
    "# Collect results for each label\n",
    "results = []\n",
    "\n",
    "for label, n in value_counts.items():\n",
    "    subset = select_middle_texts(df, label, n)\n",
    "    results.append(subset)\n",
    "\n",
    "# Concatenate results into a final DataFrame\n",
    "df_result = pd.concat(results).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "not_cyberbullying    3000\n",
       "religion              750\n",
       "age                   750\n",
       "gender                750\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSjqH8-0gs9X",
    "outputId": "7ef2ad60-a121-497d-cb14-a4d739109ed8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\den1s\\AppData\\Local\\Temp\\ipykernel_12612\\1991023214.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_result['sentiment'] = df_result['sentiment'].replace({'religion':1,'age':1,'ethnicity':1,'gender':1,'not_cyberbullying':0})\n"
     ]
    }
   ],
   "source": [
    "df_result['sentiment'] = df_result['sentiment'].replace({'religion':1,'age':1,'ethnicity':1,'gender':1,'not_cyberbullying':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['text_len'] = [len(text.split()) for text in df_result.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.270806500232935"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_len = np.mean(df['text_len'])\n",
    "mean_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not even sure he understands what he just ramb...</td>\n",
       "      <td>1</td>\n",
       "      <td>even sure understands ramble everyone right op...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIS and all those other Terrorist organisatio...</td>\n",
       "      <td>1</td>\n",
       "      <td>isi terrorist organisation muslim follow basic...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That's what these idiots have been programmed ...</td>\n",
       "      <td>1</td>\n",
       "      <td>idiot programmed believe look actual number mu...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sorry but don't say that you are also a part o...</td>\n",
       "      <td>1</td>\n",
       "      <td>sorry say also part bjp grand plan polarise hi...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wow what a family person u r! sponsering terro...</td>\n",
       "      <td>1</td>\n",
       "      <td>wow family person sponsering terrorism kashmir...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>@GerardGeorges4 @AlsisiOfficial Word is that t...</td>\n",
       "      <td>0</td>\n",
       "      <td>word ypgypj first time encroached raqqa provin...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5246</th>\n",
       "      <td>@GetEmEasy that don't make u a hater..if u sai...</td>\n",
       "      <td>0</td>\n",
       "      <td>make haterif said think good would hateri thin...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5247</th>\n",
       "      <td>@ottomanland @loveconcursall Brilliant how the...</td>\n",
       "      <td>0</td>\n",
       "      <td>brilliant english spy israeli got erdogan let ...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5248</th>\n",
       "      <td>RT @Yonadav7: Elder Of Ziyon - Israel News: Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>rt elder ziyon israel news collection charlie ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>To be fair opening a packet of chips confuses ...</td>\n",
       "      <td>0</td>\n",
       "      <td>fair opening packet chip confuses colin much a...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sentiment  \\\n",
       "0     not even sure he understands what he just ramb...          1   \n",
       "1     ISIS and all those other Terrorist organisatio...          1   \n",
       "2     That's what these idiots have been programmed ...          1   \n",
       "3     Sorry but don't say that you are also a part o...          1   \n",
       "4     wow what a family person u r! sponsering terro...          1   \n",
       "...                                                 ...        ...   \n",
       "5245  @GerardGeorges4 @AlsisiOfficial Word is that t...          0   \n",
       "5246  @GetEmEasy that don't make u a hater..if u sai...          0   \n",
       "5247  @ottomanland @loveconcursall Brilliant how the...          0   \n",
       "5248  RT @Yonadav7: Elder Of Ziyon - Israel News: Th...          0   \n",
       "5249  To be fair opening a packet of chips confuses ...          0   \n",
       "\n",
       "                                             text_clean  text_len  \n",
       "0     even sure understands ramble everyone right op...        39  \n",
       "1     isi terrorist organisation muslim follow basic...        42  \n",
       "2     idiot programmed believe look actual number mu...        40  \n",
       "3     sorry say also part bjp grand plan polarise hi...        30  \n",
       "4     wow family person sponsering terrorism kashmir...        29  \n",
       "...                                                 ...       ...  \n",
       "5245  word ypgypj first time encroached raqqa provin...        22  \n",
       "5246  make haterif said think good would hateri thin...        27  \n",
       "5247  brilliant english spy israeli got erdogan let ...        21  \n",
       "5248  rt elder ziyon israel news collection charlie ...        16  \n",
       "5249  fair opening packet chip confuses colin much a...        19  \n",
       "\n",
       "[5250 rows x 4 columns]"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "id": "WQjmvAMHfyG6",
    "outputId": "2a4d2a28-3e89-4178-e9c5-217e036ea37c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\den1s\\AppData\\Local\\Temp\\ipykernel_12612\\631618343.py:2: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.countplot(x='text_len', data=df[df['text_len']<10], palette='mako')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "ax = sns.countplot(x='text_len', data=df[df['text_len']<10], palette='mako')\n",
    "plt.title('Count of tweets with less than 10 words', fontsize=20)\n",
    "plt.yticks([])\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "Ir99Mjatf7Sz",
    "outputId": "a2fa6798-54ff-419e-8fcf-1fb2b40c8614"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\den1s\\AppData\\Local\\Temp\\ipykernel_12612\\2060477503.py:2: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.countplot(x='text_len', data=df[(df['text_len']<=1000) & (df['text_len']>10)], palette='Blues_r')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "ax = sns.countplot(x='text_len', data=df[(df['text_len']<=1000) & (df['text_len']>10)], palette='Blues_r')\n",
    "plt.title('Count of tweets with high number of words', fontsize=25)\n",
    "plt.yticks([])\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sv5RTF8ggS7a",
    "outputId": "58a4dd8d-c18e-4023-9134-b49ddfe2549d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = np.max(df['text_len'])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.860380952380954"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_len = np.mean(df['text_len'])\n",
    "mean_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSjlhVvdEqEQ"
   },
   "source": [
    "Text tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "id": "nPIz-dF6kFEH"
   },
   "outputs": [],
   "source": [
    "def Tokenize(column, seq_len):\n",
    "    ##Create vocabulary of words from column\n",
    "    corpus = [word for text in column for word in text.split()]\n",
    "    count_words = Counter(corpus)\n",
    "    sorted_words = count_words.most_common()\n",
    "    vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n",
    "\n",
    "    ##Tokenize the columns text using the vocabulary\n",
    "    text_int = []\n",
    "    for text in column:\n",
    "        r = [vocab_to_int[word] for word in text.split()]\n",
    "        text_int.append(r)\n",
    "    ##Add padding to tokens\n",
    "    features = np.zeros((len(text_int), seq_len), dtype = int)\n",
    "    for i, review in enumerate(text_int):\n",
    "        if len(review) <= seq_len:\n",
    "            zeros = list(np.zeros(seq_len - len(review)))\n",
    "            new = zeros + review\n",
    "        else:\n",
    "            new = review[: seq_len]\n",
    "        features[i, :] = np.array(new)\n",
    "\n",
    "    return sorted_words, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "id": "KqUTb1b8kd9P"
   },
   "outputs": [],
   "source": [
    "vocabulary, tokenized_column = Tokenize(df[\"text_clean\"], max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "id": "d02_zwPL-9EZ"
   },
   "outputs": [],
   "source": [
    "X = df['text_clean']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "id": "2azevoNY-y6g"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idKd2ISaEy9d"
   },
   "source": [
    "Text embedding with pre-trained Word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "id": "_TdbROTk7nYE"
   },
   "outputs": [],
   "source": [
    "Word2vec_train_data = list(map(lambda x: x.split(), X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "id": "EefOe-5Y7rSm"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "id": "fSmBTU0Y7vMO"
   },
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(Word2vec_train_data, vector_size=EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "id": "IZyohOul7yPO"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocabulary) + 1 #+1 for the padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nx5AIcgi68QL",
    "outputId": "94715133-007a-4b77-faa8-b7bb1fad6019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Matrix Shape: (37605, 200)\n"
     ]
    }
   ],
   "source": [
    "# Define an empty embedding matrix of shape (VOCAB_SIZE, EMBEDDING_DIM)\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
    "\n",
    "# Fill the embedding matrix with pre-trained values from word2vec\n",
    "for word, token in vocabulary:\n",
    "    # Check if the word is present in the word2vec model's vocabulary\n",
    "    if word in word2vec_model.wv.key_to_index:\n",
    "        # If the word is present, retrieve its embedding vector and add it to the embedding matrix\n",
    "        embedding_vector = word2vec_model.wv[word]\n",
    "        embedding_matrix[token] = embedding_vector\n",
    "\n",
    "# Print the shape of the embedding matrix\n",
    "print(\"Embedding Matrix Shape:\", embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "id": "tfO4cnjz7_Ot"
   },
   "outputs": [],
   "source": [
    "X = tokenized_column\n",
    "y = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "id": "EOAc1Vm38Njv"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ly-3aQBnFRcj"
   },
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "id": "achdE0dQ8WEO"
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler()\n",
    "X_train_os, y_train_os = ros.fit_resample(np.array(X_train),np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sac738LjIWXP",
    "outputId": "864194da-252b-44c6-8f3f-a21764cad6f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31335, 31)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_os.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGYWBOQ0FW2M"
   },
   "source": [
    "Finally, we define our preprocessed dataset and loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "id": "jyEGOm9Z8ffa"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(X_train_os), torch.from_numpy(y_train_os))\n",
    "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "id": "WjpbNrLb8jN2"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "id": "mr-o8hPq8lXW"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2V1uSsNFp3h"
   },
   "source": [
    "# Implementation of the classical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "660eM2fEF30E"
   },
   "source": [
    "In this paragraph we will implement model with classical convolution and LSTM in order to compare it with its hybrid-quantum analogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "id": "-VTp5AVlJA3l"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        # The attention linear layer which transforms the input data to the hidden space\n",
    "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim )\n",
    "        # The linear layer that calculates the attention scores\n",
    "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = encoder_outputs.size(1)\n",
    "        # Concatenate the last two hidden states in case of a bidirectional LSTM\n",
    "        hidden = hidden[-1]\n",
    "        # Repeat the hidden state across the sequence length\n",
    "        hidden_repeated = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
    "        # Calculate attention weights\n",
    "        attn_weights = torch.tanh(self.attn(torch.cat((hidden_repeated, encoder_outputs), dim=2)))\n",
    "        # Compute attention scores\n",
    "        attn_weights = self.v(attn_weights).squeeze(2)\n",
    "        # Apply softmax to get valid probabilities\n",
    "        return nn.functional.softmax(attn_weights, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "id": "raK4JVSHExXS"
   },
   "outputs": [],
   "source": [
    "class ClassicalModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, in_channels, out_channels, kernel_size, stride, padding, hidden_dim, num_classes, lstm_layers):\n",
    "        super(ClassicalModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = lstm_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, lstm_layers, batch_first=True)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # Transform words to embeddings\n",
    "        embedded = self.embedding(x)\n",
    "        # embedded = self.conv(embedded.unsqueeze(1))\n",
    "        # # Pass embeddings to LSTM\n",
    "        # out, hidden = self.lstm(embedded.reshape(-1, embedded.size(1)*embedded.size(2), embedded.size(-1)), hidden)\n",
    "        out, hidden = self.lstm(embedded, hidden)\n",
    "        # Calculate attention weights\n",
    "        attn_weights = self.attention(hidden[0], out)\n",
    "        # Calculate context vector by taking the weighted sum of LSTM outputs\n",
    "        context = attn_weights.unsqueeze(1).bmm(out).squeeze(1)\n",
    "        # Classify the context vector\n",
    "        out = self.softmax(self.fc(context))\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim)\n",
    "        return h0, c0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFolBcU3GjzL"
   },
   "source": [
    "# Implementation of the hybrid-quantum model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "id": "Zx9MSDbdkO5y"
   },
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface='torch')\n",
    "def quanvcirc(patch, weights, wires=range(num_qubits)):\n",
    "    # Angle embedding of the patch (reshape to match expected size)\n",
    "    qml.AngleEmbedding(patch, wires=wires, rotation='Y')\n",
    "\n",
    "    # Apply RX rotations based on the weights\n",
    "    qml.RX(weights[0][0], wires=0)\n",
    "    qml.RX(weights[0][1], wires=1)\n",
    "    qml.RY(weights[1][0], wires=2)\n",
    "    qml.RY(weights[1][1], wires=3)\n",
    "\n",
    "    # Apply CNOT gates\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    qml.CNOT(wires=[2, 3])\n",
    "    qml.CNOT(wires=[3, 0])\n",
    "    # Apply RY rotations based on the weights\n",
    "\n",
    "\n",
    "    # Return the expectation values of Pauli-Z measurements on all qubits\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_G1L7z_enlfZ",
    "outputId": "2bec97be-b42e-49eb-e113-1f50e6649e28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ─╭AngleEmbedding(M0)──RX(1.00)─╭●───────╭X─┤  <Z>\n",
      "1: ─├AngleEmbedding(M0)──RX(1.00)─╰X─╭●────│──┤     \n",
      "2: ─├AngleEmbedding(M0)──RY(1.00)────╰X─╭●─│──┤     \n",
      "3: ─╰AngleEmbedding(M0)──RY(1.00)───────╰X─╰●─┤     \n",
      "\n",
      "M0 = \n",
      "[[1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(qml.draw(quanvcirc)(np.ones((1, 4)), np.ones((2, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "id": "ikYNnTA1pr6A"
   },
   "outputs": [],
   "source": [
    "class QuanConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(QuanConv2D, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        # Define weights and biases as trainable parameters\n",
    "        self.weights = nn.Parameter(\n",
    "            torch.randn(out_channels, in_channels, kernel_size, kernel_size), requires_grad = True\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Extract dimensions\n",
    "        batch_size, in_channels, input_height, input_width = input.shape\n",
    "\n",
    "        # Calculate output dimensions\n",
    "        output_height = (input_height - self.kernel_size + 2 * self.padding) // self.stride + 1\n",
    "        output_width = (input_width - self.kernel_size + 2 * self.padding) // self.stride + 1\n",
    "\n",
    "        # Initialize output tensor\n",
    "        output = torch.zeros(batch_size, self.out_channels, output_height, output_width)\n",
    "\n",
    "        # If padding is required, add it to the input\n",
    "        if self.padding > 0:\n",
    "            input = F.pad(input, (self.padding, self.padding, self.padding, self.padding))\n",
    "\n",
    "        # Perform convolution\n",
    "        for b in range(batch_size):\n",
    "            for c_out in range(self.out_channels):\n",
    "                for h in range(output_height):\n",
    "                    for w in range(output_width):\n",
    "                        h_start = h * self.stride\n",
    "                        h_end = h_start + self.kernel_size\n",
    "                        w_start = w * self.stride\n",
    "                        w_end = w_start + self.kernel_size\n",
    "\n",
    "                        # Slice the input for the current window\n",
    "                        input_slice = input[b, :, h_start:h_end, w_start:w_end]\n",
    "\n",
    "                        # Perform element-wise multiplication and sum with bias\n",
    "                        output[b, c_out, h, w] = quanvcirc(input_slice.reshape(1, self.kernel_size * self.kernel_size), self.weights[c_out].squeeze(0))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "id": "ZXzmC0KuyEDb"
   },
   "outputs": [],
   "source": [
    "qdi_reps1 = 2\n",
    "qdi_reps2 = 2\n",
    "qdi_depth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "id": "QixHflZxxt-Y"
   },
   "outputs": [],
   "source": [
    "@qml.qnode(dev, interface='torch', diff_method=\"adjoint\")\n",
    "def qdi_circuit(weights, input_array, wires=range(num_qubits)):\n",
    "    for r in range(qdi_reps1):\n",
    "        for i in range(len(wires)):\n",
    "            qml.RX(weights[r][i], wires=wires[i])\n",
    "        for j in range(len(wires)-1):\n",
    "            qml.CNOT(wires=[wires[j], wires[j+1]])\n",
    "        qml.CNOT(wires=[wires[len(wires)-1], wires[0]])\n",
    "        # qml.Barrier()\n",
    "    for d in range(qdi_depth):\n",
    "        qml.AngleEmbedding(input_array, wires=range(num_qubits), rotation='Z')\n",
    "        for r in range(qdi_reps2):\n",
    "            for i in range(len(wires)):\n",
    "                qml.RX(weights[qdi_reps1+d*r][i], wires=wires[i])\n",
    "            for j in range(len(wires)-1):\n",
    "                qml.CNOT(wires=[wires[j], wires[j+1]])\n",
    "            qml.CNOT(wires=[wires[len(wires)-1], wires[0]])\n",
    "            # qml.Barrier()\n",
    "        # qml.Barrier()\n",
    "    return [qml.expval(qml.PauliY(w)) for w in wires]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iRFx50H6RkcR",
    "outputId": "6c3c5367-a2d3-4332-d6b1-e9e445cc563f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──RX(1.00)─╭●───────╭X──RX(1.00)─╭●───────╭X─╭AngleEmbedding(M0)──RX(1.00)─╭●───────╭X──RX(1.00)\n",
      "1: ──RX(1.00)─╰X─╭●────│───RX(1.00)─╰X─╭●────│──├AngleEmbedding(M0)──RX(1.00)─╰X─╭●────│───RX(1.00)\n",
      "2: ──RX(1.00)────╰X─╭●─│───RX(1.00)────╰X─╭●─│──├AngleEmbedding(M0)──RX(1.00)────╰X─╭●─│───RX(1.00)\n",
      "3: ──RX(1.00)───────╰X─╰●──RX(1.00)───────╰X─╰●─╰AngleEmbedding(M0)──RX(1.00)───────╰X─╰●──RX(1.00)\n",
      "\n",
      "──╭●───────╭X─┤  <Y>\n",
      "──╰X─╭●────│──┤  <Y>\n",
      "─────╰X─╭●─│──┤  <Y>\n",
      "────────╰X─╰●─┤  <Y>\n",
      "\n",
      "M0 = \n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(qml.draw(qdi_circuit)(np.ones((qdi_reps1 + qdi_reps2, num_qubits)), np.ones((4, 4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": true,
    "id": "v_mvdRnDqcze"
   },
   "outputs": [],
   "source": [
    "class HQLSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_qubits):\n",
    "        super(HQLSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Combined weights for efficiency\n",
    "        self.W_input = nn.Parameter(torch.rand(4 * num_qubits, input_size), requires_grad = True).float()\n",
    "        self.W_hid = nn.Parameter(torch.rand(4 * num_qubits, hidden_size), requires_grad = True).float()\n",
    "        self.W_quan = nn.Parameter(torch.zeros(4, qdi_reps1 + qdi_reps2, num_qubits), requires_grad = True).float()\n",
    "        self.W = nn.Parameter(torch.rand(4, hidden_size, num_qubits), requires_grad = True).float()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        h_prev, c_prev = hidden\n",
    "\n",
    "        yield_input = F.linear(x, self.W_input)\n",
    "        yield_hidden = F.linear(h_prev, self.W_hid)\n",
    "        # Concatenate input and previous hidden state\n",
    "        combined = yield_input + yield_hidden\n",
    "        # combined = torch.cat((yield_input, yield_hidden), dim=1)\n",
    "\n",
    "        # Apply linear transformation\n",
    "\n",
    "        # Split into gates\n",
    "        # combined = torch.cat([torch.stack(qdi_circuit(self.W_quan[i], combined[:, i:i*num_qubits].reshape(-1, num_qubits))) for i in range(num_qubits)], dim = 0)\n",
    "        i_gate = F.linear(torch.stack(qdi_circuit(self.W_quan[0], combined[:, :num_qubits].reshape(-1, num_qubits))).T.float(), self.W[0])\n",
    "        f_gate = F.linear(torch.stack(qdi_circuit(self.W_quan[1], combined[:, num_qubits:2*num_qubits].reshape(-1, num_qubits))).T.float(), self.W[1])\n",
    "        g_gate = F.linear(torch.stack(qdi_circuit(self.W_quan[2], combined[:, 2*num_qubits:3*num_qubits].reshape(-1, num_qubits))).T.float(), self.W[2])\n",
    "        o_gate = F.linear(torch.stack(qdi_circuit(self.W_quan[3], combined[:, 3*num_qubits:4*num_qubits].reshape(-1, num_qubits))).T.float(), self.W[3])\n",
    "\n",
    "\n",
    "\n",
    "        # combined = torch.cat((i_gate, f_gate, g_gate, o_gate), dim=0).float()\n",
    "        # gates = F.linear(combined, self.W)\n",
    "\n",
    "        # # Split into gates\n",
    "        # i_gate, f_gate, g_gate, o_gate = gates.chunk(4, 0)\n",
    "\n",
    "        # Apply non-linearities\n",
    "        i_gate = torch.sigmoid(i_gate)\n",
    "        f_gate = torch.sigmoid(f_gate)\n",
    "        g_gate = torch.tanh(g_gate)\n",
    "        o_gate = torch.sigmoid(o_gate)\n",
    "\n",
    "        # Update cell state\n",
    "        c_next = (f_gate * c_prev) + (i_gate * g_gate)\n",
    "\n",
    "        # Update hidden state\n",
    "        h_next = o_gate * torch.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "\n",
    "class HQLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_qubits, num_layers=1):\n",
    "        super(HQLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm_cells = nn.ModuleList([HQLSTMCell(input_size if l==0 else hidden_size, hidden_size, num_qubits) for l in range(num_layers)])\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        if hidden is None:\n",
    "             h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "             c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        else:\n",
    "            h0, c0 = hidden\n",
    "\n",
    "        output_seq = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            input_t = x[:, t, :] # input at current timestep\n",
    "            # print(f'step:{t}/{seq_len}, hidden:')\n",
    "\n",
    "            new_h = []\n",
    "            new_c = []\n",
    "\n",
    "            for layer in range(self.num_layers):\n",
    "\n",
    "                # Get hidden state for current layer\n",
    "                h_t, c_t = self.lstm_cells[layer](input_t, (h0[layer], c0[layer]))\n",
    "\n",
    "                # Update hidden states for next timestep, for current layer\n",
    "                new_h.append(h_t)\n",
    "                new_c.append(c_t)\n",
    "                input_t = h_t # The output of current layer is input for the next\n",
    "\n",
    "            h0 = torch.stack(new_h)\n",
    "            c0 = torch.stack(new_c)\n",
    "            # Append hidden state at the topmost layer\n",
    "            output_seq.append(h_t.unsqueeze(1))\n",
    "\n",
    "        # Concatenate the outputs over the sequence length\n",
    "        output_seq = torch.cat(output_seq, dim=1) # output_seq is of shape (batch_size, seq_len, hidden_size)\n",
    "\n",
    "        return output_seq, (h0, c0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "py3iiomANCjY"
   },
   "source": [
    "Toy hybrid-quantum model for benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "id": "RRz02NuCLNvM"
   },
   "outputs": [],
   "source": [
    "class ToyHQModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, in_channels, out_channels, kernel_size, stride, padding, hidden_dim, num_qubits, num_classes, lstm_layers):\n",
    "        super(ToyHQModel, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.num_layers = lstm_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        # self.conv = QuanConv2D(self.in_channels, self.out_channels, self.kernel_size, self.stride, self.padding)\n",
    "        self.lstm = HQLSTM(embedding_dim, hidden_dim, num_qubits, lstm_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Transform words to embeddings\n",
    "        embedded = self.embedding(x)\n",
    "        # x = self.conv(x.unsqueeze(1))\n",
    "        # Pass embeddings to LSTM\n",
    "        out, hidden = self.lstm(embedded)\n",
    "        # Calculate attention weights\n",
    "        attn_weights = self.attention(hidden[0], out)\n",
    "        # Calculate context vector by taking the weighted sum of LSTM outputs\n",
    "        context = attn_weights.unsqueeze(1).bmm(out).squeeze(1)\n",
    "        # Classify the context vector\n",
    "        out = self.softmax(self.fc(context))\n",
    "        return out\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim)\n",
    "        return h0, c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "id": "0V4YMT0JN6Sy"
   },
   "outputs": [],
   "source": [
    "class HybridQuantumModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, in_channels, out_channels, kernel_size, stride, padding, hidden_dim, num_qubits, num_classes, lstm_layers):\n",
    "        super(HybridQuantumModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = HQLSTM(embedding_dim, hidden_dim, num_qubits, lstm_layers)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Transform words to embeddings\n",
    "        embedded = self.embedding(x)\n",
    "        # embedded = self.conv(embedded.unsqueeze(1)).to(device)\n",
    "        # Pass embeddings to LSTM\n",
    "        # out, hidden = self.lstm(embedded.reshape(-1, embedded.size(1)*embedded.size(2), embedded.size(-1)))\n",
    "        out, hidden = self.lstm(embedded)\n",
    "        # Calculate attention weights\n",
    "        attn_weights = self.attention(hidden[0], out)\n",
    "        # Calculate context vector by taking the weighted sum of LSTM outputs\n",
    "        context = attn_weights.unsqueeze(1).bmm(out).squeeze(1)\n",
    "        # Classify the context vector\n",
    "        out = self.softmax(self.fc(context))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvla_k_6IWAH"
   },
   "source": [
    "# Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "id": "bbH3jVkhSWCr"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5 #We are dealing with a multiclass classification of 5 classes\n",
    "HIDDEN_DIM = 16 #number of neurons of the internal state (internal neural network in the LSTM)\n",
    "LSTM_LAYERS = 1 #Number of stacked LSTM layers\n",
    "IN_CHANNELS = 1\n",
    "OUT_CHANNELS = 5\n",
    "KERNEL_SIZE = 2\n",
    "STRIDE = 1\n",
    "PADDING = 1\n",
    "\n",
    "\n",
    "LR = 0.001 #Learning rate\n",
    "EPOCHS = 10 #Number of training epoch\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJnLZ5GCMMNF",
    "outputId": "6bbdfd11-9d94-4d5f-dd61-3d08452a43fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassicalModel(\n",
      "  (embedding): Embedding(37605, 200)\n",
      "  (conv): Conv2d(1, 5, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "  (lstm): LSTM(200, 16, batch_first=True)\n",
      "  (attention): Attention(\n",
      "    (attn): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (v): Linear(in_features=16, out_features=1, bias=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=16, out_features=5, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "classical_model = ClassicalModel(VOCAB_SIZE, EMBEDDING_DIM, IN_CHANNELS, OUT_CHANNELS, KERNEL_SIZE, STRIDE, PADDING, HIDDEN_DIM, NUM_CLASSES, LSTM_LAYERS)\n",
    "classical_model = classical_model\n",
    "# classical_model = torch.compile(classical_model)\n",
    "\n",
    "cl_optimizer = torch.optim.AdamW(classical_model.parameters(), lr=LR, weight_decay = 5e-6)\n",
    "\n",
    "print(classical_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "id": "vWLWMuTwu-ZR"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'embedding' in name:\n",
    "            nn.init.uniform_(param, -0.1, 0.1)\n",
    "        elif 'lstm' in name:\n",
    "            if 'weight' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0)\n",
    "        elif 'fc' in name:\n",
    "            nn.init.xavier_uniform_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_yVpeUhBSeXi",
    "outputId": "82533239-fb6e-47c4-bd0f-4462701a9b0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HybridQuantumModel(\n",
      "  (embedding): Embedding(37605, 200)\n",
      "  (lstm): HQLSTM(\n",
      "    (lstm_cells): ModuleList(\n",
      "      (0): HQLSTMCell(\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (attention): Attention(\n",
      "    (attn): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (v): Linear(in_features=16, out_features=1, bias=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=16, out_features=5, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hybrid_quantum_model = HybridQuantumModel(VOCAB_SIZE, EMBEDDING_DIM, IN_CHANNELS, OUT_CHANNELS, KERNEL_SIZE, STRIDE, PADDING, HIDDEN_DIM, num_qubits, NUM_CLASSES, LSTM_LAYERS)\n",
    "# initialize_weights(hybrid_quantum_model)\n",
    "\n",
    "\n",
    "# hybrid_quantum_model = torch.compile(hybrid_quantum_model)\n",
    "\n",
    "hq_optimizer = torch.optim.AdamW(hybrid_quantum_model.parameters(), lr=LR, weight_decay = 5e-6)\n",
    "\n",
    "print(hybrid_quantum_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "id": "ObgTsuW6kO5z"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, criterion, optimizer,\n",
    "          train_dataloader, test_dataloader, num_epochs):\n",
    "\n",
    "    train_losses = np.zeros(num_epochs)\n",
    "    test_losses = np.zeros(num_epochs)\n",
    "\n",
    "    train_accuracy_arr = np.zeros(num_epochs)\n",
    "    test_accuracy_arr = np.zeros(num_epochs)\n",
    "\n",
    "    for i_epoch in tqdm(range(num_epochs)):\n",
    "        it = 0\n",
    "        train_loss = 0\n",
    "        test_loss = 0\n",
    "\n",
    "        train_accuracy = 0\n",
    "        test_accuracy = 0\n",
    "\n",
    "        # train step\n",
    "        model.train()\n",
    "        for batch in train_dataloader:\n",
    "            start_time = time.time()\n",
    "            X = batch[0]\n",
    "            y = batch[1]\n",
    "\n",
    "            h = model.init_hidden(y.size(0))\n",
    "            # model forward-pass\n",
    "            preds, h = model(X, h)\n",
    "\n",
    "            # model backward-pass\n",
    "            optimizer.zero_grad() # t.grad = torch.tensor([0., 0., 0.])\n",
    "            loss = criterion(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step() # t = t - lr * t.grad\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "\n",
    "            # save loss and accuracy\n",
    "            train_loss += loss.detach().cpu().numpy()\n",
    "            # print(f'batch: {it+1}/{len(train_dataloader)}, loss: {train_loss/(it+1):.4f}, time: {execution_time:.4f}')\n",
    "            it += 1\n",
    "            train_accuracy += (preds.argmax(-1).detach() == y).cpu().numpy().mean()\n",
    "\n",
    "\n",
    "        train_loss /= len(train_dataloader)\n",
    "        train_accuracy /= len(train_dataloader)\n",
    "        train_losses[i_epoch] = train_loss\n",
    "        train_accuracy_arr[i_epoch] = train_accuracy\n",
    "\n",
    "        # test step\n",
    "        model.eval()\n",
    "        for batch in test_dataloader:\n",
    "            X = batch[0]\n",
    "            y = batch[1]\n",
    "\n",
    "            h = model.init_hidden(y.size(0))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # model forward-pass\n",
    "                preds, h = model(X, h)\n",
    "                loss = criterion(preds, y)\n",
    "\n",
    "                # save loss and accuracy\n",
    "                test_loss += loss.detach().cpu().numpy()\n",
    "                test_accuracy += (preds.argmax(-1) == y).cpu().numpy().mean()\n",
    "\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_accuracy /= len(test_dataloader)\n",
    "\n",
    "        test_losses[i_epoch] = test_loss\n",
    "        test_accuracy_arr[i_epoch] = test_accuracy\n",
    "\n",
    "    return train_losses, test_losses, train_accuracy_arr, test_accuracy_arr\n",
    "\n",
    "def train_for_hqnn(model, criterion, optimizer,\n",
    "          train_dataloader, test_dataloader, num_epochs):\n",
    "\n",
    "    train_losses = np.zeros(num_epochs)\n",
    "    test_losses = np.zeros(num_epochs)\n",
    "\n",
    "    train_accuracy_arr = np.zeros(num_epochs)\n",
    "    test_accuracy_arr = np.zeros(num_epochs)\n",
    "\n",
    "    for i_epoch in tqdm(range(num_epochs)):\n",
    "        it = 0\n",
    "\n",
    "        train_loss = 0\n",
    "        test_loss = 0\n",
    "\n",
    "        train_accuracy = 0\n",
    "        test_accuracy = 0\n",
    "\n",
    "        # train step\n",
    "        model.train()\n",
    "        for batch in train_dataloader:\n",
    "            start_time = time.time()\n",
    "            X = batch[0]\n",
    "            y = batch[1]\n",
    "\n",
    "            # model forward-pass\n",
    "            preds = model(X)\n",
    "\n",
    "            # model backward-pass\n",
    "            optimizer.zero_grad() # t.grad = torch.tensor([0., 0., 0.])\n",
    "            loss = criterion(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step() # t = t - lr * t.grad\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "\n",
    "            # save loss and accuracy\n",
    "            train_loss += loss.detach().cpu().numpy()\n",
    "            print(f'it: {it+1}/{len(train_dataloader)}, loss: {train_loss/(it+1):.4f}, time: {execution_time:.4f}')\n",
    "            it += 1\n",
    "            train_accuracy += (preds.argmax(-1).detach() == y).cpu().numpy().mean()\n",
    "\n",
    "\n",
    "        train_loss /= len(train_dataloader)\n",
    "        train_accuracy /= len(train_dataloader)\n",
    "        train_losses[i_epoch] = train_loss\n",
    "\n",
    "        train_accuracy_arr[i_epoch] = train_accuracy\n",
    "\n",
    "        # test step\n",
    "        model.eval()\n",
    "        for batch in test_dataloader:\n",
    "            X = batch[0]\n",
    "            y = batch[1]\n",
    "\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # model forward-pass\n",
    "                preds = model(X)\n",
    "                loss = criterion(preds, y)\n",
    "\n",
    "                # save loss and accuracy\n",
    "                test_loss += loss.detach().cpu().numpy()\n",
    "                test_accuracy += (preds.argmax(-1) == y).cpu().numpy().mean()\n",
    "\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_accuracy /= len(test_dataloader)\n",
    "\n",
    "        test_losses[i_epoch] = test_loss\n",
    "        test_accuracy_arr[i_epoch] = test_accuracy\n",
    "\n",
    "    return train_losses, test_losses, train_accuracy_arr, test_accuracy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 18:49:35,308] A new study created in memory with name: no-name-fc5f53d8-e022-4200-96b8-84d07baa0f62\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93e5e56f1da4b43b0f6a72ffd7ba699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 1/489, loss: 1.6174, time: 44.0837\n",
      "it: 2/489, loss: 1.6758, time: 44.3099\n",
      "it: 3/489, loss: 2.8335, time: 44.0837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-11-06 18:52:15,126] Trial 0 failed with parameters: {'hidden_size': 112, 'lr': 0.7554263487989283, 'batch_size': 64} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\den1s\\AppData\\Local\\Temp\\ipykernel_12612\\1114743374.py\", line 47, in objective\n",
      "    preds = hybrid_quantum_model(X)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\den1s\\AppData\\Local\\Temp\\ipykernel_12612\\306134021.py\", line 17, in forward\n",
      "    out, hidden = self.lstm(embedded)\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\den1s\\AppData\\Local\\Temp\\ipykernel_12612\\916245881.py\", line 85, in forward\n",
      "    h_t, c_t = self.lstm_cells[layer](input_t, (h0[layer], c0[layer]))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\den1s\\AppData\\Local\\Temp\\ipykernel_12612\\916245881.py\", line 27, in forward\n",
      "    f_gate = F.linear(torch.stack(qdi_circuit(self.W_quan[1], combined[:, num_qubits:2*num_qubits].reshape(-1, num_qubits))).T.float(), self.W[1])\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\qnode.py\", line 1020, in __call__\n",
      "    return self._impl_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\qnode.py\", line 1008, in _impl_call\n",
      "    res = self._execution_component(args, kwargs, override_shots=override_shots)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\qnode.py\", line 957, in _execution_component\n",
      "    res = qml.execute(\n",
      "          ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\execution.py\", line 771, in execute\n",
      "    results = ml_boundary_execute(tapes, execute_fn, jpc, device=device)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py\", line 236, in execute\n",
      "    return ExecuteTapes.apply(kwargs, *parameters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py\", line 89, in new_apply\n",
      "    flat_out = orig_apply(out_struct_holder, *inp)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\function.py\", line 575, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py\", line 93, in new_forward\n",
      "    out = orig_fw(ctx, *inp)\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py\", line 158, in forward\n",
      "    res = tuple(kwargs[\"execute_fn\"](ctx.tapes))\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\jacobian_products.py\", line 462, in execute_and_cache_jacobian\n",
      "    results, jac = self._dev_execute_and_compute_derivatives(tapes)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\jacobian_products.py\", line 427, in _dev_execute_and_compute_derivatives\n",
      "    return self._device.execute_and_compute_derivatives(numpy_tapes, self._execution_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\modifiers\\simulator_tracking.py\", line 97, in execute_and_compute_derivatives\n",
      "    return untracked_execute_and_compute_derivatives(self, circuits, execution_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\modifiers\\single_tape_support.py\", line 62, in execute_and_compute_derivatives\n",
      "    results, jacs = batch_execute_and_compute_derivatives(self, circuits, execution_config)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\modifiers\\simulator_tracking.py\", line 97, in execute_and_compute_derivatives\n",
      "    return untracked_execute_and_compute_derivatives(self, circuits, execution_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\modifiers\\single_tape_support.py\", line 62, in execute_and_compute_derivatives\n",
      "    results, jacs = batch_execute_and_compute_derivatives(self, circuits, execution_config)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane_lightning\\core\\lightning_newAPI_base.py\", line 334, in execute_and_compute_derivatives\n",
      "    results = tuple(\n",
      "              ^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane_lightning\\core\\lightning_newAPI_base.py\", line 335, in <genexpr>\n",
      "    self.simulate_and_jacobian(\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane_lightning\\core\\lightning_newAPI_base.py\", line 230, in simulate_and_jacobian\n",
      "    jac = self.LightningAdjointJacobian(state, batch_obs=batch_obs).calculate_jacobian(circuit)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane_lightning\\lightning_qubit\\_adjoint_jacobian.py\", line 132, in calculate_jacobian\n",
      "    return self._adjoint_jacobian_processing(jac_r)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane_lightning\\core\\_adjoint_jacobian_base.py\", line 153, in _adjoint_jacobian_processing\n",
      "    @staticmethod\n",
      "    \n",
      "KeyboardInterrupt\n",
      "[W 2024-11-06 18:52:15,131] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[428], line 97\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Define and execute the study\u001b[39;00m\n\u001b[0;32m     96\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 97\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[428], line 47\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     44\u001b[0m y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# model forward-pass\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mhybrid_quantum_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# model backward-pass\u001b[39;00m\n\u001b[0;32m     50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# t.grad = torch.tensor([0., 0., 0.])\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[414], line 17\u001b[0m, in \u001b[0;36mHybridQuantumModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# embedded = self.conv(embedded.unsqueeze(1)).to(device)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Pass embeddings to LSTM\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# out, hidden = self.lstm(embedded.reshape(-1, embedded.size(1)*embedded.size(2), embedded.size(-1)))\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate attention weights\u001b[39;00m\n\u001b[0;32m     19\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(hidden[\u001b[38;5;241m0\u001b[39m], out)\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[412], line 85\u001b[0m, in \u001b[0;36mHQLSTM.forward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     80\u001b[0m new_c \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers):\n\u001b[0;32m     83\u001b[0m \n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# Get hidden state for current layer\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m     h_t, c_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm_cells\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Update hidden states for next timestep, for current layer\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     new_h\u001b[38;5;241m.\u001b[39mappend(h_t)\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[412], line 27\u001b[0m, in \u001b[0;36mHQLSTMCell.forward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# combined = torch.cat((yield_input, yield_hidden), dim=1)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Apply linear transformation\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Split into gates\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# combined = torch.cat([torch.stack(qdi_circuit(self.W_quan[i], combined[:, i:i*num_qubits].reshape(-1, num_qubits))) for i in range(num_qubits)], dim = 0)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m i_gate \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(torch\u001b[38;5;241m.\u001b[39mstack(qdi_circuit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_quan[\u001b[38;5;241m0\u001b[39m], combined[:, :num_qubits]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, num_qubits)))\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mfloat(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 27\u001b[0m f_gate \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(torch\u001b[38;5;241m.\u001b[39mstack(\u001b[43mqdi_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_quan\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_qubits\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnum_qubits\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_qubits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mfloat(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     28\u001b[0m g_gate \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(torch\u001b[38;5;241m.\u001b[39mstack(qdi_circuit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_quan[\u001b[38;5;241m2\u001b[39m], combined[:, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mnum_qubits:\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mnum_qubits]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, num_qubits)))\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mfloat(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     29\u001b[0m o_gate \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(torch\u001b[38;5;241m.\u001b[39mstack(qdi_circuit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_quan[\u001b[38;5;241m3\u001b[39m], combined[:, \u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mnum_qubits:\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39mnum_qubits]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, num_qubits)))\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mfloat(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW[\u001b[38;5;241m3\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\qnode.py:1020\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mcapture\u001b[38;5;241m.\u001b[39menabled():\n\u001b[0;32m   1019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mcapture\u001b[38;5;241m.\u001b[39mqnode_call(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1020\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\qnode.py:1008\u001b[0m, in \u001b[0;36mQNode._impl_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_gradient_fn(shots\u001b[38;5;241m=\u001b[39moverride_shots, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape)\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1008\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_component\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverride_shots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_shots\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m old_interface \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\qnode.py:957\u001b[0m, in \u001b[0;36mQNode._execution_component\u001b[1;34m(self, args, kwargs, override_shots)\u001b[0m\n\u001b[0;32m    951\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[0;32m    952\u001b[0m         action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    953\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.*argument is deprecated and will be removed in version 0.39.*\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    954\u001b[0m         category\u001b[38;5;241m=\u001b[39mqml\u001b[38;5;241m.\u001b[39mPennyLaneDeprecationWarning,\n\u001b[0;32m    955\u001b[0m     )\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;66;03m# pylint: disable=unexpected-keyword-arg\u001b[39;00m\n\u001b[1;32m--> 957\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43minner_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_shots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_shots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    969\u001b[0m res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\execution.py:771\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(tapes, device, gradient_fn, interface, transform_program, inner_transform, config, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform, device_vjp, mcm_config)\u001b[0m\n\u001b[0;32m    763\u001b[0m ml_boundary_execute \u001b[38;5;241m=\u001b[39m _get_ml_boundary_execute(\n\u001b[0;32m    764\u001b[0m     interface,\n\u001b[0;32m    765\u001b[0m     config\u001b[38;5;241m.\u001b[39mgrad_on_execution,\n\u001b[0;32m    766\u001b[0m     config\u001b[38;5;241m.\u001b[39muse_device_jacobian_product,\n\u001b[0;32m    767\u001b[0m     differentiable\u001b[38;5;241m=\u001b[39mmax_diff \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    768\u001b[0m )\n\u001b[0;32m    770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interface \u001b[38;5;129;01min\u001b[39;00m jpc_interfaces:\n\u001b[1;32m--> 771\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mml_boundary_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecute_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjpc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     results \u001b[38;5;241m=\u001b[39m ml_boundary_execute(\n\u001b[0;32m    774\u001b[0m         tapes, device, execute_fn, gradient_fn, gradient_kwargs, _n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, max_diff\u001b[38;5;241m=\u001b[39mmax_diff\n\u001b[0;32m    775\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:236\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(tapes, execute_fn, jpc, device)\u001b[0m\n\u001b[0;32m    228\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mextend(tape\u001b[38;5;241m.\u001b[39mget_parameters())\n\u001b[0;32m    230\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(tapes),\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecute_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m: execute_fn,\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpc\u001b[39m\u001b[38;5;124m\"\u001b[39m: jpc,\n\u001b[0;32m    234\u001b[0m }\n\u001b[1;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mExecuteTapes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:89\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_apply\u001b[1;34m(*inp)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_apply\u001b[39m(\u001b[38;5;241m*\u001b[39minp):\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Inputs already flat\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     out_struct_holder \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 89\u001b[0m     flat_out \u001b[38;5;241m=\u001b[39m \u001b[43morig_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_struct_holder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pytree\u001b[38;5;241m.\u001b[39mtree_unflatten(flat_out, out_struct_holder[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:93\u001b[0m, in \u001b[0;36mpytreeify.<locals>.new_forward\u001b[1;34m(ctx, out_struct_holder, *inp)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_forward\u001b[39m(ctx, out_struct_holder, \u001b[38;5;241m*\u001b[39minp):\n\u001b[1;32m---> 93\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43morig_fw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     flat_out, out_struct \u001b[38;5;241m=\u001b[39m pytree\u001b[38;5;241m.\u001b[39mtree_flatten(out)\n\u001b[0;32m     95\u001b[0m     ctx\u001b[38;5;241m.\u001b[39m_out_struct \u001b[38;5;241m=\u001b[39m out_struct\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\interfaces\\torch.py:158\u001b[0m, in \u001b[0;36mExecuteTapes.forward\u001b[1;34m(ctx, kwargs, *parameters)\u001b[0m\n\u001b[0;32m    155\u001b[0m ctx\u001b[38;5;241m.\u001b[39mtapes \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    156\u001b[0m ctx\u001b[38;5;241m.\u001b[39mjpc \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjpc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 158\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexecute_fn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# if any input tensor uses the GPU, the output should as well\u001b[39;00m\n\u001b[0;32m    161\u001b[0m ctx\u001b[38;5;241m.\u001b[39mtorch_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\jacobian_products.py:462\u001b[0m, in \u001b[0;36mDeviceDerivatives.execute_and_cache_jacobian\u001b[1;34m(self, tapes)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger\u001b[38;5;241m.\u001b[39misEnabledFor(logging\u001b[38;5;241m.\u001b[39mDEBUG):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    461\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForward pass called with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, tapes)\n\u001b[1;32m--> 462\u001b[0m results, jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dev_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results_cache[tapes] \u001b[38;5;241m=\u001b[39m results\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jacs_cache[tapes] \u001b[38;5;241m=\u001b[39m jac\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\workflow\\jacobian_products.py:427\u001b[0m, in \u001b[0;36mDeviceDerivatives._dev_execute_and_compute_derivatives\u001b[1;34m(self, tapes)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;124;03mConverts tapes to numpy before computing the the results and derivatives on the device.\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \n\u001b[0;32m    424\u001b[0m \u001b[38;5;124;03mDispatches between the two different device interfaces.\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    426\u001b[0m numpy_tapes, _ \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mconvert_to_numpy_parameters(tapes)\n\u001b[1;32m--> 427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_device\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumpy_tapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\modifiers\\simulator_tracking.py:97\u001b[0m, in \u001b[0;36m_track_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[1;34m(self, circuits, execution_config)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m     92\u001b[0m         execute_and_derivative_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     93\u001b[0m         executions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[0;32m     94\u001b[0m         derivatives\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[0;32m     95\u001b[0m     )\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mrecord()\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muntracked_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\modifiers\\single_tape_support.py:62\u001b[0m, in \u001b[0;36m_make_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[1;34m(self, circuits, execution_config)\u001b[0m\n\u001b[0;32m     60\u001b[0m     is_single_circuit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     circuits \u001b[38;5;241m=\u001b[39m (circuits,)\n\u001b[1;32m---> 62\u001b[0m results, jacs \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (results[\u001b[38;5;241m0\u001b[39m], jacs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m is_single_circuit \u001b[38;5;28;01melse\u001b[39;00m (results, jacs)\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\modifiers\\simulator_tracking.py:97\u001b[0m, in \u001b[0;36m_track_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[1;34m(self, circuits, execution_config)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m     92\u001b[0m         execute_and_derivative_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     93\u001b[0m         executions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[0;32m     94\u001b[0m         derivatives\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch),\n\u001b[0;32m     95\u001b[0m     )\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker\u001b[38;5;241m.\u001b[39mrecord()\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muntracked_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\modifiers\\single_tape_support.py:62\u001b[0m, in \u001b[0;36m_make_execute_and_compute_derivatives.<locals>.execute_and_compute_derivatives\u001b[1;34m(self, circuits, execution_config)\u001b[0m\n\u001b[0;32m     60\u001b[0m     is_single_circuit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     circuits \u001b[38;5;241m=\u001b[39m (circuits,)\n\u001b[1;32m---> 62\u001b[0m results, jacs \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_execute_and_compute_derivatives\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (results[\u001b[38;5;241m0\u001b[39m], jacs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m is_single_circuit \u001b[38;5;28;01melse\u001b[39;00m (results, jacs)\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane_lightning\\core\\lightning_newAPI_base.py:334\u001b[0m, in \u001b[0;36mLightningBase.execute_and_compute_derivatives\u001b[1;34m(self, circuits, execution_config)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the results and jacobians of circuits at the same time.\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;124;03m    Tuple: A numeric result of the computation and the gradient.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    333\u001b[0m batch_obs \u001b[38;5;241m=\u001b[39m execution_config\u001b[38;5;241m.\u001b[39mdevice_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_obs)\n\u001b[1;32m--> 334\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulate_and_jacobian(\n\u001b[0;32m    336\u001b[0m         c, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_statevector, batch_obs\u001b[38;5;241m=\u001b[39mbatch_obs, wire_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wire_map\n\u001b[0;32m    337\u001b[0m     )\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m circuits\n\u001b[0;32m    339\u001b[0m )\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults))\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane_lightning\\core\\lightning_newAPI_base.py:335\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the results and jacobians of circuits at the same time.\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;124;03m    Tuple: A numeric result of the computation and the gradient.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    333\u001b[0m batch_obs \u001b[38;5;241m=\u001b[39m execution_config\u001b[38;5;241m.\u001b[39mdevice_options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_obs)\n\u001b[0;32m    334\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m--> 335\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate_and_jacobian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_statevector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwire_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wire_map\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m circuits\n\u001b[0;32m    339\u001b[0m )\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mresults))\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane_lightning\\core\\lightning_newAPI_base.py:230\u001b[0m, in \u001b[0;36mLightningBase.simulate_and_jacobian\u001b[1;34m(self, circuit, state, batch_obs, wire_map)\u001b[0m\n\u001b[0;32m    228\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimulate(circuit, state)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m--> 230\u001b[0m jac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLightningAdjointJacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_obs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_obs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_jacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res, jac\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane_lightning\\lightning_qubit\\_adjoint_jacobian.py:132\u001b[0m, in \u001b[0;36mLightningAdjointJacobian.calculate_jacobian\u001b[1;34m(self, tape)\u001b[0m\n\u001b[0;32m    130\u001b[0m jac_r \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((jac\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], processed_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_params\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m    131\u001b[0m jac_r[:, processed_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecord_tp_rows\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m jac\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adjoint_jacobian_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjac_r\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane_lightning\\core\\_adjoint_jacobian_base.py:153\u001b[0m, in \u001b[0;36mLightningBaseAdjointJacobian._adjoint_jacobian_processing\u001b[1;34m(jac)\u001b[0m\n\u001b[0;32m    141\u001b[0m         tp_shift \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tp_shift]\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate,\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs_serialized\u001b[39m\u001b[38;5;124m\"\u001b[39m: obs_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobs_indices\u001b[39m\u001b[38;5;124m\"\u001b[39m: obs_indices,\n\u001b[0;32m    151\u001b[0m     }\n\u001b[1;32m--> 153\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_adjoint_jacobian_processing\u001b[39m(jac):\n\u001b[0;32m    155\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    Post-process the Jacobian matrix returned by ``adjoint_jacobian`` for\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    the new return type system.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     jac \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(jac)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to tune\n",
    "    HIDDEN_DIM = trial.suggest_int('hidden_size', 32, 128)\n",
    "    lr = trial.suggest_float('lr', 5e-4, 1)\n",
    "    BATCH_SIZE = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "\n",
    "    # Load your dataset\n",
    "    train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "    test_loader = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "    # Initialize model, loss, and optimizer\n",
    "    hybrid_quantum_model = HybridQuantumModel(VOCAB_SIZE, EMBEDDING_DIM, IN_CHANNELS, OUT_CHANNELS, KERNEL_SIZE, STRIDE, PADDING, HIDDEN_DIM, num_qubits, NUM_CLASSES, LSTM_LAYERS)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(hybrid_quantum_model.parameters(), lr=lr)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 1\n",
    "    train_losses = np.zeros(num_epochs)\n",
    "    test_losses = np.zeros(num_epochs)\n",
    "\n",
    "    train_accuracy_arr = np.zeros(num_epochs)\n",
    "    test_accuracy_arr = np.zeros(num_epochs)\n",
    "\n",
    "    for i_epoch in tqdm(range(num_epochs)):\n",
    "        it = 0\n",
    "\n",
    "        train_loss = 0\n",
    "        test_loss = 0\n",
    "\n",
    "        train_accuracy = 0\n",
    "        test_accuracy = 0\n",
    "\n",
    "        # train step\n",
    "        hybrid_quantum_model.train()\n",
    "        for batch in train_loader:\n",
    "            start_time = time.time()\n",
    "            X = batch[0]\n",
    "            y = batch[1]\n",
    "\n",
    "            # model forward-pass\n",
    "            preds = hybrid_quantum_model(X)\n",
    "\n",
    "            # model backward-pass\n",
    "            optimizer.zero_grad() # t.grad = torch.tensor([0., 0., 0.])\n",
    "            loss = criterion(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step() # t = t - lr * t.grad\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "\n",
    "            # save loss and accuracy\n",
    "            train_loss += loss.detach().cpu().numpy()\n",
    "            print(f'it: {it+1}/{len(train_loader)}, loss: {train_loss/(it+1):.4f}, time: {execution_time:.4f}')\n",
    "            it += 1\n",
    "            train_accuracy += (preds.argmax(-1).detach() == y).cpu().numpy().mean()\n",
    "\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy /= len(train_loader)\n",
    "        train_losses[i_epoch] = train_loss\n",
    "\n",
    "        train_accuracy_arr[i_epoch] = train_accuracy\n",
    "\n",
    "        # test step\n",
    "        hybrid_quantum_model.eval()\n",
    "        for batch in test_loader:\n",
    "            X = batch[0]\n",
    "            y = batch[1]\n",
    "\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # model forward-pass\n",
    "                preds = hybrid_quantum_model(X)\n",
    "                loss = criterion(preds, y)\n",
    "\n",
    "                # save loss and accuracy\n",
    "                test_loss += loss.detach().cpu().numpy()\n",
    "                test_accuracy += (preds.argmax(-1) == y).cpu().numpy().mean()\n",
    "\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_accuracy /= len(test_loader)\n",
    "\n",
    "        test_losses[i_epoch] = test_loss\n",
    "        test_accuracy_arr[i_epoch] = test_accuracy\n",
    "\n",
    "    return train_losses, test_losses, train_accuracy_arr, test_accuracy_arr\n",
    "\n",
    "# Define and execute the study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "661cd90b76c9451f98e0ca29c4b22d44",
      "d702bf265eca4bbbbcb7a358df381c65",
      "fc30a6a4b6064be0b3c4a786a4b64952",
      "df78c6ab42474534a547a0a7ba44b754",
      "d49849d9283546c9b34517f327232757",
      "8562c9e4bc8443db82350ff5f496958b",
      "e17bf6667ccd4167af9110a09ba012ac",
      "60ed458c82de4401a7eb400c23f1338d",
      "673f3f8df9244b538ad88f1fc82442b6",
      "029421ef2fec489b8b379351e00e188a",
      "98cad26d7f274b71a04d37fca89196bf"
     ]
    },
    "collapsed": true,
    "id": "1swJ9EmxZKAT",
    "outputId": "17589abb-15b9-4765-8297-2967fc10a0b5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e550524ee41476db13dc6ea806addd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cl_train_losses, \\\n",
    "    cl_test_losses, \\\n",
    "    cl_train_accuracy_arr, \\\n",
    "    cl_test_accuracy_arr = train(classical_model, criterion=criterion,\n",
    "                              optimizer=cl_optimizer,\n",
    "                              train_dataloader=train_loader,\n",
    "                              test_dataloader=test_loader,\n",
    "                              num_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "id": "1SQ4xsOVd0bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.93100111, 0.92948009, 0.93307522, 0.92754425, 0.92975664,\n",
       "        0.92090708, 0.92712942, 0.92712942, 0.91980088, 0.91993916], requires_grad=True)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_test_accuracy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188,
     "referenced_widgets": [
      "7f2f4512c03d4d6d86d51f2f8a3a5fed",
      "22607ed241a74d4f9dc9d471f18e1690",
      "d5590ae5cbe246c8a3b97a1794582dec",
      "889ece199b2a469388992df645c9977e",
      "97def7d09b1a4359bda9237e1a46d28c",
      "b9b9d71402eb46b595cfc84dd522acfb",
      "8f43314093db461f8f90e91e48dbd0da",
      "d623bf979daa40e8af2598e247099b4e",
      "c6fd02082a4342fbb9b9da6449325cfb",
      "d788e171ee934b0d9275fcb6c88d69c8",
      "8ee7f59198f44ac6af6a747b4d7c505a"
     ]
    },
    "id": "2CqcSaKTTMhJ",
    "outputId": "30bdea22-b24c-40d6-f4e4-f220e5e04264"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a826e4ebec3b4b8c9161ea49bf3c6be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'HQLSTM' object has no attribute 'relu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[438], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m hq_train_losses, \\\n\u001b[0;32m      2\u001b[0m     hq_test_losses, \\\n\u001b[0;32m      3\u001b[0m     hq_train_accuracy_arr, \\\n\u001b[1;32m----> 4\u001b[0m     hq_test_accuracy_arr \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_for_hqnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhybrid_quantum_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                              \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhq_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[437], line 103\u001b[0m, in \u001b[0;36mtrain_for_hqnn\u001b[1;34m(model, criterion, optimizer, train_dataloader, test_dataloader, num_epochs)\u001b[0m\n\u001b[0;32m    100\u001b[0m y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# model forward-pass\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# model backward-pass\u001b[39;00m\n\u001b[0;32m    106\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# t.grad = torch.tensor([0., 0., 0.])\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[432], line 17\u001b[0m, in \u001b[0;36mHybridQuantumModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# embedded = self.conv(embedded.unsqueeze(1)).to(device)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Pass embeddings to LSTM\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# out, hidden = self.lstm(embedded.reshape(-1, embedded.size(1)*embedded.size(2), embedded.size(-1)))\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate attention weights\u001b[39;00m\n\u001b[0;32m     19\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(hidden[\u001b[38;5;241m0\u001b[39m], out)\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[430], line 99\u001b[0m, in \u001b[0;36mHQLSTM.forward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     96\u001b[0m     output_seq\u001b[38;5;241m.\u001b[39mappend(h_t\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Concatenate the outputs over the sequence length\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m output_seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m(torch\u001b[38;5;241m.\u001b[39mcat(output_seq, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m# output_seq is of shape (batch_size, seq_len, hidden_size)\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_seq, (h0, c0)\n",
      "File \u001b[1;32mc:\\Users\\den1s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1933\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HQLSTM' object has no attribute 'relu'"
     ]
    }
   ],
   "source": [
    "hq_train_losses, \\\n",
    "    hq_test_losses, \\\n",
    "    hq_train_accuracy_arr, \\\n",
    "    hq_test_accuracy_arr = train_for_hqnn(hybrid_quantum_model, criterion=criterion,\n",
    "                              optimizer=hq_optimizer,\n",
    "                              train_dataloader=train_loader,\n",
    "                              test_dataloader=test_loader,\n",
    "                              num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "id": "Jgjxi_GhTVZd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.32771018, 0.36462942], requires_grad=True)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hq_test_accuracy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "id": "Tsr4BWl-PGF1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.30154013, 0.33413216], requires_grad=True)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hq_train_accuracy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.53139265, 1.47323742], requires_grad=True)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hq_train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(hybrid_quantum_model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pF1KSYMGTdHO"
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "in_channels = 1\n",
    "out_channels = 3\n",
    "length = 31\n",
    "num_classes = 5\n",
    "kernel_size = 2\n",
    "embedding_dim = 200\n",
    "hidden_dim = 100\n",
    "padding = 1\n",
    "stride = 1\n",
    "num_qubits = 4\n",
    "\n",
    "# Create dummy data & labels\n",
    "train_dummy_data = torch.randint(0, 1000, (batch_size, length))\n",
    "train_dummy_labels = torch.randint(0, num_classes, (batch_size,))\n",
    "\n",
    "test_dummy_data = torch.randn(batch_size, length)\n",
    "test_dummy_labels = torch.randint(0, num_classes, (batch_size,))\n",
    "\n",
    "# Create a simple Dataset and DataLoader\n",
    "train_dummy_dataset = TensorDataset(train_dummy_data, train_dummy_labels)\n",
    "train_dummy_loader = DataLoader(train_dummy_dataset, batch_size)\n",
    "\n",
    "test_dummy_dataset = TensorDataset(test_dummy_data, test_dummy_labels)\n",
    "test_dummy_loader = DataLoader(test_dummy_dataset, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZjYDvFJLG0z",
    "outputId": "108bfc04-5bdf-43dc-8322-3659a2112648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToyHQModel(\n",
      "  (embedding): Embedding(37569, 200)\n",
      "  (attention): Attention(\n",
      "    (attn): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (v): Linear(in_features=100, out_features=1, bias=False)\n",
      "  )\n",
      "  (lstm): HQLSTM(\n",
      "    (lstm_cells): ModuleList(\n",
      "      (0): HQLSTMCell()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "LR = 8e-4 #Learning rate\n",
    "\n",
    "toy_hq_model = ToyHQModel(VOCAB_SIZE, embedding_dim, in_channels, out_channels, kernel_size, stride, padding, hidden_dim, num_qubits, num_classes, lstm_layers = 1)\n",
    "\n",
    "toy_hq_model = toy_hq_model\n",
    "# Set up the criterion (loss function)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.AdamW(toy_hq_model.parameters(), lr=LR, weight_decay = 5e-6)\n",
    "\n",
    "print(toy_hq_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AH2z4g_A5FjA",
    "outputId": "ca9d8fa0-d80c-4a16-b9b9-f4bb0df18bb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6381, -1.6118, -1.5608, -1.6813, -1.5606],\n",
       "        [-1.6472, -1.6141, -1.5558, -1.6795, -1.5565]], device='cuda:0',\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_hq_model(train_dummy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rActVEdigY8M",
    "outputId": "05ad61af-0c0d-4c9a-aeb7-d989abf48ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28985, 31)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cps3yt0-eIKQ"
   },
   "outputs": [],
   "source": [
    "# train_dummy_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "# test_dummy_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18tjNlfVeIKR"
   },
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQRprRrveIKR"
   },
   "outputs": [],
   "source": [
    "# train_dummy_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "test_dummy_loader = DataLoader(test_data, shuffle=False, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388,
     "referenced_widgets": [
      "06a8e085c5684549b8564f24bd762e4f",
      "3a33592a8c0f4c3e9e42f2d092dd0889",
      "885eeace639140e2a01b16692b64accc",
      "ca36aa40d1e64ad496b3b838462acaa0",
      "62374ed5a97a431c942ba275585d7d57",
      "6281ff12628a44da968a820165064dd1",
      "a32f46d1b39247d69617fd8d08255dde",
      "e437002cee7c48468d608ac3b6419490",
      "d4d7dc520db647d9bd626ee52f8a35bd",
      "27d5e2469ff444539de5d7d4b4ab6278",
      "875eff2116cf45b9b386071a7d8cc1c7"
     ]
    },
    "id": "RBB6oiTGG02t",
    "outputId": "48e1fb56-cbc4-4c18-9836-1a3a5342eb11"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a8e085c5684549b8564f24bd762e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-fd0fa7cb832d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_accuracy_arr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     test_accuracy_arr = train_for_hqnn(toy_hq_model, criterion=criterion,\n\u001b[0m\u001b[1;32m      5\u001b[0m                               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dummy_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-0036f823edc8>\u001b[0m in \u001b[0;36mtrain_for_hqnn\u001b[0;34m(model, criterion, optimizer, train_dataloader, test_dataloader, num_epochs)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# t.grad = torch.tensor([0., 0., 0.])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# t = t - lr * t.grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, \\\n",
    "    test_losses, \\\n",
    "    train_accuracy_arr, \\\n",
    "    test_accuracy_arr = train_for_hqnn(toy_hq_model, criterion=criterion,\n",
    "                              optimizer=optimizer,\n",
    "                              train_dataloader=train_dummy_loader,\n",
    "                              test_dataloader=test_dummy_loader,\n",
    "                              num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPCx3xe9zXNy"
   },
   "outputs": [],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FysnlhgaW4TF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "029421ef2fec489b8b379351e00e188a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06a8e085c5684549b8564f24bd762e4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3a33592a8c0f4c3e9e42f2d092dd0889",
       "IPY_MODEL_885eeace639140e2a01b16692b64accc",
       "IPY_MODEL_ca36aa40d1e64ad496b3b838462acaa0"
      ],
      "layout": "IPY_MODEL_62374ed5a97a431c942ba275585d7d57"
     }
    },
    "22607ed241a74d4f9dc9d471f18e1690": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9b9d71402eb46b595cfc84dd522acfb",
      "placeholder": "​",
      "style": "IPY_MODEL_8f43314093db461f8f90e91e48dbd0da",
      "value": "  0%"
     }
    },
    "27d5e2469ff444539de5d7d4b4ab6278": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a33592a8c0f4c3e9e42f2d092dd0889": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6281ff12628a44da968a820165064dd1",
      "placeholder": "​",
      "style": "IPY_MODEL_a32f46d1b39247d69617fd8d08255dde",
      "value": "  0%"
     }
    },
    "60ed458c82de4401a7eb400c23f1338d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62374ed5a97a431c942ba275585d7d57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6281ff12628a44da968a820165064dd1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "661cd90b76c9451f98e0ca29c4b22d44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d702bf265eca4bbbbcb7a358df381c65",
       "IPY_MODEL_fc30a6a4b6064be0b3c4a786a4b64952",
       "IPY_MODEL_df78c6ab42474534a547a0a7ba44b754"
      ],
      "layout": "IPY_MODEL_d49849d9283546c9b34517f327232757"
     }
    },
    "673f3f8df9244b538ad88f1fc82442b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7f2f4512c03d4d6d86d51f2f8a3a5fed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_22607ed241a74d4f9dc9d471f18e1690",
       "IPY_MODEL_d5590ae5cbe246c8a3b97a1794582dec",
       "IPY_MODEL_889ece199b2a469388992df645c9977e"
      ],
      "layout": "IPY_MODEL_97def7d09b1a4359bda9237e1a46d28c"
     }
    },
    "8562c9e4bc8443db82350ff5f496958b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "875eff2116cf45b9b386071a7d8cc1c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "885eeace639140e2a01b16692b64accc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e437002cee7c48468d608ac3b6419490",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4d7dc520db647d9bd626ee52f8a35bd",
      "value": 0
     }
    },
    "889ece199b2a469388992df645c9977e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d788e171ee934b0d9275fcb6c88d69c8",
      "placeholder": "​",
      "style": "IPY_MODEL_8ee7f59198f44ac6af6a747b4d7c505a",
      "value": " 0/1 [00:00&lt;?, ?it/s]"
     }
    },
    "8ee7f59198f44ac6af6a747b4d7c505a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f43314093db461f8f90e91e48dbd0da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "97def7d09b1a4359bda9237e1a46d28c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98cad26d7f274b71a04d37fca89196bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a32f46d1b39247d69617fd8d08255dde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9b9d71402eb46b595cfc84dd522acfb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6fd02082a4342fbb9b9da6449325cfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ca36aa40d1e64ad496b3b838462acaa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27d5e2469ff444539de5d7d4b4ab6278",
      "placeholder": "​",
      "style": "IPY_MODEL_875eff2116cf45b9b386071a7d8cc1c7",
      "value": " 0/2 [30:03&lt;?, ?it/s]"
     }
    },
    "d49849d9283546c9b34517f327232757": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4d7dc520db647d9bd626ee52f8a35bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d5590ae5cbe246c8a3b97a1794582dec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d623bf979daa40e8af2598e247099b4e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c6fd02082a4342fbb9b9da6449325cfb",
      "value": 0
     }
    },
    "d623bf979daa40e8af2598e247099b4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d702bf265eca4bbbbcb7a358df381c65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8562c9e4bc8443db82350ff5f496958b",
      "placeholder": "​",
      "style": "IPY_MODEL_e17bf6667ccd4167af9110a09ba012ac",
      "value": "  0%"
     }
    },
    "d788e171ee934b0d9275fcb6c88d69c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df78c6ab42474534a547a0a7ba44b754": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_029421ef2fec489b8b379351e00e188a",
      "placeholder": "​",
      "style": "IPY_MODEL_98cad26d7f274b71a04d37fca89196bf",
      "value": " 0/10 [00:03&lt;?, ?it/s]"
     }
    },
    "e17bf6667ccd4167af9110a09ba012ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e437002cee7c48468d608ac3b6419490": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc30a6a4b6064be0b3c4a786a4b64952": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60ed458c82de4401a7eb400c23f1338d",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_673f3f8df9244b538ad88f1fc82442b6",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
